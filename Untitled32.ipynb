{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27636fca3a8c461787baff1a349af865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_077922fa4810484e8defa176e64342f9",
              "IPY_MODEL_d80bc3a6f888467bb324f0ec49873368",
              "IPY_MODEL_3fef3da9e5d1429bb1b83dc0d644a1df"
            ],
            "layout": "IPY_MODEL_7b6f536541dc4aeca8739a8a9c20f591"
          }
        },
        "077922fa4810484e8defa176e64342f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e342024e50534b55a3214b4207edcf57",
            "placeholder": "​",
            "style": "IPY_MODEL_40bebe3c8e784541a465d0750e760cf1",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d80bc3a6f888467bb324f0ec49873368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9fd7844cbed4400bc8b1f076fd4a58d",
            "max": 662513657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6cde0dfcd0843d3905a7e9495817da5",
            "value": 662513657
          }
        },
        "3fef3da9e5d1429bb1b83dc0d644a1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492df7f033904f20b38d06c4c585b97a",
            "placeholder": "​",
            "style": "IPY_MODEL_6ada7b011ccd49e2a3b6f6e17a074095",
            "value": " 663M/663M [00:00&lt;00:00, 225MB/s]"
          }
        },
        "7b6f536541dc4aeca8739a8a9c20f591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e342024e50534b55a3214b4207edcf57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40bebe3c8e784541a465d0750e760cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9fd7844cbed4400bc8b1f076fd4a58d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6cde0dfcd0843d3905a7e9495817da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "492df7f033904f20b38d06c4c585b97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ada7b011ccd49e2a3b6f6e17a074095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1311d909060444b8a8a73c0d234b06dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c8e7b06275c4fd9a8cbdc6521264359",
              "IPY_MODEL_247eb04689f145849b61281011ee10d6",
              "IPY_MODEL_681ae69919854e8cb6c94f6bae04af22"
            ],
            "layout": "IPY_MODEL_b8e5d36ceb6a4ae487d0f2707c6544fe"
          }
        },
        "5c8e7b06275c4fd9a8cbdc6521264359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a07bdf1a534f70a9a7fef0659cf880",
            "placeholder": "​",
            "style": "IPY_MODEL_4c709f707db449059f713b123e262d22",
            "value": "model.safetensors: 100%"
          }
        },
        "247eb04689f145849b61281011ee10d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c22b429f86e468a96e31abdf1f1f6c1",
            "max": 662435448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a73d0fa1972c4ac8bc9541d4bf5f767f",
            "value": 662435448
          }
        },
        "681ae69919854e8cb6c94f6bae04af22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215163703bad4934a7a88ea6b4c3d779",
            "placeholder": "​",
            "style": "IPY_MODEL_46c35cfe1fca4e51ab5b95c1a51917f9",
            "value": " 662M/662M [00:04&lt;00:00, 202MB/s]"
          }
        },
        "b8e5d36ceb6a4ae487d0f2707c6544fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a07bdf1a534f70a9a7fef0659cf880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c709f707db449059f713b123e262d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c22b429f86e468a96e31abdf1f1f6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73d0fa1972c4ac8bc9541d4bf5f767f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "215163703bad4934a7a88ea6b4c3d779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c35cfe1fca4e51ab5b95c1a51917f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72408a7d7d2249af9750dba116cf988b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_101ef3d549554056b207930d46b4dc12",
              "IPY_MODEL_71f9032787014916908a32144a5c4886",
              "IPY_MODEL_d3c3d75af4624fa58f1b33b06c0e7962"
            ],
            "layout": "IPY_MODEL_bf40faae9ec045819040acce8bde91ce"
          }
        },
        "101ef3d549554056b207930d46b4dc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d20c4d3235d4a22a74f97cf9dcbed05",
            "placeholder": "​",
            "style": "IPY_MODEL_7b6c0ad98d1644f4b92519bf4b8f8ce6",
            "value": "generation_config.json: 100%"
          }
        },
        "71f9032787014916908a32144a5c4886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d79b0c8aaf4f07a86d54300066ef7c",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3002aa9d8664787b3569fcc2c081ccb",
            "value": 137
          }
        },
        "d3c3d75af4624fa58f1b33b06c0e7962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae0b8cfed0b442e0b4c6c06068892d23",
            "placeholder": "​",
            "style": "IPY_MODEL_6216311ad10d4b3f92fdf4f2ff027f60",
            "value": " 137/137 [00:00&lt;00:00, 9.60kB/s]"
          }
        },
        "bf40faae9ec045819040acce8bde91ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d20c4d3235d4a22a74f97cf9dcbed05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b6c0ad98d1644f4b92519bf4b8f8ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d79b0c8aaf4f07a86d54300066ef7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3002aa9d8664787b3569fcc2c081ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae0b8cfed0b442e0b4c6c06068892d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6216311ad10d4b3f92fdf4f2ff027f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f471e5fd7740dbb24be36fc5454f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcfda591b71f4bbdbe1b5b42c7249f4e",
              "IPY_MODEL_7029c1cf5f334a23858b3c327ec6d092",
              "IPY_MODEL_dbc088d308f3490fae85fb36f300caf7"
            ],
            "layout": "IPY_MODEL_00a74ba2c8cf4023b39648e9c1c4d8fb"
          }
        },
        "bcfda591b71f4bbdbe1b5b42c7249f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6843d3f27ea84ad8bc484bfb692c57f1",
            "placeholder": "​",
            "style": "IPY_MODEL_5af922a87bf1446499f6ca851c961c6e",
            "value": "config.json: 100%"
          }
        },
        "7029c1cf5f334a23858b3c327ec6d092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f04dc8f6874d83917465cc54fe5340",
            "max": 693,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aece4236eb144e00a8dbefc08ce40cf4",
            "value": 693
          }
        },
        "dbc088d308f3490fae85fb36f300caf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69fbc99b54914aad83634b4ddc3dcc98",
            "placeholder": "​",
            "style": "IPY_MODEL_5b1343ad068947809b857848aaf9818e",
            "value": " 693/693 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "00a74ba2c8cf4023b39648e9c1c4d8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6843d3f27ea84ad8bc484bfb692c57f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af922a87bf1446499f6ca851c961c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f04dc8f6874d83917465cc54fe5340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aece4236eb144e00a8dbefc08ce40cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69fbc99b54914aad83634b4ddc3dcc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1343ad068947809b857848aaf9818e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb95701d0d8146ada10dbb3de7cda519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceeadcf920eb4c51861d8c865affdb60",
              "IPY_MODEL_de294bfbba604d68a739db3b72e73379",
              "IPY_MODEL_14b6964c771646f38f00915a1164df17"
            ],
            "layout": "IPY_MODEL_205bb7b50e0f4c27998a3cbaf4ec1ef8"
          }
        },
        "ceeadcf920eb4c51861d8c865affdb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230fc155266440df97d51b63d7e6432e",
            "placeholder": "​",
            "style": "IPY_MODEL_82a6d34c456d4a04b5513f627b4e4e9c",
            "value": "model.safetensors: 100%"
          }
        },
        "de294bfbba604d68a739db3b72e73379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929090e773f8432ab9af59420235c08b",
            "max": 1118459525,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4221dd8b0bed410ba8c88123d25b0dc5",
            "value": 1118459525
          }
        },
        "14b6964c771646f38f00915a1164df17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4fbf0e14d54867bda9f49ef8cc2d2b",
            "placeholder": "​",
            "style": "IPY_MODEL_d490dc4551684169beced0f6fbfebe97",
            "value": " 1.12G/1.12G [00:05&lt;00:00, 246MB/s]"
          }
        },
        "205bb7b50e0f4c27998a3cbaf4ec1ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "230fc155266440df97d51b63d7e6432e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a6d34c456d4a04b5513f627b4e4e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "929090e773f8432ab9af59420235c08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4221dd8b0bed410ba8c88123d25b0dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f4fbf0e14d54867bda9f49ef8cc2d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d490dc4551684169beced0f6fbfebe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc08189e4904e6eb82480ac14bb26b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5a272c9c0434460a31d3a954b78c926",
              "IPY_MODEL_1baad00fa283443dbb7999f8b8796784",
              "IPY_MODEL_4ebd8c0f24cb4837b54ecde14baf2c6f"
            ],
            "layout": "IPY_MODEL_79e763ca59bb42f2b55a16076b2e60ae"
          }
        },
        "e5a272c9c0434460a31d3a954b78c926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f51a040331c4485ca93aebf998ba3a97",
            "placeholder": "​",
            "style": "IPY_MODEL_bd96d89c4145420da99a154c6c3a1bda",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1baad00fa283443dbb7999f8b8796784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c457d7efd64aad81bbadd1bb1e9199",
            "max": 746,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbb5c90f8c1549cabd5f14d8700840e5",
            "value": 746
          }
        },
        "4ebd8c0f24cb4837b54ecde14baf2c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b669a91a4a543e1a2de3292ea1bcf26",
            "placeholder": "​",
            "style": "IPY_MODEL_32d81b3df6cb4b529564b710b8ab9935",
            "value": " 746/746 [00:00&lt;00:00, 42.2kB/s]"
          }
        },
        "79e763ca59bb42f2b55a16076b2e60ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51a040331c4485ca93aebf998ba3a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd96d89c4145420da99a154c6c3a1bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c457d7efd64aad81bbadd1bb1e9199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb5c90f8c1549cabd5f14d8700840e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b669a91a4a543e1a2de3292ea1bcf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d81b3df6cb4b529564b710b8ab9935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a19dfed298040a4a2af082fbd369d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb1488be0ed54e3ead3153b7ae9e13f7",
              "IPY_MODEL_2837c17c40894a4e85300d06c1b86f2f",
              "IPY_MODEL_61c824fe12f045099d28440112213175"
            ],
            "layout": "IPY_MODEL_8a741a14bbd548939f748e725ad74941"
          }
        },
        "fb1488be0ed54e3ead3153b7ae9e13f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c502e0ad277041f784602b65cffdab52",
            "placeholder": "​",
            "style": "IPY_MODEL_ffcbaf5b39a44867ad92e22dd4283cb4",
            "value": "tokenizer.model: 100%"
          }
        },
        "2837c17c40894a4e85300d06c1b86f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e0c8a21601414f8c99a8684f9a6a89",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d1540c67a1b486f93647fb8b3631ca8",
            "value": 499723
          }
        },
        "61c824fe12f045099d28440112213175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef8cbc35e78343528538be1e3c7b7e3a",
            "placeholder": "​",
            "style": "IPY_MODEL_d3ee237a93704a13bd7e50c7aa2e485d",
            "value": " 500k/500k [00:00&lt;00:00, 14.7MB/s]"
          }
        },
        "8a741a14bbd548939f748e725ad74941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c502e0ad277041f784602b65cffdab52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcbaf5b39a44867ad92e22dd4283cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45e0c8a21601414f8c99a8684f9a6a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1540c67a1b486f93647fb8b3631ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef8cbc35e78343528538be1e3c7b7e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ee237a93704a13bd7e50c7aa2e485d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e13d2d63d984fbea8e5e3dce5186b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48015d00bc794fabb1a758c832df4773",
              "IPY_MODEL_a5ac73c2a4044d2cb9d04db55c53e346",
              "IPY_MODEL_4cf3596f40ab483d970e4b192ce6e374"
            ],
            "layout": "IPY_MODEL_b63f74ed4b7c40c285b76bf452c295fd"
          }
        },
        "48015d00bc794fabb1a758c832df4773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b287036dd04171b87e5d88073850a9",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5d3a6eaec442f7afe407bc70600cde",
            "value": "tokenizer.json: 100%"
          }
        },
        "a5ac73c2a4044d2cb9d04db55c53e346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f79345d097134fab95ac0bf98be3b728",
            "max": 1842764,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e0fdc9e7844ed0a32af4ba17473de2",
            "value": 1842764
          }
        },
        "4cf3596f40ab483d970e4b192ce6e374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2e1e0c4e6f4a5fadca406413918650",
            "placeholder": "​",
            "style": "IPY_MODEL_2e313602b5a34674bd019e6f34829904",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 11.6MB/s]"
          }
        },
        "b63f74ed4b7c40c285b76bf452c295fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59b287036dd04171b87e5d88073850a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e5d3a6eaec442f7afe407bc70600cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f79345d097134fab95ac0bf98be3b728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e0fdc9e7844ed0a32af4ba17473de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e2e1e0c4e6f4a5fadca406413918650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e313602b5a34674bd019e6f34829904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21b94fa823e645f49f9af64f70ebf4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f51ffffcc83944518310f94bbfb27781",
              "IPY_MODEL_3a0cdb50137a400085e7cde7ad5b8acf",
              "IPY_MODEL_10b5bb4a56eb4f15a5bdbcb4c336c015"
            ],
            "layout": "IPY_MODEL_0aec4b5a6f6b4c159ae337bd4fceb224"
          }
        },
        "f51ffffcc83944518310f94bbfb27781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812f21e5c1ce41b485c7ba0c26254663",
            "placeholder": "​",
            "style": "IPY_MODEL_d35315dac2ff4066a4325f2ffbce1646",
            "value": "added_tokens.json: 100%"
          }
        },
        "3a0cdb50137a400085e7cde7ad5b8acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b2dbf07b294bc99bc48748cf754290",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d9c1da89c074d6a999b74b7ec653084",
            "value": 21
          }
        },
        "10b5bb4a56eb4f15a5bdbcb4c336c015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e6ce7b3bd4e4031aba0aafcc41d8bbe",
            "placeholder": "​",
            "style": "IPY_MODEL_92cf9e86450a4fe3bd4e8bc46a3537fe",
            "value": " 21.0/21.0 [00:00&lt;00:00, 1.21kB/s]"
          }
        },
        "0aec4b5a6f6b4c159ae337bd4fceb224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812f21e5c1ce41b485c7ba0c26254663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d35315dac2ff4066a4325f2ffbce1646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63b2dbf07b294bc99bc48748cf754290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9c1da89c074d6a999b74b7ec653084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e6ce7b3bd4e4031aba0aafcc41d8bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cf9e86450a4fe3bd4e8bc46a3537fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e636cd4ef8b94ea9b2690945b242a016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a3a6058c0d847048ddaba625274f8d2",
              "IPY_MODEL_c88af462d6974988b59dc86420abc414",
              "IPY_MODEL_dca1f2afdb854ff0ae0f4dc5f290e7b6"
            ],
            "layout": "IPY_MODEL_a3687a9268894df9a8d5a4b95e39c8c8"
          }
        },
        "5a3a6058c0d847048ddaba625274f8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67362ba128214f3a817f05de200f7d25",
            "placeholder": "​",
            "style": "IPY_MODEL_f39237b55ac34c26a4c2e0c3932b11a0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c88af462d6974988b59dc86420abc414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc8677593f84768a8a2906506269656",
            "max": 435,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1583f122a07349c293acef8eefce8b5b",
            "value": 435
          }
        },
        "dca1f2afdb854ff0ae0f4dc5f290e7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c0be8257f44ebab74edd27e57e1c5d",
            "placeholder": "​",
            "style": "IPY_MODEL_1079b5b793b34c36b5208dbae1ff7ee8",
            "value": " 435/435 [00:00&lt;00:00, 36.0kB/s]"
          }
        },
        "a3687a9268894df9a8d5a4b95e39c8c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67362ba128214f3a817f05de200f7d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f39237b55ac34c26a4c2e0c3932b11a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc8677593f84768a8a2906506269656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1583f122a07349c293acef8eefce8b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1c0be8257f44ebab74edd27e57e1c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1079b5b793b34c36b5208dbae1ff7ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_09HfTqWrrA0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0b5x7l_prw1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czlcOszJrw4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tve517v9rw69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ttj/blt"
      ],
      "metadata": {
        "id": "q32ls6OCtOAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('safetensors/blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('safetensors/entropy_model/consolidated.safetensors')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "bjvQSp8Trw9V",
        "outputId": "182fa071-7ea7-4886-c8d5-bebafe410f53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: \"safetensors/blt_1b/consolidated.safetensors\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3beb9621934a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load BLT-1B model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'safetensors/blt_1b/consolidated.safetensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load entropy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[1;32m    312\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"safetensors/blt_1b/consolidated.safetensors\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0F097eVrxjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('ttj/blt')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('ttj/blt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "fBf9X4V3sXuO",
        "outputId": "24ee96dc-8986-42fc-b335-f42d6f9545d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: \"ttj/blt\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6dd8b7c053b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load BLT-1B model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ttj/blt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load entropy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[1;32m    312\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"ttj/blt\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/safetensors/ blt_1b\n",
        "\n",
        "\n",
        "!wget https://huggingface.co/ttj/blt/resolve/main/safetensors/blt_1b/consolidated.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so3MSs3Osbkv",
        "outputId": "23e5f44e-f760-4dbf-a0e9-2cd84acbd459"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/safetensors/ blt_1b\n",
            "--2025-04-24 21:28:03--  https://huggingface.co/ttj/blt/resolve/main/safetensors/blt_1b/consolidated.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.167.112.96, 3.167.112.45, 3.167.112.38, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.167.112.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/c4/d6/c4d6ccaf6771cc82a464702e8fb58c952ab0960b39b8a81be086d594c3ff5b3f/3738bef71ca45c1ac58783c93c6eee8da6feefc0672113bcccd0a44cfd3cfe1f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27consolidated.safetensors%3B+filename%3D%22consolidated.safetensors%22%3B&Expires=1745533683&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTUzMzY4M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2M0L2Q2L2M0ZDZjY2FmNjc3MWNjODJhNDY0NzAyZThmYjU4Yzk1MmFiMDk2MGIzOWI4YTgxYmUwODZkNTk0YzNmZjViM2YvMzczOGJlZjcxY2E0NWMxYWM1ODc4M2M5M2M2ZWVlOGRhNmZlZWZjMDY3MjExM2JjY2NkMGE0NGNmZDNjZmUxZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lvGaAy4rsLhd6YYzdcg-iqAeAikrj2XSNQEuwFpmTVannQrSU4lv%7EAI7sil9Xopewr9GVM0wLbnAZejKCfbnhe7p2s3PSK2Mbkgy5shVha1qFR4hxUqQ1OvdnxPJBAjpv1cDFzDRo6meZPfjEC%7EOQjOYVG6LbMuStPmaixGdLGagPE1bXMGumRjvAsv22vcxD0cAgkrQAKAJsxA1Vb8incMH7bubQwzj3Oj7RxEkOQI2q5wFwopZKeUZsOMTcaGxtzOrVx39FWGewEE2U%7E4zwC3bf3HJRU5rxVqnYgENfiyZI9-B0ZX-49Wg0Ve%7EEGKEsuFL47XVNI4JjOlM90w02w__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-24 21:28:03--  https://cdn-lfs-us-1.hf.co/repos/c4/d6/c4d6ccaf6771cc82a464702e8fb58c952ab0960b39b8a81be086d594c3ff5b3f/3738bef71ca45c1ac58783c93c6eee8da6feefc0672113bcccd0a44cfd3cfe1f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27consolidated.safetensors%3B+filename%3D%22consolidated.safetensors%22%3B&Expires=1745533683&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTUzMzY4M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2M0L2Q2L2M0ZDZjY2FmNjc3MWNjODJhNDY0NzAyZThmYjU4Yzk1MmFiMDk2MGIzOWI4YTgxYmUwODZkNTk0YzNmZjViM2YvMzczOGJlZjcxY2E0NWMxYWM1ODc4M2M5M2M2ZWVlOGRhNmZlZWZjMDY3MjExM2JjY2NkMGE0NGNmZDNjZmUxZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=lvGaAy4rsLhd6YYzdcg-iqAeAikrj2XSNQEuwFpmTVannQrSU4lv%7EAI7sil9Xopewr9GVM0wLbnAZejKCfbnhe7p2s3PSK2Mbkgy5shVha1qFR4hxUqQ1OvdnxPJBAjpv1cDFzDRo6meZPfjEC%7EOQjOYVG6LbMuStPmaixGdLGagPE1bXMGumRjvAsv22vcxD0cAgkrQAKAJsxA1Vb8incMH7bubQwzj3Oj7RxEkOQI2q5wFwopZKeUZsOMTcaGxtzOrVx39FWGewEE2U%7E4zwC3bf3HJRU5rxVqnYgENfiyZI9-B0ZX-49Wg0Ve%7EEGKEsuFL47XVNI4JjOlM90w02w__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.168.73.68, 3.168.73.31, 3.168.73.67, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.168.73.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9067807688 (8.4G) [binary/octet-stream]\n",
            "Saving to: ‘consolidated.safetensors’\n",
            "\n",
            "consolidated.safete 100%[===================>]   8.44G  44.3MB/s    in 3m 6s   \n",
            "\n",
            "2025-04-24 21:31:09 (46.4 MB/s) - ‘consolidated.safetensors’ saved [9067807688/9067807688]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/safetensors/entropy_model\n",
        "!wget https://huggingface.co/ttj/blt/resolve/main/safetensors/entropy_model/consolidated.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4jHl4E5s0vX",
        "outputId": "e669a885-6ed1-4813-9b09-f1fe0fa01a11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/safetensors/entropy_model\n",
            "--2025-04-24 21:32:15--  https://huggingface.co/ttj/blt/resolve/main/safetensors/entropy_model/consolidated.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 3.168.73.106, 3.168.73.111, 3.168.73.38, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.168.73.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/c4/d6/c4d6ccaf6771cc82a464702e8fb58c952ab0960b39b8a81be086d594c3ff5b3f/aa45c5ffae9f528329d146a91356d1d06056b71653beddada39781bfcadb521d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27consolidated.safetensors%3B+filename%3D%22consolidated.safetensors%22%3B&Expires=1745533935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTUzMzkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2M0L2Q2L2M0ZDZjY2FmNjc3MWNjODJhNDY0NzAyZThmYjU4Yzk1MmFiMDk2MGIzOWI4YTgxYmUwODZkNTk0YzNmZjViM2YvYWE0NWM1ZmZhZTlmNTI4MzI5ZDE0NmE5MTM1NmQxZDA2MDU2YjcxNjUzYmVkZGFkYTM5NzgxYmZjYWRiNTIxZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=urQ3EPZdtqBKXOE6YVZBfNbvPWTvMTIUElrrfsFDuLYVLZWHJl5OqLXw7qN9QlVd6vGII7sNH5fi8kL-8VFWDjuOI56-3IPHloyvdRnGByJCTEHRjbiza98DNlzAQQlXw9Ez-eUJGOLIVgKD1WJuP3ht7aDENLpT57uH5lwsrXWQsXRvYdrK59C5ZnT3I61B4UUNENAZ5Jh1CpIVZEbWiJfcsx3rQkJmpSyvIY88O2sJARJtB8GSIpME4BQFBDyuND8TXGDnAdNMeLKTIrfRriVehJSPRFTg1pcyHAAiKftdinnw9l9VTwWcYLiWMyfmkMqrxv2H5ZbyW5IXLhSvmw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-24 21:32:15--  https://cdn-lfs-us-1.hf.co/repos/c4/d6/c4d6ccaf6771cc82a464702e8fb58c952ab0960b39b8a81be086d594c3ff5b3f/aa45c5ffae9f528329d146a91356d1d06056b71653beddada39781bfcadb521d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27consolidated.safetensors%3B+filename%3D%22consolidated.safetensors%22%3B&Expires=1745533935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTUzMzkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2M0L2Q2L2M0ZDZjY2FmNjc3MWNjODJhNDY0NzAyZThmYjU4Yzk1MmFiMDk2MGIzOWI4YTgxYmUwODZkNTk0YzNmZjViM2YvYWE0NWM1ZmZhZTlmNTI4MzI5ZDE0NmE5MTM1NmQxZDA2MDU2YjcxNjUzYmVkZGFkYTM5NzgxYmZjYWRiNTIxZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=urQ3EPZdtqBKXOE6YVZBfNbvPWTvMTIUElrrfsFDuLYVLZWHJl5OqLXw7qN9QlVd6vGII7sNH5fi8kL-8VFWDjuOI56-3IPHloyvdRnGByJCTEHRjbiza98DNlzAQQlXw9Ez-eUJGOLIVgKD1WJuP3ht7aDENLpT57uH5lwsrXWQsXRvYdrK59C5ZnT3I61B4UUNENAZ5Jh1CpIVZEbWiJfcsx3rQkJmpSyvIY88O2sJARJtB8GSIpME4BQFBDyuND8TXGDnAdNMeLKTIrfRriVehJSPRFTg1pcyHAAiKftdinnw9l9VTwWcYLiWMyfmkMqrxv2H5ZbyW5IXLhSvmw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.138.128.54, 108.138.128.37, 108.138.128.53, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.138.128.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199037304 (190M) [binary/octet-stream]\n",
            "Saving to: ‘consolidated.safetensors’\n",
            "\n",
            "consolidated.safete 100%[===================>] 189.82M  41.7MB/s    in 4.6s    \n",
            "\n",
            "2025-04-24 21:32:20 (41.0 MB/s) - ‘consolidated.safetensors’ saved [199037304/199037304]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8JrtRAUty4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ksa8HQRUuAru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "# Load the weights from the safetensors files\n",
        "model.load_state_dict(model_weights)\n",
        "# (Optional) Load the entropy model weights if needed\n",
        "# entropy_model.load_state_dict(entropy_weights)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "u3IicIeXuBBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "input_text = \"Your input text here\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_ids)\n",
        "\n",
        "# Decode the output\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(decoded_output)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8btdg7cPuCYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "q_nqpqYguG51",
        "outputId": "e2f619c2-5580-42ad-e71f-be7fc181be6a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file or directory: \"/content/safetensors/blt_1b/consolidated.safetensors\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-61808ccfa397>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load BLT-1B model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/safetensors/blt_1b/consolidated.safetensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load entropy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filename, device)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[1;32m    312\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"/content/safetensors/blt_1b/consolidated.safetensors\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/safetensors"
      ],
      "metadata": {
        "id": "hIfrwCCWuM0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n"
      ],
      "metadata": {
        "id": "oD1UdoHYuZfV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "model.load_state_dict(model_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "FAPTxklIuvPm",
        "outputId": "269bb493-5028-4041-bc14-62792e7a0cbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b488e1c30aa0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mentropy_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/safetensors/entropy_model/consolidated.safetensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "St_CLiiVuvhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Define and initialize the model\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "# Now load the weights\n",
        "model.load_state_dict(model_weights)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "27636fca3a8c461787baff1a349af865",
            "077922fa4810484e8defa176e64342f9",
            "d80bc3a6f888467bb324f0ec49873368",
            "3fef3da9e5d1429bb1b83dc0d644a1df",
            "7b6f536541dc4aeca8739a8a9c20f591",
            "e342024e50534b55a3214b4207edcf57",
            "40bebe3c8e784541a465d0750e760cf1",
            "d9fd7844cbed4400bc8b1f076fd4a58d",
            "a6cde0dfcd0843d3905a7e9495817da5",
            "492df7f033904f20b38d06c4c585b97a",
            "6ada7b011ccd49e2a3b6f6e17a074095",
            "1311d909060444b8a8a73c0d234b06dd",
            "5c8e7b06275c4fd9a8cbdc6521264359",
            "247eb04689f145849b61281011ee10d6",
            "681ae69919854e8cb6c94f6bae04af22",
            "b8e5d36ceb6a4ae487d0f2707c6544fe",
            "37a07bdf1a534f70a9a7fef0659cf880",
            "4c709f707db449059f713b123e262d22",
            "0c22b429f86e468a96e31abdf1f1f6c1",
            "a73d0fa1972c4ac8bc9541d4bf5f767f",
            "215163703bad4934a7a88ea6b4c3d779",
            "46c35cfe1fca4e51ab5b95c1a51917f9",
            "72408a7d7d2249af9750dba116cf988b",
            "101ef3d549554056b207930d46b4dc12",
            "71f9032787014916908a32144a5c4886",
            "d3c3d75af4624fa58f1b33b06c0e7962",
            "bf40faae9ec045819040acce8bde91ce",
            "0d20c4d3235d4a22a74f97cf9dcbed05",
            "7b6c0ad98d1644f4b92519bf4b8f8ce6",
            "d8d79b0c8aaf4f07a86d54300066ef7c",
            "d3002aa9d8664787b3569fcc2c081ccb",
            "ae0b8cfed0b442e0b4c6c06068892d23",
            "6216311ad10d4b3f92fdf4f2ff027f60"
          ]
        },
        "id": "mu01MD_Fu-fn",
        "outputId": "f7af800f-033c-4024-aa4d-ec3dbd6fd7c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:  79%|#######9  | 524M/663M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27636fca3a8c461787baff1a349af865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/662M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1311d909060444b8a8a73c0d234b06dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72408a7d7d2249af9750dba116cf988b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for OPTForCausalLM:\n\tMissing key(s) in state_dict: \"model.decoder.embed_tokens.weight\", \"model.decoder.embed_positions.weight\", \"model.decoder.project_out.weight\", \"model.decoder.project_in.weight\", \"model.decoder.layers.0.self_attn.k_proj.weight\", \"model.decoder.layers.0.self_attn.k_proj.bias\", \"model.decoder.layers.0.self_attn.v_proj.weight\", \"model.decoder.layers.0.self_attn.v_proj.bias\", \"model.decoder.layers.0.self_attn.q_proj.weight\", \"model.decoder.layers.0.self_attn.q_proj.bias\", \"model.decoder.layers.0.self_attn.out_proj.weight\", \"model.decoder.layers.0.self_attn.out_proj.bias\", \"model.decoder.layers.0.self_attn_layer_norm.weight\", \"model.decoder.layers.0.self_attn_layer_norm.bias\", \"model.decoder.layers.0.fc1.weight\", \"model.decoder.layers.0.fc1.bias\", \"model.decoder.layers.0.fc2.weight\", \"model.decoder.layers.0.fc2.bias\", \"model.decoder.layers.0.final_layer_norm.weight\", \"model.decoder.layers.0.final_layer_norm.bias\", \"model.decoder.layers.1.self_attn.k_proj.weight\", \"model.decoder.layers.1.self_attn.k_proj.bias\", \"model.decoder.layers.1.self_attn.v_proj.weight\", \"model.decoder.layers.1.self_attn.v_proj.bias\", \"model.decoder.layers.1.self_attn.q_proj.weight\", \"model.decoder.layers.1.self_attn.q_proj.bias\", \"model.decoder.layers.1.self_attn.out_proj.weight\", \"model.decoder.layers.1.self_attn.out_proj.bias\", \"model.decoder.layers.1.self_attn_layer_norm.weight\", \"model.decoder.layers.1.self_attn_layer_norm.bias\", \"model.decoder.layers.1.fc1.weight\", \"model.decoder.layers.1.fc1.bias\", \"model.decoder.layers.1.fc2.weight\", \"model.decoder.layers.1.fc2.bias\", \"model.decoder.layers.1.final_layer_norm.weight\", \"model.decoder.layers.1.final_layer_norm.bias\", \"model.decoder.layers.2.self_attn.k_proj.weight\", \"model.decoder.layers.2.self_attn.k_proj.bias\", \"model.decoder.layers.2.self_attn.v_proj.weight\", \"model.decoder.layers.2.self_attn.v_proj.bias\", \"model.decoder.layers.2.self_attn.q_proj.weight\", \"model.decoder.layers.2.self_attn.q_proj.bias\", \"model.decoder.layers.2.self_attn.out_proj.weight\", \"model.decoder.layers.2.self_attn.out_proj.bias\", \"model.decoder.layers.2.self_attn_layer_norm.weight\", \"model.decoder.layers.2.self_attn_layer_norm.bias\", \"model.decoder.layers.2.fc1.weight\", \"model.decoder.layers.2.fc1.bias\", \"model.decoder.layers.2.fc2.weight\", \"model.decoder.layers.2.fc2.bias\", \"model.decoder.layers.2.final_layer_norm.weight\", \"model.decoder.layers.2.final_layer_norm.bias\", \"model.decoder.layers.3.self_attn.k_proj.weight\", \"model.decoder.layers.3.self_attn.k_proj.bias\", \"model.decoder.layers.3.self_attn.v_proj.weight\", \"model.decoder.layers.3.self_attn.v_proj.bias\", \"model.decoder.layers.3.self_attn.q_proj.weight\", \"model.decoder.layers.3.self_attn.q_proj.bias\", \"model.decoder.layers.3.self_attn.out_proj.weight\", \"model.decoder.layers.3.self_attn.out_proj.bias\", \"model.decoder.layers.3.self_attn_layer_norm.weight\", \"model.decoder.layers.3.self_attn_layer_norm.bias\", \"model.decoder.layers.3.fc1.weight\", \"model.decoder.layers.3.fc1.bias\", \"model.decoder.layers.3.fc2.weight\", \"model.decoder.layers.3.fc2.bias\", \"model.decoder.layers.3.final_layer_norm.weight\", \"model.decoder.layers.3.final_layer_norm.bias\", \"model.decoder.layers.4.self_attn.k_proj.weight\", \"model.decoder.layers.4.self_attn.k_proj.bias\", \"model.decoder.layers.4.self_attn.v_proj.weight\", \"model.decoder.layers.4.self_attn.v_proj.bias\", \"model.decoder.layers.4.self_attn.q_proj.weight\", \"model.decoder.layers.4.self_attn.q_proj.bias\", \"model.decoder.layers.4.self_attn.out_proj.weight\", \"model.decoder.layers.4.self_attn.out_proj.bias\", \"model.decoder.layers.4.self_attn_layer_norm.weight\", \"model.decoder.layers.4.self_attn_layer_norm.bias\", \"model.decoder.layers.4.fc1.weight\", \"model.decoder.layers.4.fc1.bias\", \"model.decoder.layers.4.fc2.weight\", \"model.decoder.layers.4.fc2.bias\", \"model.decoder.layers.4.final_layer_norm.weight\", \"model.decoder.layers.4.final_layer_norm.bias\", \"model.decoder.layers.5.self_attn.k_proj.weight\", \"model.decoder.layers.5.self_attn.k_proj.bias\", \"model.decoder.layers.5.self_attn.v_proj.weight\", \"model.decoder.layers.5.self_attn.v_proj.bias\", \"model.decoder.layers.5.self_attn.q_proj.weight\", \"model.decoder.layers.5.self_attn.q_proj.bias\", \"model.decoder.layers.5.self_attn.out_proj.weight\", \"model.decoder.layers.5.self_attn.out_proj.bias\", \"model.decoder.layers.5.self_attn_layer_norm.weight\", \"model.decoder.layers.5.self_attn_layer_norm.bias\", \"model.decoder.layers.5.fc1.weight\", \"model.decoder.layers.5.fc1.bias\", \"model.decoder.layers.5.fc2.weight\", \"model.decoder.layers.5.fc2.bias\", \"model.decoder.layers.5.final_layer_norm.weight\", \"model.decoder.layers.5.final_layer_norm.bias\", \"model.decoder.layers.6.self_attn.k_proj.weight\", \"model.decoder.layers.6.self_attn.k_proj.bias\", \"model.decoder.layers.6.self_attn.v_proj.weight\", \"model.decoder.layers.6.self_attn.v_proj.bias\", \"model.decoder.layers.6.self_attn.q_proj.weight\", \"model.decoder.layers.6.self_attn.q_proj.bias\", \"model.decoder.layers.6.self_attn.out_proj.weight\", \"model.decoder.layers.6.self_attn.out_proj.bias\", \"model.decoder.layers.6.self_attn_layer_norm.weight\", \"model.decoder.layers.6.self_attn_layer_norm.bias\", \"model.decoder.layers.6.fc1.weight\", \"model.decoder.layers.6.fc1.bias\", \"model.decoder.layers.6.fc2.weight\", \"model.decoder.layers.6.fc2.bias\", \"model.decoder.layers.6.final_layer_norm.weight\", \"model.decoder.layers.6.final_layer_norm.bias\", \"model.decoder.layers.7.self_attn.k_proj.weight\", \"model.decoder.layers.7.self_attn.k_proj.bias\", \"model.decoder.layers.7.self_attn.v_proj.weight\", \"model.decoder.layers.7.self_attn.v_proj.bias\", \"model.decoder.layers.7.self_attn.q_proj.weight\", \"model.decoder.layers.7.self_attn.q_proj.bias\", \"model.decoder.layers.7.self_attn.out_proj.weight\", \"model.decoder.layers.7.self_attn.out_proj.bias\", \"model.decoder.layers.7.self_attn_layer_norm.weight\", \"model.decoder.layers.7.self_attn_layer_norm.bias\", \"model.decoder.layers.7.fc1.weight\", \"model.decoder.layers.7.fc1.bias\", \"model.decoder.layers.7.fc2.weight\", \"model.decoder.layers.7.fc2.bias\", \"model.decoder.layers.7.final_layer_norm.weight\", \"model.decoder.layers.7.final_layer_norm.bias\", \"model.decoder.layers.8.self_attn.k_proj.weight\", \"model.decoder.layers.8.self_attn.k_proj.bias\", \"model.decoder.layers.8.self_attn.v_proj.weight\", \"model.decoder.layers.8.self_attn.v_proj.bias\", \"model.decoder.layers.8.self_attn.q_proj.weight\", \"model.decoder.layers.8.self_attn.q_proj.bias\", \"model.decoder.layers.8.self_attn.out_proj.weight\", \"model.decoder.layers.8.self_attn.out_proj.bias\", \"model.decoder.layers.8.self_attn_layer_norm.weight\", \"model.decoder.layers.8.self_attn_layer_norm.bias\", \"model.decoder.layers.8.fc1.weight\", \"model.decoder.layers.8.fc1.bias\", \"model.decoder.layers.8.fc2.weight\", \"model.decoder.layers.8.fc2.bias\", \"model.decoder.layers.8.final_layer_norm.weight\", \"model.decoder.layers.8.final_layer_norm.bias\", \"model.decoder.layers.9.self_attn.k_proj.weight\", \"model.decoder.layers.9.self_attn.k_proj.bias\", \"model.decoder.layers.9.self_attn.v_proj.weight\", \"model.decoder.layers.9.self_attn.v_proj.bias\", \"model.decoder.layers.9.self_attn.q_proj.weight\", \"model.decoder.layers.9.self_attn.q_proj.bias\", \"model.decoder.layers.9.self_attn.out_proj.weight\", \"model.decoder.layers.9.self_attn.out_proj.bias\", \"model.decoder.layers.9.self_attn_layer_norm.weight\", \"model.decoder.layers.9.self_attn_layer_norm.bias\", \"model.decoder.layers.9.fc1.weight\", \"model.decoder.layers.9.fc1.bias\", \"model.decoder.layers.9.fc2.weight\", \"model.decoder.layers.9.fc2.bias\", \"model.decoder.layers.9.final_layer_norm.weight\", \"model.decoder.layers.9.final_layer_norm.bias\", \"model.decoder.layers.10.self_attn.k_proj.weight\", \"model.decoder.layers.10.self_attn.k_proj.bias\", \"model.decoder.layers.10.self_attn.v_proj.weight\", \"model.decoder.layers.10.self_attn.v_proj.bias\", \"model.decoder.layers.10.self_attn.q_proj.weight\", \"model.decoder.layers.10.self_attn.q_proj.bias\", \"model.decoder.layers.10.self_attn.out_proj.weight\", \"model.decoder.layers.10.self_attn.out_proj.bias\", \"model.decoder.layers.10.self_attn_layer_norm.weight\", \"model.decoder.layers.10.self_attn_layer_norm.bias\", \"model.decoder.layers.10.fc1.weight\", \"model.decoder.layers.10.fc1.bias\", \"model.decoder.layers.10.fc2.weight\", \"model.decoder.layers.10.fc2.bias\", \"model.decoder.layers.10.final_layer_norm.weight\", \"model.decoder.layers.10.final_layer_norm.bias\", \"model.decoder.layers.11.self_attn.k_proj.weight\", \"model.decoder.layers.11.self_attn.k_proj.bias\", \"model.decoder.layers.11.self_attn.v_proj.weight\", \"model.decoder.layers.11.self_attn.v_proj.bias\", \"model.decoder.layers.11.self_attn.q_proj.weight\", \"model.decoder.layers.11.self_attn.q_proj.bias\", \"model.decoder.layers.11.self_attn.out_proj.weight\", \"model.decoder.layers.11.self_attn.out_proj.bias\", \"model.decoder.layers.11.self_attn_layer_norm.weight\", \"model.decoder.layers.11.self_attn_layer_norm.bias\", \"model.decoder.layers.11.fc1.weight\", \"model.decoder.layers.11.fc1.bias\", \"model.decoder.layers.11.fc2.weight\", \"model.decoder.layers.11.fc2.bias\", \"model.decoder.layers.11.final_layer_norm.weight\", \"model.decoder.layers.11.final_layer_norm.bias\", \"model.decoder.layers.12.self_attn.k_proj.weight\", \"model.decoder.layers.12.self_attn.k_proj.bias\", \"model.decoder.layers.12.self_attn.v_proj.weight\", \"model.decoder.layers.12.self_attn.v_proj.bias\", \"model.decoder.layers.12.self_attn.q_proj.weight\", \"model.decoder.layers.12.self_attn.q_proj.bias\", \"model.decoder.layers.12.self_attn.out_proj.weight\", \"model.decoder.layers.12.self_attn.out_proj.bias\", \"model.decoder.layers.12.self_attn_layer_norm.weight\", \"model.decoder.layers.12.self_attn_layer_norm.bias\", \"model.decoder.layers.12.fc1.weight\", \"model.decoder.layers.12.fc1.bias\", \"model.decoder.layers.12.fc2.weight\", \"model.decoder.layers.12.fc2.bias\", \"model.decoder.layers.12.final_layer_norm.weight\", \"model.decoder.layers.12.final_layer_norm.bias\", \"model.decoder.layers.13.self_attn.k_proj.weight\", \"model.decoder.layers.13.self_attn.k_proj.bias\", \"model.decoder.layers.13.self_attn.v_proj.weight\", \"model.decoder.layers.13.self_attn.v_proj.bias\", \"model.decoder.layers.13.self_attn.q_proj.weight\", \"model.decoder.layers.13.self_attn.q_proj.bias\", \"model.decoder.layers.13.self_attn.out_proj.weight\", \"model.decoder.layers.13.self_attn.out_proj.bias\", \"model.decoder.layers.13.self_attn_layer_norm.weight\", \"model.decoder.layers.13.self_attn_layer_norm.bias\", \"model.decoder.layers.13.fc1.weight\", \"model.decoder.layers.13.fc1.bias\", \"model.decoder.layers.13.fc2.weight\", \"model.decoder.layers.13.fc2.bias\", \"model.decoder.layers.13.final_layer_norm.weight\", \"model.decoder.layers.13.final_layer_norm.bias\", \"model.decoder.layers.14.self_attn.k_proj.weight\", \"model.decoder.layers.14.self_attn.k_proj.bias\", \"model.decoder.layers.14.self_attn.v_proj.weight\", \"model.decoder.layers.14.self_attn.v_proj.bias\", \"model.decoder.layers.14.self_attn.q_proj.weight\", \"model.decoder.layers.14.self_attn.q_proj.bias\", \"model.decoder.layers.14.self_attn.out_proj.weight\", \"model.decoder.layers.14.self_attn.out_proj.bias\", \"model.decoder.layers.14.self_attn_layer_norm.weight\", \"model.decoder.layers.14.self_attn_layer_norm.bias\", \"model.decoder.layers.14.fc1.weight\", \"model.decoder.layers.14.fc1.bias\", \"model.decoder.layers.14.fc2.weight\", \"model.decoder.layers.14.fc2.bias\", \"model.decoder.layers.14.final_layer_norm.weight\", \"model.decoder.layers.14.final_layer_norm.bias\", \"model.decoder.layers.15.self_attn.k_proj.weight\", \"model.decoder.layers.15.self_attn.k_proj.bias\", \"model.decoder.layers.15.self_attn.v_proj.weight\", \"model.decoder.layers.15.self_attn.v_proj.bias\", \"model.decoder.layers.15.self_attn.q_proj.weight\", \"model.decoder.layers.15.self_attn.q_proj.bias\", \"model.decoder.layers.15.self_attn.out_proj.weight\", \"model.decoder.layers.15.self_attn.out_proj.bias\", \"model.decoder.layers.15.self_attn_layer_norm.weight\", \"model.decoder.layers.15.self_attn_layer_norm.bias\", \"model.decoder.layers.15.fc1.weight\", \"model.decoder.layers.15.fc1.bias\", \"model.decoder.layers.15.fc2.weight\", \"model.decoder.layers.15.fc2.bias\", \"model.decoder.layers.15.final_layer_norm.weight\", \"model.decoder.layers.15.final_layer_norm.bias\", \"model.decoder.layers.16.self_attn.k_proj.weight\", \"model.decoder.layers.16.self_attn.k_proj.bias\", \"model.decoder.layers.16.self_attn.v_proj.weight\", \"model.decoder.layers.16.self_attn.v_proj.bias\", \"model.decoder.layers.16.self_attn.q_proj.weight\", \"model.decoder.layers.16.self_attn.q_proj.bias\", \"model.decoder.layers.16.self_attn.out_proj.weight\", \"model.decoder.layers.16.self_attn.out_proj.bias\", \"model.decoder.layers.16.self_attn_layer_norm.weight\", \"model.decoder.layers.16.self_attn_layer_norm.bias\", \"model.decoder.layers.16.fc1.weight\", \"model.decoder.layers.16.fc1.bias\", \"model.decoder.layers.16.fc2.weight\", \"model.decoder.layers.16.fc2.bias\", \"model.decoder.layers.16.final_layer_norm.weight\", \"model.decoder.layers.16.final_layer_norm.bias\", \"model.decoder.layers.17.self_attn.k_proj.weight\", \"model.decoder.layers.17.self_attn.k_proj.bias\", \"model.decoder.layers.17.self_attn.v_proj.weight\", \"model.decoder.layers.17.self_attn.v_proj.bias\", \"model.decoder.layers.17.self_attn.q_proj.weight\", \"model.decoder.layers.17.self_attn.q_proj.bias\", \"model.decoder.layers.17.self_attn.out_proj.weight\", \"model.decoder.layers.17.self_attn.out_proj.bias\", \"model.decoder.layers.17.self_attn_layer_norm.weight\", \"model.decoder.layers.17.self_attn_layer_norm.bias\", \"model.decoder.layers.17.fc1.weight\", \"model.decoder.layers.17.fc1.bias\", \"model.decoder.layers.17.fc2.weight\", \"model.decoder.layers.17.fc2.bias\", \"model.decoder.layers.17.final_layer_norm.weight\", \"model.decoder.layers.17.final_layer_norm.bias\", \"model.decoder.layers.18.self_attn.k_proj.weight\", \"model.decoder.layers.18.self_attn.k_proj.bias\", \"model.decoder.layers.18.self_attn.v_proj.weight\", \"model.decoder.layers.18.self_attn.v_proj.bias\", \"model.decoder.layers.18.self_attn.q_proj.weight\", \"model.decoder.layers.18.self_attn.q_proj.bias\", \"model.decoder.layers.18.self_attn.out_proj.weight\", \"model.decoder.layers.18.self_attn.out_proj.bias\", \"model.decoder.layers.18.self_attn_layer_norm.weight\", \"model.decoder.layers.18.self_attn_layer_norm.bias\", \"model.decoder.layers.18.fc1.weight\", \"model.decoder.layers.18.fc1.bias\", \"model.decoder.layers.18.fc2.weight\", \"model.decoder.layers.18.fc2.bias\", \"model.decoder.layers.18.final_layer_norm.weight\", \"model.decoder.layers.18.final_layer_norm.bias\", \"model.decoder.layers.19.self_attn.k_proj.weight\", \"model.decoder.layers.19.self_attn.k_proj.bias\", \"model.decoder.layers.19.self_attn.v_proj.weight\", \"model.decoder.layers.19.self_attn.v_proj.bias\", \"model.decoder.layers.19.self_attn.q_proj.weight\", \"model.decoder.layers.19.self_attn.q_proj.bias\", \"model.decoder.layers.19.self_attn.out_proj.weight\", \"model.decoder.layers.19.self_attn.out_proj.bias\", \"model.decoder.layers.19.self_attn_layer_norm.weight\", \"model.decoder.layers.19.self_attn_layer_norm.bias\", \"model.decoder.layers.19.fc1.weight\", \"model.decoder.layers.19.fc1.bias\", \"model.decoder.layers.19.fc2.weight\", \"model.decoder.layers.19.fc2.bias\", \"model.decoder.layers.19.final_layer_norm.weight\", \"model.decoder.layers.19.final_layer_norm.bias\", \"model.decoder.layers.20.self_attn.k_proj.weight\", \"model.decoder.layers.20.self_attn.k_proj.bias\", \"model.decoder.layers.20.self_attn.v_proj.weight\", \"model.decoder.layers.20.self_attn.v_proj.bias\", \"model.decoder.layers.20.self_attn.q_proj.weight\", \"model.decoder.layers.20.self_attn.q_proj.bias\", \"model.decoder.layers.20.self_attn.out_proj.weight\", \"model.decoder.layers.20.self_attn.out_proj.bias\", \"model.decoder.layers.20.self_attn_layer_norm.weight\", \"model.decoder.layers.20.self_attn_layer_norm.bias\", \"model.decoder.layers.20.fc1.weight\", \"model.decoder.layers.20.fc1.bias\", \"model.decoder.layers.20.fc2.weight\", \"model.decoder.layers.20.fc2.bias\", \"model.decoder.layers.20.final_layer_norm.weight\", \"model.decoder.layers.20.final_layer_norm.bias\", \"model.decoder.layers.21.self_attn.k_proj.weight\", \"model.decoder.layers.21.self_attn.k_proj.bias\", \"model.decoder.layers.21.self_attn.v_proj.weight\", \"model.decoder.layers.21.self_attn.v_proj.bias\", \"model.decoder.layers.21.self_attn.q_proj.weight\", \"model.decoder.layers.21.self_attn.q_proj.bias\", \"model.decoder.layers.21.self_attn.out_proj.weight\", \"model.decoder.layers.21.self_attn.out_proj.bias\", \"model.decoder.layers.21.self_attn_layer_norm.weight\", \"model.decoder.layers.21.self_attn_layer_norm.bias\", \"model.decoder.layers.21.fc1.weight\", \"model.decoder.layers.21.fc1.bias\", \"model.decoder.layers.21.fc2.weight\", \"model.decoder.layers.21.fc2.bias\", \"model.decoder.layers.21.final_layer_norm.weight\", \"model.decoder.layers.21.final_layer_norm.bias\", \"model.decoder.layers.22.self_attn.k_proj.weight\", \"model.decoder.layers.22.self_attn.k_proj.bias\", \"model.decoder.layers.22.self_attn.v_proj.weight\", \"model.decoder.layers.22.self_attn.v_proj.bias\", \"model.decoder.layers.22.self_attn.q_proj.weight\", \"model.decoder.layers.22.self_attn.q_proj.bias\", \"model.decoder.layers.22.self_attn.out_proj.weight\", \"model.decoder.layers.22.self_attn.out_proj.bias\", \"model.decoder.layers.22.self_attn_layer_norm.weight\", \"model.decoder.layers.22.self_attn_layer_norm.bias\", \"model.decoder.layers.22.fc1.weight\", \"model.decoder.layers.22.fc1.bias\", \"model.decoder.layers.22.fc2.weight\", \"model.decoder.layers.22.fc2.bias\", \"model.decoder.layers.22.final_layer_norm.weight\", \"model.decoder.layers.22.final_layer_norm.bias\", \"model.decoder.layers.23.self_attn.k_proj.weight\", \"model.decoder.layers.23.self_attn.k_proj.bias\", \"model.decoder.layers.23.self_attn.v_proj.weight\", \"model.decoder.layers.23.self_attn.v_proj.bias\", \"model.decoder.layers.23.self_attn.q_proj.weight\", \"model.decoder.layers.23.self_attn.q_proj.bias\", \"model.decoder.layers.23.self_attn.out_proj.weight\", \"model.decoder.layers.23.self_attn.out_proj.bias\", \"model.decoder.layers.23.self_attn_layer_norm.weight\", \"model.decoder.layers.23.self_attn_layer_norm.bias\", \"model.decoder.layers.23.fc1.weight\", \"model.decoder.layers.23.fc1.bias\", \"model.decoder.layers.23.fc2.weight\", \"model.decoder.layers.23.fc2.bias\", \"model.decoder.layers.23.final_layer_norm.weight\", \"model.decoder.layers.23.final_layer_norm.bias\", \"lm_head.weight\". \n\tUnexpected key(s) in state_dict: \"encoder_hash_tok_embedding.0.weight\", \"encoder_hash_tok_embedding.1.weight\", \"encoder_hash_tok_embedding.2.weight\", \"encoder_hash_tok_embedding.3.weight\", \"encoder_hash_tok_embedding.4.weight\", \"encoder_hash_tok_embedding.5.weight\", \"global_transformer.layers.0.attention.wk.weight\", \"global_transformer.layers.0.attention.wo.weight\", \"global_transformer.layers.0.attention.wq.weight\", \"global_transformer.layers.0.attention.wv.weight\", \"global_transformer.layers.0.attention_norm.weight\", \"global_transformer.layers.0.feed_forward.w1.weight\", \"global_transformer.layers.0.feed_forward.w2.weight\", \"global_transformer.layers.0.feed_forward.w3.weight\", \"global_transformer.layers.0.ffn_norm.weight\", \"global_transformer.layers.1.attention.wk.weight\", \"global_transformer.layers.1.attention.wo.weight\", \"global_transformer.layers.1.attention.wq.weight\", \"global_transformer.layers.1.attention.wv.weight\", \"global_transformer.layers.1.attention_norm.weight\", \"global_transformer.layers.1.feed_forward.w1.weight\", \"global_transformer.layers.1.feed_forward.w2.weight\", \"global_transformer.layers.1.feed_forward.w3.weight\", \"global_transformer.layers.1.ffn_norm.weight\", \"global_transformer.layers.10.attention.wk.weight\", \"global_transformer.layers.10.attention.wo.weight\", \"global_transformer.layers.10.attention.wq.weight\", \"global_transformer.layers.10.attention.wv.weight\", \"global_transformer.layers.10.attention_norm.weight\", \"global_transformer.layers.10.feed_forward.w1.weight\", \"global_transformer.layers.10.feed_forward.w2.weight\", \"global_transformer.layers.10.feed_forward.w3.weight\", \"global_transformer.layers.10.ffn_norm.weight\", \"global_transformer.layers.11.attention.wk.weight\", \"global_transformer.layers.11.attention.wo.weight\", \"global_transformer.layers.11.attention.wq.weight\", \"global_transformer.layers.11.attention.wv.weight\", \"global_transformer.layers.11.attention_norm.weight\", \"global_transformer.layers.11.feed_forward.w1.weight\", \"global_transformer.layers.11.feed_forward.w2.weight\", \"global_transformer.layers.11.feed_forward.w3.weight\", \"global_transformer.layers.11.ffn_norm.weight\", \"global_transformer.layers.12.attention.wk.weight\", \"global_transformer.layers.12.attention.wo.weight\", \"global_transformer.layers.12.attention.wq.weight\", \"global_transformer.layers.12.attention.wv.weight\", \"global_transformer.layers.12.attention_norm.weight\", \"global_transformer.layers.12.feed_forward.w1.weight\", \"global_transformer.layers.12.feed_forward.w2.weight\", \"global_transformer.layers.12.feed_forward.w3.weight\", \"global_transformer.layers.12.ffn_norm.weight\", \"global_transformer.layers.13.attention.wk.weight\", \"global_transformer.layers.13.attention.wo.weight\", \"global_transformer.layers.13.attention.wq.weight\", \"global_transformer.layers.13.attention.wv.weight\", \"global_transformer.layers.13.attention_norm.weight\", \"global_transformer.layers.13.feed_forward.w1.weight\", \"global_transformer.layers.13.feed_forward.w2.weight\", \"global_transformer.layers.13.feed_forward.w3.weight\", \"global_transformer.layers.13.ffn_norm.weight\", \"global_transformer.layers.14.attention.wk.weight\", \"global_transformer.layers.14.attention.wo.weight\", \"global_transformer.layers.14.attention.wq.weight\", \"global_transformer.layers.14.attention.wv.weight\", \"global_transformer.layers.14.attention_norm.weight\", \"global_transformer.layers.14.feed_forward.w1.weight\", \"global_transformer.layers.14.feed_forward.w2.weight\", \"global_transformer.layers.14.feed_forward.w3.weight\", \"global_transformer.layers.14.ffn_norm.weight\", \"global_transformer.layers.15.attention.wk.weight\", \"global_transformer.layers.15.attention.wo.weight\", \"global_transformer.layers.15.attention.wq.weight\", \"global_transformer.layers.15.attention.wv.weight\", \"global_transformer.layers.15.attention_norm.weight\", \"global_transformer.layers.15.feed_forward.w1.weight\", \"global_transformer.layers.15.feed_forward.w2.weight\", \"global_transformer.layers.15.feed_forward.w3.weight\", \"global_transformer.layers.15.ffn_norm.weight\", \"global_transformer.layers.16.attention.wk.weight\", \"global_transformer.layers.16.attention.wo.weight\", \"global_transformer.layers.16.attention.wq.weight\", \"global_transformer.layers.16.attention.wv.weight\", \"global_transformer.layers.16.attention_norm.weight\", \"global_transformer.layers.16.feed_forward.w1.weight\", \"global_transformer.layers.16.feed_forward.w2.weight\", \"global_transformer.layers.16.feed_forward.w3.weight\", \"global_transformer.layers.16.ffn_norm.weight\", \"global_transformer.layers.17.attention.wk.weight\", \"global_transformer.layers.17.attention.wo.weight\", \"global_transformer.layers.17.attention.wq.weight\", \"global_transformer.layers.17.attention.wv.weight\", \"global_transformer.layers.17.attention_norm.weight\", \"global_transformer.layers.17.feed_forward.w1.weight\", \"global_transformer.layers.17.feed_forward.w2.weight\", \"global_transformer.layers.17.feed_forward.w3.weight\", \"global_transformer.layers.17.ffn_norm.weight\", \"global_transformer.layers.18.attention.wk.weight\", \"global_transformer.layers.18.attention.wo.weight\", \"global_transformer.layers.18.attention.wq.weight\", \"global_transformer.layers.18.attention.wv.weight\", \"global_transformer.layers.18.attention_norm.weight\", \"global_transformer.layers.18.feed_forward.w1.weight\", \"global_transformer.layers.18.feed_forward.w2.weight\", \"global_transformer.layers.18.feed_forward.w3.weight\", \"global_transformer.layers.18.ffn_norm.weight\", \"global_transformer.layers.19.attention.wk.weight\", \"global_transformer.layers.19.attention.wo.weight\", \"global_transformer.layers.19.attention.wq.weight\", \"global_transformer.layers.19.attention.wv.weight\", \"global_transformer.layers.19.attention_norm.weight\", \"global_transformer.layers.19.feed_forward.w1.weight\", \"global_transformer.layers.19.feed_forward.w2.weight\", \"global_transformer.layers.19.feed_forward.w3.weight\", \"global_transformer.layers.19.ffn_norm.weight\", \"global_transformer.layers.2.attention.wk.weight\", \"global_transformer.layers.2.attention.wo.weight\", \"global_transformer.layers.2.attention.wq.weight\", \"global_transformer.layers.2.attention.wv.weight\", \"global_transformer.layers.2.attention_norm.weight\", \"global_transformer.layers.2.feed_forward.w1.weight\", \"global_transformer.layers.2.feed_forward.w2.weight\", \"global_transformer.layers.2.feed_forward.w3.weight\", \"global_transformer.layers.2.ffn_norm.weight\", \"global_transformer.layers.20.attention.wk.weight\", \"global_transformer.layers.20.attention.wo.weight\", \"global_transformer.layers.20.attention.wq.weight\", \"global_transformer.layers.20.attention.wv.weight\", \"global_transformer.layers.20.attention_norm.weight\", \"global_transformer.layers.20.feed_forward.w1.weight\", \"global_transformer.layers.20.feed_forward.w2.weight\", \"global_transformer.layers.20.feed_forward.w3.weight\", \"global_transformer.layers.20.ffn_norm.weight\", \"global_transformer.layers.21.attention.wk.weight\", \"global_transformer.layers.21.attention.wo.weight\", \"global_transformer.layers.21.attention.wq.weight\", \"global_transformer.layers.21.attention.wv.weight\", \"global_transformer.layers.21.attention_norm.weight\", \"global_transformer.layers.21.feed_forward.w1.weight\", \"global_transformer.layers.21.feed_forward.w2.weight\", \"global_transformer.layers.21.feed_forward.w3.weight\", \"global_transformer.layers.21.ffn_norm.weight\", \"global_transformer.layers.22.attention.wk.weight\", \"global_transformer.layers.22.attention.wo.weight\", \"global_transformer.layers.22.attention.wq.weight\", \"global_transformer.layers.22.attention.wv.weight\", \"global_transformer.layers.22.attention_norm.weight\", \"global_transformer.layers.22.feed_forward.w1.weight\", \"global_transformer.layers.22.feed_forward.w2.weight\", \"global_transformer.layers.22.feed_forward.w3.weight\", \"global_transformer.layers.22.ffn_norm.weight\", \"global_transformer.layers.23.attention.wk.weight\", \"global_transformer.layers.23.attention.wo.weight\", \"global_transformer.layers.23.attention.wq.weight\", \"global_transformer.layers.23.attention.wv.weight\", \"global_transformer.layers.23.attention_norm.weight\", \"global_transformer.layers.23.feed_forward.w1.weight\", \"global_transformer.layers.23.feed_forward.w2.weight\", \"global_transformer.layers.23.feed_forward.w3.weight\", \"global_transformer.layers.23.ffn_norm.weight\", \"global_transformer.layers.24.attention.wk.weight\", \"global_transformer.layers.24.attention.wo.weight\", \"global_transformer.layers.24.attention.wq.weight\", \"global_transformer.layers.24.attention.wv.weight\", \"global_transformer.layers.24.attention_norm.weight\", \"global_transformer.layers.24.feed_forward.w1.weight\", \"global_transformer.layers.24.feed_forward.w2.weight\", \"global_transformer.layers.24.feed_forward.w3.weight\", \"global_transformer.layers.24.ffn_norm.weight\", \"global_transformer.layers.3.attention.wk.weight\", \"global_transformer.layers.3.attention.wo.weight\", \"global_transformer.layers.3.attention.wq.weight\", \"global_transformer.layers.3.attention.wv.weight\", \"global_transformer.layers.3.attention_norm.weight\", \"global_transformer.layers.3.feed_forward.w1.weight\", \"global_transformer.layers.3.feed_forward.w2.weight\", \"global_transformer.layers.3.feed_forward.w3.weight\", \"global_transformer.layers.3.ffn_norm.weight\", \"global_transformer.layers.4.attention.wk.weight\", \"global_transformer.layers.4.attention.wo.weight\", \"global_transformer.layers.4.attention.wq.weight\", \"global_transformer.layers.4.attention.wv.weight\", \"global_transformer.layers.4.attention_norm.weight\", \"global_transformer.layers.4.feed_forward.w1.weight\", \"global_transformer.layers.4.feed_forward.w2.weight\", \"global_transformer.layers.4.feed_forward.w3.weight\", \"global_transformer.layers.4.ffn_norm.weight\", \"global_transformer.layers.5.attention.wk.weight\", \"global_transformer.layers.5.attention.wo.weight\", \"global_transformer.layers.5.attention.wq.weight\", \"global_transformer.layers.5.attention.wv.weight\", \"global_transformer.layers.5.attention_norm.weight\", \"global_transformer.layers.5.feed_forward.w1.weight\", \"global_transformer.layers.5.feed_forward.w2.weight\", \"global_transformer.layers.5.feed_forward.w3.weight\", \"global_transformer.layers.5.ffn_norm.weight\", \"global_transformer.layers.6.attention.wk.weight\", \"global_transformer.layers.6.attention.wo.weight\", \"global_transformer.layers.6.attention.wq.weight\", \"global_transformer.layers.6.attention.wv.weight\", \"global_transformer.layers.6.attention_norm.weight\", \"global_transformer.layers.6.feed_forward.w1.weight\", \"global_transformer.layers.6.feed_forward.w2.weight\", \"global_transformer.layers.6.feed_forward.w3.weight\", \"global_transformer.layers.6.ffn_norm.weight\", \"global_transformer.layers.7.attention.wk.weight\", \"global_transformer.layers.7.attention.wo.weight\", \"global_transformer.layers.7.attention.wq.weight\", \"global_transformer.layers.7.attention.wv.weight\", \"global_transformer.layers.7.attention_norm.weight\", \"global_transformer.layers.7.feed_forward.w1.weight\", \"global_transformer.layers.7.feed_forward.w2.weight\", \"global_transformer.layers.7.feed_forward.w3.weight\", \"global_transformer.layers.7.ffn_norm.weight\", \"global_transformer.layers.8.attention.wk.weight\", \"global_transformer.layers.8.attention.wo.weight\", \"global_transformer.layers.8.attention.wq.weight\", \"global_transformer.layers.8.attention.wv.weight\", \"global_transformer.layers.8.attention_norm.weight\", \"global_transformer.layers.8.feed_forward.w1.weight\", \"global_transformer.layers.8.feed_forward.w2.weight\", \"global_transformer.layers.8.feed_forward.w3.weight\", \"global_transformer.layers.8.ffn_norm.weight\", \"global_transformer.layers.9.attention.wk.weight\", \"global_transformer.layers.9.attention.wo.weight\", \"global_transformer.layers.9.attention.wq.weight\", \"global_transformer.layers.9.attention.wv.weight\", \"global_transformer.layers.9.attention_norm.weight\", \"global_transformer.layers.9.feed_forward.w1.weight\", \"global_transformer.layers.9.feed_forward.w2.weight\", \"global_transformer.layers.9.feed_forward.w3.weight\", \"global_transformer.layers.9.ffn_norm.weight\", \"local_decoder.cross_attn_layers.0.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.0.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.0.wk.weight\", \"local_decoder.cross_attn_layers.0.wo.weight\", \"local_decoder.cross_attn_layers.0.wq.weight\", \"local_decoder.cross_attn_layers.0.wv.weight\", \"local_decoder.cross_attn_layers.1.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.1.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.1.wk.weight\", \"local_decoder.cross_attn_layers.1.wo.weight\", \"local_decoder.cross_attn_layers.1.wq.weight\", \"local_decoder.cross_attn_layers.1.wv.weight\", \"local_decoder.cross_attn_layers.2.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.2.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.2.wk.weight\", \"local_decoder.cross_attn_layers.2.wo.weight\", \"local_decoder.cross_attn_layers.2.wq.weight\", \"local_decoder.cross_attn_layers.2.wv.weight\", \"local_decoder.cross_attn_layers.3.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.3.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.3.wk.weight\", \"local_decoder.cross_attn_layers.3.wo.weight\", \"local_decoder.cross_attn_layers.3.wq.weight\", \"local_decoder.cross_attn_layers.3.wv.weight\", \"local_decoder.cross_attn_layers.4.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.4.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.4.wk.weight\", \"local_decoder.cross_attn_layers.4.wo.weight\", \"local_decoder.cross_attn_layers.4.wq.weight\", \"local_decoder.cross_attn_layers.4.wv.weight\", \"local_decoder.cross_attn_layers.5.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.5.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.5.wk.weight\", \"local_decoder.cross_attn_layers.5.wo.weight\", \"local_decoder.cross_attn_layers.5.wq.weight\", \"local_decoder.cross_attn_layers.5.wv.weight\", \"local_decoder.cross_attn_layers.6.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.6.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.6.wk.weight\", \"local_decoder.cross_attn_layers.6.wo.weight\", \"local_decoder.cross_attn_layers.6.wq.weight\", \"local_decoder.cross_attn_layers.6.wv.weight\", \"local_decoder.cross_attn_layers.7.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.7.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.7.wk.weight\", \"local_decoder.cross_attn_layers.7.wo.weight\", \"local_decoder.cross_attn_layers.7.wq.weight\", \"local_decoder.cross_attn_layers.7.wv.weight\", \"local_decoder.cross_attn_layers.8.cross_attn_norm_kv.weight\", \"local_decoder.cross_attn_layers.8.cross_attn_norm_q.weight\", \"local_decoder.cross_attn_layers.8.wk.weight\", \"local_decoder.cross_attn_layers.8.wo.weight\", \"local_decoder.cross_attn_layers.8.wq.weight\", \"local_decoder.cross_attn_layers.8.wv.weight\", \"local_decoder.layers.0.attention.wk.weight\", \"local_decoder.layers.0.attention.wo.weight\", \"local_decoder.layers.0.attention.wq.weight\", \"local_decoder.layers.0.attention.wv.weight\", \"local_decoder.layers.0.attention_norm.weight\", \"local_decoder.layers.0.feed_forward.w1.weight\", \"local_decoder.layers.0.feed_forward.w2.weight\", \"local_decoder.layers.0.feed_forward.w3.weight\", \"local_decoder.layers.0.ffn_norm.weight\", \"local_decoder.layers.1.attention.wk.weight\", \"local_decoder.layers.1.attention.wo.weight\", \"local_decoder.layers.1.attention.wq.weight\", \"local_decoder.layers.1.attention.wv.weight\", \"local_decoder.layers.1.attention_norm.weight\", \"local_decoder.layers.1.feed_forward.w1.weight\", \"local_decoder.layers.1.feed_forward.w2.weight\", \"local_decoder.layers.1.feed_forward.w3.weight\", \"local_decoder.layers.1.ffn_norm.weight\", \"local_decoder.layers.2.attention.wk.weight\", \"local_decoder.layers.2.attention.wo.weight\", \"local_decoder.layers.2.attention.wq.weight\", \"local_decoder.layers.2.attention.wv.weight\", \"local_decoder.layers.2.attention_norm.weight\", \"local_decoder.layers.2.feed_forward.w1.weight\", \"local_decoder.layers.2.feed_forward.w2.weight\", \"local_decoder.layers.2.feed_forward.w3.weight\", \"local_decoder.layers.2.ffn_norm.weight\", \"local_decoder.layers.3.attention.wk.weight\", \"local_decoder.layers.3.attention.wo.weight\", \"local_decoder.layers.3.attention.wq.weight\", \"local_decoder.layers.3.attention.wv.weight\", \"local_decoder.layers.3.attention_norm.weight\", \"local_decoder.layers.3.feed_forward.w1.weight\", \"local_decoder.layers.3.feed_forward.w2.weight\", \"local_decoder.layers.3.feed_forward.w3.weight\", \"local_decoder.layers.3.ffn_norm.weight\", \"local_decoder.layers.4.attention.wk.weight\", \"local_decoder.layers.4.attention.wo.weight\", \"local_decoder.layers.4.attention.wq.weight\", \"local_decoder.layers.4.attention.wv.weight\", \"local_decoder.layers.4.attention_norm.weight\", \"local_decoder.layers.4.feed_forward.w1.weight\", \"local_decoder.layers.4.feed_forward.w2.weight\", \"local_decoder.layers.4.feed_forward.w3.weight\", \"local_decoder.layers.4.ffn_norm.weight\", \"local_decoder.layers.5.attention.wk.weight\", \"local_decoder.layers.5.attention.wo.weight\", \"local_decoder.layers.5.attention.wq.weight\", \"local_decoder.layers.5.attention.wv.weight\", \"local_decoder.layers.5.attention_norm.weight\", \"local_decoder.layers.5.feed_forward.w1.weight\", \"local_decoder.layers.5.feed_forward.w2.weight\", \"local_decoder.layers.5.feed_forward.w3.weight\", \"local_decoder.layers.5.ffn_norm.weight\", \"local_decoder.layers.6.attention.wk.weight\", \"local_decoder.layers.6.attention.wo.weight\", \"local_decoder.layers.6.attention.wq.weight\", \"local_decoder.layers.6.attention.wv.weight\", \"local_decoder.layers.6.attention_norm.weight\", \"local_decoder.layers.6.feed_forward.w1.weight\", \"local_decoder.layers.6.feed_forward.w2.weight\", \"local_decoder.layers.6.feed_forward.w3.weight\", \"local_decoder.layers.6.ffn_norm.weight\", \"local_decoder.layers.7.attention.wk.weight\", \"local_decoder.layers.7.attention.wo.weight\", \"local_decoder.layers.7.attention.wq.weight\", \"local_decoder.layers.7.attention.wv.weight\", \"local_decoder.layers.7.attention_norm.weight\", \"local_decoder.layers.7.feed_forward.w1.weight\", \"local_decoder.layers.7.feed_forward.w2.weight\", \"local_decoder.layers.7.feed_forward.w3.weight\", \"local_decoder.layers.7.ffn_norm.weight\", \"local_decoder.layers.8.attention.wk.weight\", \"local_decoder.layers.8.attention.wo.weight\", \"local_decoder.layers.8.attention.wq.weight\", \"local_decoder.layers.8.attention.wv.weight\", \"local_decoder.layers.8.attention_norm.weight\", \"local_decoder.layers.8.feed_forward.w1.weight\", \"local_decoder.layers.8.feed_forward.w2.weight\", \"local_decoder.layers.8.feed_forward.w3.weight\", \"local_decoder.layers.8.ffn_norm.weight\", \"local_decoder.norm.weight\", \"local_decoder.output.weight\", \"local_decoder.patch_embedding_projection.weight\", \"local_encoder.cross_attn_layers.0.cross_attn_norm_kv.weight\", \"local_encoder.cross_attn_layers.0.cross_attn_norm_q.weight\", \"local_encoder.cross_attn_layers.0.wk.weight\", \"local_encoder.cross_attn_layers.0.wo.weight\", \"local_encoder.cross_attn_layers.0.wq.weight\", \"local_encoder.cross_attn_layers.0.wv.weight\", \"local_encoder.layers.0.attention.wk.weight\", \"local_encoder.layers.0.attention.wo.weight\", \"local_encoder.layers.0.attention.wq.weight\", \"local_encoder.layers.0.attention.wv.weight\", \"local_encoder.layers.0.attention_norm.weight\", \"local_encoder.layers.0.feed_forward.w1.weight\", \"local_encoder.layers.0.feed_forward.w2.weight\", \"local_encoder.layers.0.feed_forward.w3.weight\", \"local_encoder.layers.0.ffn_norm.weight\", \"local_encoder.patch_embedding_projection.weight\", \"local_encoder.tok_embeddings.weight\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ec3e2517a4f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Now load the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for OPTForCausalLM:\n\tMissing key(s) in state_dict: \"model.decoder.embed_tokens.weight\", \"model.decoder.embed_positions.weight\", \"model.decoder.project_out.weight\", \"model.decoder.project_in.weight\", \"model.decoder.layers.0.self_attn.k_proj.weight\", \"model.decoder.layers.0.self_attn.k_proj.bias\", \"model.decoder.layers.0.self_attn.v_proj.weight\", \"model.decoder.layers.0.self_attn.v_proj.bias\", \"model.decoder.layers.0.self_attn.q_proj.weight\", \"model.decoder.layers.0.self_attn.q_proj.bias\", \"model.decoder.layers.0.self_attn.out_proj.weight\", \"model.decoder.layers.0.self_attn.out_proj.bias\", \"model.decoder.layers.0.self_attn_layer_norm.weight\", \"model.decoder.layers.0.self_attn_layer_norm.bias\", \"model.decoder.layers.0.fc1.weight\", \"model.decoder.layers.0.fc1.bias\", \"model.decoder.layers.0.fc2.weight\", \"model.decoder.layers.0.fc2.bias\", \"model.decoder.layers.0.final_layer_norm.weight\", \"model.decoder.layers.0.final_layer_norm.bias\", \"model.decoder.layers.1.self_attn.k_proj.weight\", \"model.decoder.layers.1.self_attn.k_proj.bias\", \"model.decoder.layers.1.self_attn.v_proj.weight\", \"model.decoder.layers.1.self_attn.v_proj.bias\", \"model.decoder.layers.1.self_attn.q_proj.weight\", \"model.decoder.layers.1.self_attn.q_proj.bias\", \"model.decoder.layers.1.self_attn.out_proj.weight\", \"model.decoder.layers.1.self_attn.out_proj.bias\", \"model.decoder.layers.1.self_attn_layer_norm.weight\", \"model.decoder.layers.1.self_attn_layer_norm.bias\", \"model.decoder.layers.1.fc1.weight\", \"model.decoder.layers.1.fc1.bias\", ...\n\tUnexpected key(s) in state_dict: \"encoder_hash_tok_embedding.0.weight\", \"encoder_hash_tok_embedding.1.weight\", \"encoder_hash_tok_embedding.2.weight\", \"encoder_hash_tok_embedding.3.weight\", \"encoder_hash_tok_embedding.4.weight\", \"encoder_hash_tok_embedding.5.weight\", \"global_transformer.layers.0.attention.wk.weight\", \"global_transformer.layers.0.attention.wo.weight\", \"global_transformer.layers.0.attention.wq.weight\", \"global_transformer.layers.0.attention.wv.weight\", \"global_transformer.layers.0.attention_norm.weight\", \"global_transformer.layers.0.feed_forward.w1.weight\", \"global_transformer.layers.0.feed_forward.w2.weight\", \"global_transformer.layers.0.feed_forward.w3.weight\", \"global_transformer.layers.0.ffn_norm.weight\", \"global_transformer.layers.1.attention.wk.weight\", \"global_transformer.layers.1.attention.wo.weight\", \"global_transformer.layers.1.attention.wq.weight\", \"global_transformer.layers.1.attention.wv.weight\", \"global_transformer.layers.1.attention_norm.weight\", \"global_transformer.layers.1.feed_forward.w1.weight\", \"global_transformer.layers.1.feed_forward.w2.weight\", \"global_transformer.layers.1.feed_forward.w3.weight\", \"global_transformer.layers.1.ffn_norm.weight\", \"global_transformer.layers.10.attention.wk.weight\", \"global_transformer.layers.10.attention.wo.weight\", \"global_transformer.layers.10.attention.wq.weight\", \"global_transformer.layers.10.attention.wv.weight\", \"global_transformer.layers.10.attention_norm.weight\", \"global_transformer.layers.10.feed_..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSz7MYFZxAPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BloomForCausalLM\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Define and initialize the model using BloomForCausalLM\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "\n",
        "# Now load the weights, using strict=False to ignore mismatched keys\n",
        "model.load_state_dict(model_weights, strict=False)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "77f471e5fd7740dbb24be36fc5454f47",
            "bcfda591b71f4bbdbe1b5b42c7249f4e",
            "7029c1cf5f334a23858b3c327ec6d092",
            "dbc088d308f3490fae85fb36f300caf7",
            "00a74ba2c8cf4023b39648e9c1c4d8fb",
            "6843d3f27ea84ad8bc484bfb692c57f1",
            "5af922a87bf1446499f6ca851c961c6e",
            "03f04dc8f6874d83917465cc54fe5340",
            "aece4236eb144e00a8dbefc08ce40cf4",
            "69fbc99b54914aad83634b4ddc3dcc98",
            "5b1343ad068947809b857848aaf9818e",
            "eb95701d0d8146ada10dbb3de7cda519",
            "ceeadcf920eb4c51861d8c865affdb60",
            "de294bfbba604d68a739db3b72e73379",
            "14b6964c771646f38f00915a1164df17",
            "205bb7b50e0f4c27998a3cbaf4ec1ef8",
            "230fc155266440df97d51b63d7e6432e",
            "82a6d34c456d4a04b5513f627b4e4e9c",
            "929090e773f8432ab9af59420235c08b",
            "4221dd8b0bed410ba8c88123d25b0dc5",
            "3f4fbf0e14d54867bda9f49ef8cc2d2b",
            "d490dc4551684169beced0f6fbfebe97"
          ]
        },
        "id": "EyAyrawRxAnf",
        "outputId": "8b8baaa4-b3bd-47d2-d1bb-6a7b187f764e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77f471e5fd7740dbb24be36fc5454f47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb95701d0d8146ada10dbb3de7cda519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['transformer.word_embeddings.weight', 'transformer.word_embeddings_layernorm.weight', 'transformer.word_embeddings_layernorm.bias', 'transformer.h.0.input_layernorm.weight', 'transformer.h.0.input_layernorm.bias', 'transformer.h.0.self_attention.query_key_value.weight', 'transformer.h.0.self_attention.query_key_value.bias', 'transformer.h.0.self_attention.dense.weight', 'transformer.h.0.self_attention.dense.bias', 'transformer.h.0.post_attention_layernorm.weight', 'transformer.h.0.post_attention_layernorm.bias', 'transformer.h.0.mlp.dense_h_to_4h.weight', 'transformer.h.0.mlp.dense_h_to_4h.bias', 'transformer.h.0.mlp.dense_4h_to_h.weight', 'transformer.h.0.mlp.dense_4h_to_h.bias', 'transformer.h.1.input_layernorm.weight', 'transformer.h.1.input_layernorm.bias', 'transformer.h.1.self_attention.query_key_value.weight', 'transformer.h.1.self_attention.query_key_value.bias', 'transformer.h.1.self_attention.dense.weight', 'transformer.h.1.self_attention.dense.bias', 'transformer.h.1.post_attention_layernorm.weight', 'transformer.h.1.post_attention_layernorm.bias', 'transformer.h.1.mlp.dense_h_to_4h.weight', 'transformer.h.1.mlp.dense_h_to_4h.bias', 'transformer.h.1.mlp.dense_4h_to_h.weight', 'transformer.h.1.mlp.dense_4h_to_h.bias', 'transformer.h.2.input_layernorm.weight', 'transformer.h.2.input_layernorm.bias', 'transformer.h.2.self_attention.query_key_value.weight', 'transformer.h.2.self_attention.query_key_value.bias', 'transformer.h.2.self_attention.dense.weight', 'transformer.h.2.self_attention.dense.bias', 'transformer.h.2.post_attention_layernorm.weight', 'transformer.h.2.post_attention_layernorm.bias', 'transformer.h.2.mlp.dense_h_to_4h.weight', 'transformer.h.2.mlp.dense_h_to_4h.bias', 'transformer.h.2.mlp.dense_4h_to_h.weight', 'transformer.h.2.mlp.dense_4h_to_h.bias', 'transformer.h.3.input_layernorm.weight', 'transformer.h.3.input_layernorm.bias', 'transformer.h.3.self_attention.query_key_value.weight', 'transformer.h.3.self_attention.query_key_value.bias', 'transformer.h.3.self_attention.dense.weight', 'transformer.h.3.self_attention.dense.bias', 'transformer.h.3.post_attention_layernorm.weight', 'transformer.h.3.post_attention_layernorm.bias', 'transformer.h.3.mlp.dense_h_to_4h.weight', 'transformer.h.3.mlp.dense_h_to_4h.bias', 'transformer.h.3.mlp.dense_4h_to_h.weight', 'transformer.h.3.mlp.dense_4h_to_h.bias', 'transformer.h.4.input_layernorm.weight', 'transformer.h.4.input_layernorm.bias', 'transformer.h.4.self_attention.query_key_value.weight', 'transformer.h.4.self_attention.query_key_value.bias', 'transformer.h.4.self_attention.dense.weight', 'transformer.h.4.self_attention.dense.bias', 'transformer.h.4.post_attention_layernorm.weight', 'transformer.h.4.post_attention_layernorm.bias', 'transformer.h.4.mlp.dense_h_to_4h.weight', 'transformer.h.4.mlp.dense_h_to_4h.bias', 'transformer.h.4.mlp.dense_4h_to_h.weight', 'transformer.h.4.mlp.dense_4h_to_h.bias', 'transformer.h.5.input_layernorm.weight', 'transformer.h.5.input_layernorm.bias', 'transformer.h.5.self_attention.query_key_value.weight', 'transformer.h.5.self_attention.query_key_value.bias', 'transformer.h.5.self_attention.dense.weight', 'transformer.h.5.self_attention.dense.bias', 'transformer.h.5.post_attention_layernorm.weight', 'transformer.h.5.post_attention_layernorm.bias', 'transformer.h.5.mlp.dense_h_to_4h.weight', 'transformer.h.5.mlp.dense_h_to_4h.bias', 'transformer.h.5.mlp.dense_4h_to_h.weight', 'transformer.h.5.mlp.dense_4h_to_h.bias', 'transformer.h.6.input_layernorm.weight', 'transformer.h.6.input_layernorm.bias', 'transformer.h.6.self_attention.query_key_value.weight', 'transformer.h.6.self_attention.query_key_value.bias', 'transformer.h.6.self_attention.dense.weight', 'transformer.h.6.self_attention.dense.bias', 'transformer.h.6.post_attention_layernorm.weight', 'transformer.h.6.post_attention_layernorm.bias', 'transformer.h.6.mlp.dense_h_to_4h.weight', 'transformer.h.6.mlp.dense_h_to_4h.bias', 'transformer.h.6.mlp.dense_4h_to_h.weight', 'transformer.h.6.mlp.dense_4h_to_h.bias', 'transformer.h.7.input_layernorm.weight', 'transformer.h.7.input_layernorm.bias', 'transformer.h.7.self_attention.query_key_value.weight', 'transformer.h.7.self_attention.query_key_value.bias', 'transformer.h.7.self_attention.dense.weight', 'transformer.h.7.self_attention.dense.bias', 'transformer.h.7.post_attention_layernorm.weight', 'transformer.h.7.post_attention_layernorm.bias', 'transformer.h.7.mlp.dense_h_to_4h.weight', 'transformer.h.7.mlp.dense_h_to_4h.bias', 'transformer.h.7.mlp.dense_4h_to_h.weight', 'transformer.h.7.mlp.dense_4h_to_h.bias', 'transformer.h.8.input_layernorm.weight', 'transformer.h.8.input_layernorm.bias', 'transformer.h.8.self_attention.query_key_value.weight', 'transformer.h.8.self_attention.query_key_value.bias', 'transformer.h.8.self_attention.dense.weight', 'transformer.h.8.self_attention.dense.bias', 'transformer.h.8.post_attention_layernorm.weight', 'transformer.h.8.post_attention_layernorm.bias', 'transformer.h.8.mlp.dense_h_to_4h.weight', 'transformer.h.8.mlp.dense_h_to_4h.bias', 'transformer.h.8.mlp.dense_4h_to_h.weight', 'transformer.h.8.mlp.dense_4h_to_h.bias', 'transformer.h.9.input_layernorm.weight', 'transformer.h.9.input_layernorm.bias', 'transformer.h.9.self_attention.query_key_value.weight', 'transformer.h.9.self_attention.query_key_value.bias', 'transformer.h.9.self_attention.dense.weight', 'transformer.h.9.self_attention.dense.bias', 'transformer.h.9.post_attention_layernorm.weight', 'transformer.h.9.post_attention_layernorm.bias', 'transformer.h.9.mlp.dense_h_to_4h.weight', 'transformer.h.9.mlp.dense_h_to_4h.bias', 'transformer.h.9.mlp.dense_4h_to_h.weight', 'transformer.h.9.mlp.dense_4h_to_h.bias', 'transformer.h.10.input_layernorm.weight', 'transformer.h.10.input_layernorm.bias', 'transformer.h.10.self_attention.query_key_value.weight', 'transformer.h.10.self_attention.query_key_value.bias', 'transformer.h.10.self_attention.dense.weight', 'transformer.h.10.self_attention.dense.bias', 'transformer.h.10.post_attention_layernorm.weight', 'transformer.h.10.post_attention_layernorm.bias', 'transformer.h.10.mlp.dense_h_to_4h.weight', 'transformer.h.10.mlp.dense_h_to_4h.bias', 'transformer.h.10.mlp.dense_4h_to_h.weight', 'transformer.h.10.mlp.dense_4h_to_h.bias', 'transformer.h.11.input_layernorm.weight', 'transformer.h.11.input_layernorm.bias', 'transformer.h.11.self_attention.query_key_value.weight', 'transformer.h.11.self_attention.query_key_value.bias', 'transformer.h.11.self_attention.dense.weight', 'transformer.h.11.self_attention.dense.bias', 'transformer.h.11.post_attention_layernorm.weight', 'transformer.h.11.post_attention_layernorm.bias', 'transformer.h.11.mlp.dense_h_to_4h.weight', 'transformer.h.11.mlp.dense_h_to_4h.bias', 'transformer.h.11.mlp.dense_4h_to_h.weight', 'transformer.h.11.mlp.dense_4h_to_h.bias', 'transformer.h.12.input_layernorm.weight', 'transformer.h.12.input_layernorm.bias', 'transformer.h.12.self_attention.query_key_value.weight', 'transformer.h.12.self_attention.query_key_value.bias', 'transformer.h.12.self_attention.dense.weight', 'transformer.h.12.self_attention.dense.bias', 'transformer.h.12.post_attention_layernorm.weight', 'transformer.h.12.post_attention_layernorm.bias', 'transformer.h.12.mlp.dense_h_to_4h.weight', 'transformer.h.12.mlp.dense_h_to_4h.bias', 'transformer.h.12.mlp.dense_4h_to_h.weight', 'transformer.h.12.mlp.dense_4h_to_h.bias', 'transformer.h.13.input_layernorm.weight', 'transformer.h.13.input_layernorm.bias', 'transformer.h.13.self_attention.query_key_value.weight', 'transformer.h.13.self_attention.query_key_value.bias', 'transformer.h.13.self_attention.dense.weight', 'transformer.h.13.self_attention.dense.bias', 'transformer.h.13.post_attention_layernorm.weight', 'transformer.h.13.post_attention_layernorm.bias', 'transformer.h.13.mlp.dense_h_to_4h.weight', 'transformer.h.13.mlp.dense_h_to_4h.bias', 'transformer.h.13.mlp.dense_4h_to_h.weight', 'transformer.h.13.mlp.dense_4h_to_h.bias', 'transformer.h.14.input_layernorm.weight', 'transformer.h.14.input_layernorm.bias', 'transformer.h.14.self_attention.query_key_value.weight', 'transformer.h.14.self_attention.query_key_value.bias', 'transformer.h.14.self_attention.dense.weight', 'transformer.h.14.self_attention.dense.bias', 'transformer.h.14.post_attention_layernorm.weight', 'transformer.h.14.post_attention_layernorm.bias', 'transformer.h.14.mlp.dense_h_to_4h.weight', 'transformer.h.14.mlp.dense_h_to_4h.bias', 'transformer.h.14.mlp.dense_4h_to_h.weight', 'transformer.h.14.mlp.dense_4h_to_h.bias', 'transformer.h.15.input_layernorm.weight', 'transformer.h.15.input_layernorm.bias', 'transformer.h.15.self_attention.query_key_value.weight', 'transformer.h.15.self_attention.query_key_value.bias', 'transformer.h.15.self_attention.dense.weight', 'transformer.h.15.self_attention.dense.bias', 'transformer.h.15.post_attention_layernorm.weight', 'transformer.h.15.post_attention_layernorm.bias', 'transformer.h.15.mlp.dense_h_to_4h.weight', 'transformer.h.15.mlp.dense_h_to_4h.bias', 'transformer.h.15.mlp.dense_4h_to_h.weight', 'transformer.h.15.mlp.dense_4h_to_h.bias', 'transformer.h.16.input_layernorm.weight', 'transformer.h.16.input_layernorm.bias', 'transformer.h.16.self_attention.query_key_value.weight', 'transformer.h.16.self_attention.query_key_value.bias', 'transformer.h.16.self_attention.dense.weight', 'transformer.h.16.self_attention.dense.bias', 'transformer.h.16.post_attention_layernorm.weight', 'transformer.h.16.post_attention_layernorm.bias', 'transformer.h.16.mlp.dense_h_to_4h.weight', 'transformer.h.16.mlp.dense_h_to_4h.bias', 'transformer.h.16.mlp.dense_4h_to_h.weight', 'transformer.h.16.mlp.dense_4h_to_h.bias', 'transformer.h.17.input_layernorm.weight', 'transformer.h.17.input_layernorm.bias', 'transformer.h.17.self_attention.query_key_value.weight', 'transformer.h.17.self_attention.query_key_value.bias', 'transformer.h.17.self_attention.dense.weight', 'transformer.h.17.self_attention.dense.bias', 'transformer.h.17.post_attention_layernorm.weight', 'transformer.h.17.post_attention_layernorm.bias', 'transformer.h.17.mlp.dense_h_to_4h.weight', 'transformer.h.17.mlp.dense_h_to_4h.bias', 'transformer.h.17.mlp.dense_4h_to_h.weight', 'transformer.h.17.mlp.dense_4h_to_h.bias', 'transformer.h.18.input_layernorm.weight', 'transformer.h.18.input_layernorm.bias', 'transformer.h.18.self_attention.query_key_value.weight', 'transformer.h.18.self_attention.query_key_value.bias', 'transformer.h.18.self_attention.dense.weight', 'transformer.h.18.self_attention.dense.bias', 'transformer.h.18.post_attention_layernorm.weight', 'transformer.h.18.post_attention_layernorm.bias', 'transformer.h.18.mlp.dense_h_to_4h.weight', 'transformer.h.18.mlp.dense_h_to_4h.bias', 'transformer.h.18.mlp.dense_4h_to_h.weight', 'transformer.h.18.mlp.dense_4h_to_h.bias', 'transformer.h.19.input_layernorm.weight', 'transformer.h.19.input_layernorm.bias', 'transformer.h.19.self_attention.query_key_value.weight', 'transformer.h.19.self_attention.query_key_value.bias', 'transformer.h.19.self_attention.dense.weight', 'transformer.h.19.self_attention.dense.bias', 'transformer.h.19.post_attention_layernorm.weight', 'transformer.h.19.post_attention_layernorm.bias', 'transformer.h.19.mlp.dense_h_to_4h.weight', 'transformer.h.19.mlp.dense_h_to_4h.bias', 'transformer.h.19.mlp.dense_4h_to_h.weight', 'transformer.h.19.mlp.dense_4h_to_h.bias', 'transformer.h.20.input_layernorm.weight', 'transformer.h.20.input_layernorm.bias', 'transformer.h.20.self_attention.query_key_value.weight', 'transformer.h.20.self_attention.query_key_value.bias', 'transformer.h.20.self_attention.dense.weight', 'transformer.h.20.self_attention.dense.bias', 'transformer.h.20.post_attention_layernorm.weight', 'transformer.h.20.post_attention_layernorm.bias', 'transformer.h.20.mlp.dense_h_to_4h.weight', 'transformer.h.20.mlp.dense_h_to_4h.bias', 'transformer.h.20.mlp.dense_4h_to_h.weight', 'transformer.h.20.mlp.dense_4h_to_h.bias', 'transformer.h.21.input_layernorm.weight', 'transformer.h.21.input_layernorm.bias', 'transformer.h.21.self_attention.query_key_value.weight', 'transformer.h.21.self_attention.query_key_value.bias', 'transformer.h.21.self_attention.dense.weight', 'transformer.h.21.self_attention.dense.bias', 'transformer.h.21.post_attention_layernorm.weight', 'transformer.h.21.post_attention_layernorm.bias', 'transformer.h.21.mlp.dense_h_to_4h.weight', 'transformer.h.21.mlp.dense_h_to_4h.bias', 'transformer.h.21.mlp.dense_4h_to_h.weight', 'transformer.h.21.mlp.dense_4h_to_h.bias', 'transformer.h.22.input_layernorm.weight', 'transformer.h.22.input_layernorm.bias', 'transformer.h.22.self_attention.query_key_value.weight', 'transformer.h.22.self_attention.query_key_value.bias', 'transformer.h.22.self_attention.dense.weight', 'transformer.h.22.self_attention.dense.bias', 'transformer.h.22.post_attention_layernorm.weight', 'transformer.h.22.post_attention_layernorm.bias', 'transformer.h.22.mlp.dense_h_to_4h.weight', 'transformer.h.22.mlp.dense_h_to_4h.bias', 'transformer.h.22.mlp.dense_4h_to_h.weight', 'transformer.h.22.mlp.dense_4h_to_h.bias', 'transformer.h.23.input_layernorm.weight', 'transformer.h.23.input_layernorm.bias', 'transformer.h.23.self_attention.query_key_value.weight', 'transformer.h.23.self_attention.query_key_value.bias', 'transformer.h.23.self_attention.dense.weight', 'transformer.h.23.self_attention.dense.bias', 'transformer.h.23.post_attention_layernorm.weight', 'transformer.h.23.post_attention_layernorm.bias', 'transformer.h.23.mlp.dense_h_to_4h.weight', 'transformer.h.23.mlp.dense_h_to_4h.bias', 'transformer.h.23.mlp.dense_4h_to_h.weight', 'transformer.h.23.mlp.dense_4h_to_h.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'], unexpected_keys=['encoder_hash_tok_embedding.0.weight', 'encoder_hash_tok_embedding.1.weight', 'encoder_hash_tok_embedding.2.weight', 'encoder_hash_tok_embedding.3.weight', 'encoder_hash_tok_embedding.4.weight', 'encoder_hash_tok_embedding.5.weight', 'global_transformer.layers.0.attention.wk.weight', 'global_transformer.layers.0.attention.wo.weight', 'global_transformer.layers.0.attention.wq.weight', 'global_transformer.layers.0.attention.wv.weight', 'global_transformer.layers.0.attention_norm.weight', 'global_transformer.layers.0.feed_forward.w1.weight', 'global_transformer.layers.0.feed_forward.w2.weight', 'global_transformer.layers.0.feed_forward.w3.weight', 'global_transformer.layers.0.ffn_norm.weight', 'global_transformer.layers.1.attention.wk.weight', 'global_transformer.layers.1.attention.wo.weight', 'global_transformer.layers.1.attention.wq.weight', 'global_transformer.layers.1.attention.wv.weight', 'global_transformer.layers.1.attention_norm.weight', 'global_transformer.layers.1.feed_forward.w1.weight', 'global_transformer.layers.1.feed_forward.w2.weight', 'global_transformer.layers.1.feed_forward.w3.weight', 'global_transformer.layers.1.ffn_norm.weight', 'global_transformer.layers.10.attention.wk.weight', 'global_transformer.layers.10.attention.wo.weight', 'global_transformer.layers.10.attention.wq.weight', 'global_transformer.layers.10.attention.wv.weight', 'global_transformer.layers.10.attention_norm.weight', 'global_transformer.layers.10.feed_forward.w1.weight', 'global_transformer.layers.10.feed_forward.w2.weight', 'global_transformer.layers.10.feed_forward.w3.weight', 'global_transformer.layers.10.ffn_norm.weight', 'global_transformer.layers.11.attention.wk.weight', 'global_transformer.layers.11.attention.wo.weight', 'global_transformer.layers.11.attention.wq.weight', 'global_transformer.layers.11.attention.wv.weight', 'global_transformer.layers.11.attention_norm.weight', 'global_transformer.layers.11.feed_forward.w1.weight', 'global_transformer.layers.11.feed_forward.w2.weight', 'global_transformer.layers.11.feed_forward.w3.weight', 'global_transformer.layers.11.ffn_norm.weight', 'global_transformer.layers.12.attention.wk.weight', 'global_transformer.layers.12.attention.wo.weight', 'global_transformer.layers.12.attention.wq.weight', 'global_transformer.layers.12.attention.wv.weight', 'global_transformer.layers.12.attention_norm.weight', 'global_transformer.layers.12.feed_forward.w1.weight', 'global_transformer.layers.12.feed_forward.w2.weight', 'global_transformer.layers.12.feed_forward.w3.weight', 'global_transformer.layers.12.ffn_norm.weight', 'global_transformer.layers.13.attention.wk.weight', 'global_transformer.layers.13.attention.wo.weight', 'global_transformer.layers.13.attention.wq.weight', 'global_transformer.layers.13.attention.wv.weight', 'global_transformer.layers.13.attention_norm.weight', 'global_transformer.layers.13.feed_forward.w1.weight', 'global_transformer.layers.13.feed_forward.w2.weight', 'global_transformer.layers.13.feed_forward.w3.weight', 'global_transformer.layers.13.ffn_norm.weight', 'global_transformer.layers.14.attention.wk.weight', 'global_transformer.layers.14.attention.wo.weight', 'global_transformer.layers.14.attention.wq.weight', 'global_transformer.layers.14.attention.wv.weight', 'global_transformer.layers.14.attention_norm.weight', 'global_transformer.layers.14.feed_forward.w1.weight', 'global_transformer.layers.14.feed_forward.w2.weight', 'global_transformer.layers.14.feed_forward.w3.weight', 'global_transformer.layers.14.ffn_norm.weight', 'global_transformer.layers.15.attention.wk.weight', 'global_transformer.layers.15.attention.wo.weight', 'global_transformer.layers.15.attention.wq.weight', 'global_transformer.layers.15.attention.wv.weight', 'global_transformer.layers.15.attention_norm.weight', 'global_transformer.layers.15.feed_forward.w1.weight', 'global_transformer.layers.15.feed_forward.w2.weight', 'global_transformer.layers.15.feed_forward.w3.weight', 'global_transformer.layers.15.ffn_norm.weight', 'global_transformer.layers.16.attention.wk.weight', 'global_transformer.layers.16.attention.wo.weight', 'global_transformer.layers.16.attention.wq.weight', 'global_transformer.layers.16.attention.wv.weight', 'global_transformer.layers.16.attention_norm.weight', 'global_transformer.layers.16.feed_forward.w1.weight', 'global_transformer.layers.16.feed_forward.w2.weight', 'global_transformer.layers.16.feed_forward.w3.weight', 'global_transformer.layers.16.ffn_norm.weight', 'global_transformer.layers.17.attention.wk.weight', 'global_transformer.layers.17.attention.wo.weight', 'global_transformer.layers.17.attention.wq.weight', 'global_transformer.layers.17.attention.wv.weight', 'global_transformer.layers.17.attention_norm.weight', 'global_transformer.layers.17.feed_forward.w1.weight', 'global_transformer.layers.17.feed_forward.w2.weight', 'global_transformer.layers.17.feed_forward.w3.weight', 'global_transformer.layers.17.ffn_norm.weight', 'global_transformer.layers.18.attention.wk.weight', 'global_transformer.layers.18.attention.wo.weight', 'global_transformer.layers.18.attention.wq.weight', 'global_transformer.layers.18.attention.wv.weight', 'global_transformer.layers.18.attention_norm.weight', 'global_transformer.layers.18.feed_forward.w1.weight', 'global_transformer.layers.18.feed_forward.w2.weight', 'global_transformer.layers.18.feed_forward.w3.weight', 'global_transformer.layers.18.ffn_norm.weight', 'global_transformer.layers.19.attention.wk.weight', 'global_transformer.layers.19.attention.wo.weight', 'global_transformer.layers.19.attention.wq.weight', 'global_transformer.layers.19.attention.wv.weight', 'global_transformer.layers.19.attention_norm.weight', 'global_transformer.layers.19.feed_forward.w1.weight', 'global_transformer.layers.19.feed_forward.w2.weight', 'global_transformer.layers.19.feed_forward.w3.weight', 'global_transformer.layers.19.ffn_norm.weight', 'global_transformer.layers.2.attention.wk.weight', 'global_transformer.layers.2.attention.wo.weight', 'global_transformer.layers.2.attention.wq.weight', 'global_transformer.layers.2.attention.wv.weight', 'global_transformer.layers.2.attention_norm.weight', 'global_transformer.layers.2.feed_forward.w1.weight', 'global_transformer.layers.2.feed_forward.w2.weight', 'global_transformer.layers.2.feed_forward.w3.weight', 'global_transformer.layers.2.ffn_norm.weight', 'global_transformer.layers.20.attention.wk.weight', 'global_transformer.layers.20.attention.wo.weight', 'global_transformer.layers.20.attention.wq.weight', 'global_transformer.layers.20.attention.wv.weight', 'global_transformer.layers.20.attention_norm.weight', 'global_transformer.layers.20.feed_forward.w1.weight', 'global_transformer.layers.20.feed_forward.w2.weight', 'global_transformer.layers.20.feed_forward.w3.weight', 'global_transformer.layers.20.ffn_norm.weight', 'global_transformer.layers.21.attention.wk.weight', 'global_transformer.layers.21.attention.wo.weight', 'global_transformer.layers.21.attention.wq.weight', 'global_transformer.layers.21.attention.wv.weight', 'global_transformer.layers.21.attention_norm.weight', 'global_transformer.layers.21.feed_forward.w1.weight', 'global_transformer.layers.21.feed_forward.w2.weight', 'global_transformer.layers.21.feed_forward.w3.weight', 'global_transformer.layers.21.ffn_norm.weight', 'global_transformer.layers.22.attention.wk.weight', 'global_transformer.layers.22.attention.wo.weight', 'global_transformer.layers.22.attention.wq.weight', 'global_transformer.layers.22.attention.wv.weight', 'global_transformer.layers.22.attention_norm.weight', 'global_transformer.layers.22.feed_forward.w1.weight', 'global_transformer.layers.22.feed_forward.w2.weight', 'global_transformer.layers.22.feed_forward.w3.weight', 'global_transformer.layers.22.ffn_norm.weight', 'global_transformer.layers.23.attention.wk.weight', 'global_transformer.layers.23.attention.wo.weight', 'global_transformer.layers.23.attention.wq.weight', 'global_transformer.layers.23.attention.wv.weight', 'global_transformer.layers.23.attention_norm.weight', 'global_transformer.layers.23.feed_forward.w1.weight', 'global_transformer.layers.23.feed_forward.w2.weight', 'global_transformer.layers.23.feed_forward.w3.weight', 'global_transformer.layers.23.ffn_norm.weight', 'global_transformer.layers.24.attention.wk.weight', 'global_transformer.layers.24.attention.wo.weight', 'global_transformer.layers.24.attention.wq.weight', 'global_transformer.layers.24.attention.wv.weight', 'global_transformer.layers.24.attention_norm.weight', 'global_transformer.layers.24.feed_forward.w1.weight', 'global_transformer.layers.24.feed_forward.w2.weight', 'global_transformer.layers.24.feed_forward.w3.weight', 'global_transformer.layers.24.ffn_norm.weight', 'global_transformer.layers.3.attention.wk.weight', 'global_transformer.layers.3.attention.wo.weight', 'global_transformer.layers.3.attention.wq.weight', 'global_transformer.layers.3.attention.wv.weight', 'global_transformer.layers.3.attention_norm.weight', 'global_transformer.layers.3.feed_forward.w1.weight', 'global_transformer.layers.3.feed_forward.w2.weight', 'global_transformer.layers.3.feed_forward.w3.weight', 'global_transformer.layers.3.ffn_norm.weight', 'global_transformer.layers.4.attention.wk.weight', 'global_transformer.layers.4.attention.wo.weight', 'global_transformer.layers.4.attention.wq.weight', 'global_transformer.layers.4.attention.wv.weight', 'global_transformer.layers.4.attention_norm.weight', 'global_transformer.layers.4.feed_forward.w1.weight', 'global_transformer.layers.4.feed_forward.w2.weight', 'global_transformer.layers.4.feed_forward.w3.weight', 'global_transformer.layers.4.ffn_norm.weight', 'global_transformer.layers.5.attention.wk.weight', 'global_transformer.layers.5.attention.wo.weight', 'global_transformer.layers.5.attention.wq.weight', 'global_transformer.layers.5.attention.wv.weight', 'global_transformer.layers.5.attention_norm.weight', 'global_transformer.layers.5.feed_forward.w1.weight', 'global_transformer.layers.5.feed_forward.w2.weight', 'global_transformer.layers.5.feed_forward.w3.weight', 'global_transformer.layers.5.ffn_norm.weight', 'global_transformer.layers.6.attention.wk.weight', 'global_transformer.layers.6.attention.wo.weight', 'global_transformer.layers.6.attention.wq.weight', 'global_transformer.layers.6.attention.wv.weight', 'global_transformer.layers.6.attention_norm.weight', 'global_transformer.layers.6.feed_forward.w1.weight', 'global_transformer.layers.6.feed_forward.w2.weight', 'global_transformer.layers.6.feed_forward.w3.weight', 'global_transformer.layers.6.ffn_norm.weight', 'global_transformer.layers.7.attention.wk.weight', 'global_transformer.layers.7.attention.wo.weight', 'global_transformer.layers.7.attention.wq.weight', 'global_transformer.layers.7.attention.wv.weight', 'global_transformer.layers.7.attention_norm.weight', 'global_transformer.layers.7.feed_forward.w1.weight', 'global_transformer.layers.7.feed_forward.w2.weight', 'global_transformer.layers.7.feed_forward.w3.weight', 'global_transformer.layers.7.ffn_norm.weight', 'global_transformer.layers.8.attention.wk.weight', 'global_transformer.layers.8.attention.wo.weight', 'global_transformer.layers.8.attention.wq.weight', 'global_transformer.layers.8.attention.wv.weight', 'global_transformer.layers.8.attention_norm.weight', 'global_transformer.layers.8.feed_forward.w1.weight', 'global_transformer.layers.8.feed_forward.w2.weight', 'global_transformer.layers.8.feed_forward.w3.weight', 'global_transformer.layers.8.ffn_norm.weight', 'global_transformer.layers.9.attention.wk.weight', 'global_transformer.layers.9.attention.wo.weight', 'global_transformer.layers.9.attention.wq.weight', 'global_transformer.layers.9.attention.wv.weight', 'global_transformer.layers.9.attention_norm.weight', 'global_transformer.layers.9.feed_forward.w1.weight', 'global_transformer.layers.9.feed_forward.w2.weight', 'global_transformer.layers.9.feed_forward.w3.weight', 'global_transformer.layers.9.ffn_norm.weight', 'local_decoder.cross_attn_layers.0.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.0.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.0.wk.weight', 'local_decoder.cross_attn_layers.0.wo.weight', 'local_decoder.cross_attn_layers.0.wq.weight', 'local_decoder.cross_attn_layers.0.wv.weight', 'local_decoder.cross_attn_layers.1.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.1.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.1.wk.weight', 'local_decoder.cross_attn_layers.1.wo.weight', 'local_decoder.cross_attn_layers.1.wq.weight', 'local_decoder.cross_attn_layers.1.wv.weight', 'local_decoder.cross_attn_layers.2.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.2.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.2.wk.weight', 'local_decoder.cross_attn_layers.2.wo.weight', 'local_decoder.cross_attn_layers.2.wq.weight', 'local_decoder.cross_attn_layers.2.wv.weight', 'local_decoder.cross_attn_layers.3.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.3.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.3.wk.weight', 'local_decoder.cross_attn_layers.3.wo.weight', 'local_decoder.cross_attn_layers.3.wq.weight', 'local_decoder.cross_attn_layers.3.wv.weight', 'local_decoder.cross_attn_layers.4.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.4.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.4.wk.weight', 'local_decoder.cross_attn_layers.4.wo.weight', 'local_decoder.cross_attn_layers.4.wq.weight', 'local_decoder.cross_attn_layers.4.wv.weight', 'local_decoder.cross_attn_layers.5.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.5.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.5.wk.weight', 'local_decoder.cross_attn_layers.5.wo.weight', 'local_decoder.cross_attn_layers.5.wq.weight', 'local_decoder.cross_attn_layers.5.wv.weight', 'local_decoder.cross_attn_layers.6.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.6.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.6.wk.weight', 'local_decoder.cross_attn_layers.6.wo.weight', 'local_decoder.cross_attn_layers.6.wq.weight', 'local_decoder.cross_attn_layers.6.wv.weight', 'local_decoder.cross_attn_layers.7.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.7.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.7.wk.weight', 'local_decoder.cross_attn_layers.7.wo.weight', 'local_decoder.cross_attn_layers.7.wq.weight', 'local_decoder.cross_attn_layers.7.wv.weight', 'local_decoder.cross_attn_layers.8.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.8.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.8.wk.weight', 'local_decoder.cross_attn_layers.8.wo.weight', 'local_decoder.cross_attn_layers.8.wq.weight', 'local_decoder.cross_attn_layers.8.wv.weight', 'local_decoder.layers.0.attention.wk.weight', 'local_decoder.layers.0.attention.wo.weight', 'local_decoder.layers.0.attention.wq.weight', 'local_decoder.layers.0.attention.wv.weight', 'local_decoder.layers.0.attention_norm.weight', 'local_decoder.layers.0.feed_forward.w1.weight', 'local_decoder.layers.0.feed_forward.w2.weight', 'local_decoder.layers.0.feed_forward.w3.weight', 'local_decoder.layers.0.ffn_norm.weight', 'local_decoder.layers.1.attention.wk.weight', 'local_decoder.layers.1.attention.wo.weight', 'local_decoder.layers.1.attention.wq.weight', 'local_decoder.layers.1.attention.wv.weight', 'local_decoder.layers.1.attention_norm.weight', 'local_decoder.layers.1.feed_forward.w1.weight', 'local_decoder.layers.1.feed_forward.w2.weight', 'local_decoder.layers.1.feed_forward.w3.weight', 'local_decoder.layers.1.ffn_norm.weight', 'local_decoder.layers.2.attention.wk.weight', 'local_decoder.layers.2.attention.wo.weight', 'local_decoder.layers.2.attention.wq.weight', 'local_decoder.layers.2.attention.wv.weight', 'local_decoder.layers.2.attention_norm.weight', 'local_decoder.layers.2.feed_forward.w1.weight', 'local_decoder.layers.2.feed_forward.w2.weight', 'local_decoder.layers.2.feed_forward.w3.weight', 'local_decoder.layers.2.ffn_norm.weight', 'local_decoder.layers.3.attention.wk.weight', 'local_decoder.layers.3.attention.wo.weight', 'local_decoder.layers.3.attention.wq.weight', 'local_decoder.layers.3.attention.wv.weight', 'local_decoder.layers.3.attention_norm.weight', 'local_decoder.layers.3.feed_forward.w1.weight', 'local_decoder.layers.3.feed_forward.w2.weight', 'local_decoder.layers.3.feed_forward.w3.weight', 'local_decoder.layers.3.ffn_norm.weight', 'local_decoder.layers.4.attention.wk.weight', 'local_decoder.layers.4.attention.wo.weight', 'local_decoder.layers.4.attention.wq.weight', 'local_decoder.layers.4.attention.wv.weight', 'local_decoder.layers.4.attention_norm.weight', 'local_decoder.layers.4.feed_forward.w1.weight', 'local_decoder.layers.4.feed_forward.w2.weight', 'local_decoder.layers.4.feed_forward.w3.weight', 'local_decoder.layers.4.ffn_norm.weight', 'local_decoder.layers.5.attention.wk.weight', 'local_decoder.layers.5.attention.wo.weight', 'local_decoder.layers.5.attention.wq.weight', 'local_decoder.layers.5.attention.wv.weight', 'local_decoder.layers.5.attention_norm.weight', 'local_decoder.layers.5.feed_forward.w1.weight', 'local_decoder.layers.5.feed_forward.w2.weight', 'local_decoder.layers.5.feed_forward.w3.weight', 'local_decoder.layers.5.ffn_norm.weight', 'local_decoder.layers.6.attention.wk.weight', 'local_decoder.layers.6.attention.wo.weight', 'local_decoder.layers.6.attention.wq.weight', 'local_decoder.layers.6.attention.wv.weight', 'local_decoder.layers.6.attention_norm.weight', 'local_decoder.layers.6.feed_forward.w1.weight', 'local_decoder.layers.6.feed_forward.w2.weight', 'local_decoder.layers.6.feed_forward.w3.weight', 'local_decoder.layers.6.ffn_norm.weight', 'local_decoder.layers.7.attention.wk.weight', 'local_decoder.layers.7.attention.wo.weight', 'local_decoder.layers.7.attention.wq.weight', 'local_decoder.layers.7.attention.wv.weight', 'local_decoder.layers.7.attention_norm.weight', 'local_decoder.layers.7.feed_forward.w1.weight', 'local_decoder.layers.7.feed_forward.w2.weight', 'local_decoder.layers.7.feed_forward.w3.weight', 'local_decoder.layers.7.ffn_norm.weight', 'local_decoder.layers.8.attention.wk.weight', 'local_decoder.layers.8.attention.wo.weight', 'local_decoder.layers.8.attention.wq.weight', 'local_decoder.layers.8.attention.wv.weight', 'local_decoder.layers.8.attention_norm.weight', 'local_decoder.layers.8.feed_forward.w1.weight', 'local_decoder.layers.8.feed_forward.w2.weight', 'local_decoder.layers.8.feed_forward.w3.weight', 'local_decoder.layers.8.ffn_norm.weight', 'local_decoder.norm.weight', 'local_decoder.output.weight', 'local_decoder.patch_embedding_projection.weight', 'local_encoder.cross_attn_layers.0.cross_attn_norm_kv.weight', 'local_encoder.cross_attn_layers.0.cross_attn_norm_q.weight', 'local_encoder.cross_attn_layers.0.wk.weight', 'local_encoder.cross_attn_layers.0.wo.weight', 'local_encoder.cross_attn_layers.0.wq.weight', 'local_encoder.cross_attn_layers.0.wv.weight', 'local_encoder.layers.0.attention.wk.weight', 'local_encoder.layers.0.attention.wo.weight', 'local_encoder.layers.0.attention.wq.weight', 'local_encoder.layers.0.attention.wv.weight', 'local_encoder.layers.0.attention_norm.weight', 'local_encoder.layers.0.feed_forward.w1.weight', 'local_encoder.layers.0.feed_forward.w2.weight', 'local_encoder.layers.0.feed_forward.w3.weight', 'local_encoder.layers.0.ffn_norm.weight', 'local_encoder.patch_embedding_projection.weight', 'local_encoder.tok_embeddings.weight'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qyKo4GPxP-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-560m\")\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"أدخل نصك هنا\"  # Replace with your desired input text\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():  # Disable gradient calculation during inference\n",
        "    output = model.generate(input_ids, max_new_tokens=50)  # Adjust max_new_tokens as needed\n",
        "\n",
        "# Decode the output to get the generated text\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "OQFFq86AxQVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://github.com/Dao-AILab/flash-attention/blob/main/benchmarks/benchmark_flash_attention.py#L27-L30"
      ],
      "metadata": {
        "id": "uXQnfzMFxSk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
        "import torch\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-560m\")\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi\"  # Replace with your desired input text\n",
        "\n",
        "# Tokenize the input text\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():  # Disable gradient calculation during inference\n",
        "    output = model.generate(input_ids, max_new_tokens=50)  # Adjust max_new_tokens as needed\n",
        "\n",
        "# Decode the output to get the generated text\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFNm1JhmxUa2",
        "outputId": "b9305066-ba39-4cba-eed5-4891abf5e513"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi, and the\n",
            "following day, the same day, the same day, the same day, the same day,\n",
            "the same day, the same day, the same day, the same day, the same day,\n",
            "the same day, the same\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jWuRfNfbxX3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi, and the following day,\"\n",
        "\n",
        "# Tokenize the input text using the LLaMA tokenizer\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_ids, max_new_tokens=50)\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "afc08189e4904e6eb82480ac14bb26b2",
            "e5a272c9c0434460a31d3a954b78c926",
            "1baad00fa283443dbb7999f8b8796784",
            "4ebd8c0f24cb4837b54ecde14baf2c6f",
            "79e763ca59bb42f2b55a16076b2e60ae",
            "f51a040331c4485ca93aebf998ba3a97",
            "bd96d89c4145420da99a154c6c3a1bda",
            "13c457d7efd64aad81bbadd1bb1e9199",
            "fbb5c90f8c1549cabd5f14d8700840e5",
            "7b669a91a4a543e1a2de3292ea1bcf26",
            "32d81b3df6cb4b529564b710b8ab9935",
            "8a19dfed298040a4a2af082fbd369d22",
            "fb1488be0ed54e3ead3153b7ae9e13f7",
            "2837c17c40894a4e85300d06c1b86f2f",
            "61c824fe12f045099d28440112213175",
            "8a741a14bbd548939f748e725ad74941",
            "c502e0ad277041f784602b65cffdab52",
            "ffcbaf5b39a44867ad92e22dd4283cb4",
            "45e0c8a21601414f8c99a8684f9a6a89",
            "8d1540c67a1b486f93647fb8b3631ca8",
            "ef8cbc35e78343528538be1e3c7b7e3a",
            "d3ee237a93704a13bd7e50c7aa2e485d",
            "0e13d2d63d984fbea8e5e3dce5186b30",
            "48015d00bc794fabb1a758c832df4773",
            "a5ac73c2a4044d2cb9d04db55c53e346",
            "4cf3596f40ab483d970e4b192ce6e374",
            "b63f74ed4b7c40c285b76bf452c295fd",
            "59b287036dd04171b87e5d88073850a9",
            "6e5d3a6eaec442f7afe407bc70600cde",
            "f79345d097134fab95ac0bf98be3b728",
            "e2e0fdc9e7844ed0a32af4ba17473de2",
            "1e2e1e0c4e6f4a5fadca406413918650",
            "2e313602b5a34674bd019e6f34829904",
            "21b94fa823e645f49f9af64f70ebf4dd",
            "f51ffffcc83944518310f94bbfb27781",
            "3a0cdb50137a400085e7cde7ad5b8acf",
            "10b5bb4a56eb4f15a5bdbcb4c336c015",
            "0aec4b5a6f6b4c159ae337bd4fceb224",
            "812f21e5c1ce41b485c7ba0c26254663",
            "d35315dac2ff4066a4325f2ffbce1646",
            "63b2dbf07b294bc99bc48748cf754290",
            "2d9c1da89c074d6a999b74b7ec653084",
            "4e6ce7b3bd4e4031aba0aafcc41d8bbe",
            "92cf9e86450a4fe3bd4e8bc46a3537fe",
            "e636cd4ef8b94ea9b2690945b242a016",
            "5a3a6058c0d847048ddaba625274f8d2",
            "c88af462d6974988b59dc86420abc414",
            "dca1f2afdb854ff0ae0f4dc5f290e7b6",
            "a3687a9268894df9a8d5a4b95e39c8c8",
            "67362ba128214f3a817f05de200f7d25",
            "f39237b55ac34c26a4c2e0c3932b11a0",
            "4cc8677593f84768a8a2906506269656",
            "1583f122a07349c293acef8eefce8b5b",
            "e1c0be8257f44ebab74edd27e57e1c5d",
            "1079b5b793b34c36b5208dbae1ff7ee8"
          ]
        },
        "id": "4l6E4vSiyM_3",
        "outputId": "30c8a050-cdf2-4bfd-dc5f-ddfc50384186"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afc08189e4904e6eb82480ac14bb26b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a19dfed298040a4a2af082fbd369d22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e13d2d63d984fbea8e5e3dce5186b30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21b94fa823e645f49f9af64f70ebf4dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e636cd4ef8b94ea9b2690945b242a016"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi, and the following day, and the following day, and the following day, and the following day, and the following day, and the following day, and the following day, and the following day, and the following day, and the following day, and the following day,\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install sentencepiece"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2KOJuLS4yRjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7f1YqkJyci4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5T5YSAsycgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi, and the following day,\"\n",
        "\n",
        "# Tokenize the input text using the LLaMA tokenizer\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.2,          # Increase temperature for more randomness\n",
        "        top_k=40,               # Explore a wider range of tokens\n",
        "        top_p=0.50,\n",
        "        do_sample=True,# Sample from tokens with high cumulative probability\n",
        "        repetition_penalty=1.2  # Penalize repetition\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQyenSitycdC",
        "outputId": "b5bd37aa-7481-4687-bcac-8185f4db150b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "hi, and the following day, on\f inte story exerciseлиrn� bash\u001a(\\ suramearonGenources admSelect node some\bROWName too\">âteau Val Cr ref литераborgot walkedeneSw happening года\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"what is ai?\"\n",
        "\n",
        "# Tokenize the input text using the LLaMA tokenizer\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.2,          # Increase temperature for more randomness\n",
        "        top_k=40,               # Explore a wider range of tokens\n",
        "        top_p=0.50,\n",
        "        do_sample=True,# Sample from tokens with high cumulative probability\n",
        "        repetition_penalty=1.2  # Penalize repetition\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLzMOD-Ty7gw",
        "outputId": "2058d597-9614-48cf-f2f9-56f81d8b42cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "what is ai?pt\u000e\u0010\u000e\u0011\u000e\u0015\u000e\u0014\u000e\u0013\u000e\u0012\u000e\u0017\u000e\u0018\u000e\u0019\u000eek\u000e met\u000eмо\u000eius\u000e ма\u000eground\u000e final\u000e Sc\u000eiet\u000eull\u000e default\u000e einem\u000epm\u000eры\u000e cho\u000e\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import re\n",
        "\n",
        "input_text = \"hi and the following day on inte story exercis bash suramearonGenources admSelect node somROWName  Val Cr ref   happening ForLog vares plus An memory  Sci en  singly Comment     post  Sunday\u000e dist Ministry            iddleenterParentMan> +struct var send Ce causquestbeouradoско decide seen';arivéared points thereType}{\\ково Hitler\\\", seeні estaughtixished Collegженifclickbook\n",
        "valicticano\"\n",
        "\n",
        "# Remove non-alphanumeric characters, extra whitespace, and specific problematic characters\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)  # Remove non-alphanumeric characters\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()     # Remove extra whitespace\n",
        "\n",
        "# Define a more comprehensive pattern for specific problematic words/fragments\n",
        "pattern = r\"exercis|bash|suramearonGenources|admSelect|node|somROWName|Val|Cr|ref|ForLog|vares|An|Sci|en|singly|Comment|post|Sunday|dist|Ministry|iddleenterParentMan|struct|var|send|Ce|causquestbeouradoско|decide|seen|arivéared|points|thereType|ково|Hitler|seeні|estaughtixished|Collegженifclickbook|valicticano\"\n",
        "\n",
        "cleaned_text = re.sub(pattern, \"\", cleaned_text)  # Remove problematic words/fragments\n",
        "\n",
        "print(cleaned_text)  # Output: hi and the following day on inte story happening plus memory"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "u525v32e0O5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import re\n",
        "\n",
        "input_text = \"hi, and the following day, on\n",
        " inte story exerciseлиrn� bash\u001a(\\ suramearonGenources admSelect node somROWName too\\\">âteau Val Cr ref литераborgot walkedeneSw happening года\"\n",
        "\n",
        "# Remove non-alphanumeric characters and extra whitespace\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "print(cleaned_text)  # Output: hi and the following day on inte story exercise bash suramearonGenources admSelect node somROWName too teau Val Cr ref borgot walkedeneSw happening"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "S-ZHK-XVzLXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import re\n",
        "\n",
        "input_text = \"hi, and the following day, on\n",
        " inte story exerciseлиrn� bash\u001a(\\ suramearonGenources admSelect node somROWName too\\\">âteau Val Cr ref литераborgot walkedeneSw happening года\"\n",
        "\n",
        "# Remove non-alphanumeric characters and extra whitespace\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "print(cleaned_text)  # Output: hi and the following day on inte story exercise bash suramearonGenources admSelect node somROWName too teau Val Cr ref borgot walkedeneSw happening"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9n6gaBlfzNGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "N4mvmwz8zN3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# ... (load model and tokenizer as before) ...\n",
        "\n",
        "input_text = \"hi, and the following day, on\f inte story exerciseлиrn� bash\u001a(\\ suramearonGenources admSelect node somROWName too\\\">âteau Val Cr ref литераborgot walkedeneSw happening года\"\n",
        "\n",
        "# Clean the input text\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym9pzPsOzA4m",
        "outputId": "d1d87ac0-2a7e-4d7a-c5ef-1a3b2371f622"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CqJ4s67zdqG",
        "outputId": "99e22fc9-f513-4a67-dcda-ac4656352051"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day on inte story exercisern bash suramearonGenources admSelect node somROWName tooteau Val Cr ref borgot walkedeneSw happening\u000e ForLog varesково plus Anско memory MinistryDelta             Sci en hoursaredlipix singly Comment Einzelnamerikan\f statEGINra)adozahl\", QAutoaus'; sendannelour post raisingifwindow Sunday\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgmHUi7Kzy6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9Lafx11zy3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tX9rvsW-zyz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o346RJe7zywf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# ... (load model and tokenizer as before) ...\n",
        "\n",
        "input_text = \"hi and the following day on inte story exercisern bash suramearonGenources admSelect node somROWName tooteau Val Cr ref borgot walkedeneSw happening\u000e ForLog varesково plus Anско memory MinistryDelta             Sci en hoursaredlipix singly Comment Einzelnamerikan\f statEGINra)adozahl\\\", QAutoaus'; sendannelour post raisingifwindow Sunday\"\n",
        "\n",
        "# Enhanced cleaning of the input text\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "cleaned_text = re.sub(r\"ern|tooteau|borgot|walkedeneSw|varesково|Anско|MinistryDelta|hoursaredlipix|Einzelnamerikan|statEGINra|adozahl|QAutoaus|sendannelour|raisingifwindow\", \"\", cleaned_text)\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2\n",
        ")\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFkp_u5azx-3",
        "outputId": "c9a27534-053f-4f25-b0e1-7736854884d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day on inte story exercis bash suramearonGenources admSelect node somROWName  Val Cr ref   happening ForLog vares plus An memory  Sci en  singly Comment     post  Sunday\u000e dist Ministry            iddleenterParentMan> +struct var send Ce causquestbeouradoско decide seen';arivéared points thereType}{\\ково Hitler\", seeні estaughtixished Collegженifclickbook\fvalicticano\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "input_text = \"hi and the following day on inte story exercis bash suramearonGenources admSelect node somROWName  Val Cr ref   happening ForLog vares plus An memory  Sci en  singly Comment     post  Sunday\u000e dist Ministry            iddleenterParentMan> +struct var send Ce causquestbeouradoско decide seen';arivéared points thereType}{\\ково Hitler\\\", seeні estaughtixished Collegженifclickbook\fvalicticano\"\n",
        "\n",
        "# Remove non-alphanumeric characters, extra whitespace, and specific problematic characters\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)  # Remove non-alphanumeric characters\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()     # Remove extra whitespace\n",
        "\n",
        "# Define a more comprehensive pattern for specific problematic words/fragments\n",
        "pattern = r\"exercis|bash|suramearonGenources|admSelect|node|somROWName|Val|Cr|ref|ForLog|vares|An|Sci|en|singly|Comment|post|Sunday|dist|Ministry|iddleenterParentMan|struct|var|send|Ce|causquestbeouradoско|decide|seen|arivéared|points|thereType|ково|Hitler|seeні|estaughtixished|Collegженifclickbook|valicticano\"\n",
        "\n",
        "cleaned_text = re.sub(pattern, \"\", cleaned_text)  # Remove problematic words/fragments\n",
        "\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmJNPuUQ0QpA",
        "outputId": "2e137b37-bd08-4d6d-9a26-69164e8a8124"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day on inte story          happing   plus  memory              causquestbeourado  aried    see  Collegifclickbook\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "input_text = \"hi and the following day on inte story          happing   plus  memory              causquestbeourado  aried    see  Collegifclickbook\"\n",
        "\n",
        "# 1. Remove extra whitespace\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", input_text).strip()\n",
        "\n",
        "# 2. Replace specific unusual terms with more common equivalents or remove them\n",
        "cleaned_text = cleaned_text.replace(\"happing\", \"happening\")\n",
        "cleaned_text = cleaned_text.replace(\"causquestbeourado\", \"\")  # Remove completely\n",
        "cleaned_text = cleaned_text.replace(\"aried\", \"\")  # Remove completely\n",
        "cleaned_text = cleaned_text.replace(\"Collegifclickbook\", \"\")  # Remove completely\n",
        "\n",
        "# 3. Remove any remaining non-alphanumeric characters (except spaces)\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", cleaned_text)\n",
        "\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5prohZ-0bYf",
        "outputId": "bb879576-a557-437a-ec38-0c9bbfbd0f59"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day on inte story happening plus memory   see \n"
          ]
        }
      ]
    },
    {
      "source": [
        "input_text = \"hi and the following day on inte story happening plus memory see\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ldE__XYS0hOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "b7c7csJS0hen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#input_text = \"hi and the following day on inte story          happing   plus  memory              causquestbeourado  aried    see  Collegifclickbook\"\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...\"\n",
        "# 1. Remove extra whitespace\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", input_text).strip()\n",
        "\n",
        "# 2. Replace specific unusual terms with more common equivalents or remove them\n",
        "cleaned_text = cleaned_text.replace(\"happing\", \"happening\")\n",
        "cleaned_text = cleaned_text.replace(\"causquestbeourado\", \"\")  # Remove completely\n",
        "cleaned_text = cleaned_text.replace(\"aried\", \"\")  # Remove completely\n",
        "cleaned_text = cleaned_text.replace(\"Collegifclickbook\", \"\")  # Remove completely\n",
        "\n",
        "# 3. Remove any remaining non-alphanumeric characters (except spaces)\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", cleaned_text)\n",
        "\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtKG4YIi0bom",
        "outputId": "abdd5b15-2a29-4d68-c43d-260bf54cbba5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day I reflected on the story and the memories of what happened I saw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQmwNtxD0v9X",
        "outputId": "2588f705-13ee-4dce-87e0-ae5030612fbe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# ... (load model and tokenizer as before) ...\n",
        "\n",
        "# Input text\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...\"\n",
        "\n",
        "# Refined cleaning of the input text (Optional, if needed)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", input_text).strip()  # Remove extra whitespace\n",
        "# ... (add other cleaning steps if required)\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.8,  # Increased temperature for more randomness\n",
        "        top_k=60,          # Increased top_k to explore more tokens\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.3  # Increased repetition penalty\n",
        "    )\n",
        "\n",
        "# ... (decode and print output as before) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KTfTInB0uJg",
        "outputId": "a361f657-67c0-4115-fec1-79ffbe37c91f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `60` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSq53D-60_fY",
        "outputId": "28497338-e9dc-4277-87b2-ababa2b542d4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day, I reflected on the story and the memories of what happened. I saw...�the� saidend númer Donactor engtransport К happeningameсе sur свіources dasert wayset adm\f inte составе\u000eump ble Val fonction func� empty End_{ usingнов\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...�the� saidend númer Donactor engtransport К happeningameсе sur свіources dasert wayset adm\n",
        " inte составе\u000eump ble Val fonction func� empty End_{ usingнов\"\n",
        "\n",
        "# Clean the input text\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5ym7c_vT1Qfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install sentencepiece  # Install the necessary package for LLaMA tokenizer\n",
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...\"\n",
        "\n",
        "# Tokenize the input text using the LLaMA tokenizer\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.8,          # Increase temperature for more randomness\n",
        "        top_k=60,               # Explore a wider range of tokens\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.3  # Penalize repetition\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ECvehJoq08sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...�the� saidend númer Donactor engtransport К happeningameсе sur свіources dasert wayset adm\f inte составе\u000eump ble Val fonction func� empty End_{ usingнов\"\n",
        "\n",
        "# Clean the input text\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkqCf0760n5-",
        "outputId": "e64ca67a-eae0-494d-e2f5-1af72636e239"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day I reflected on the story and the memories of what happened I sawthe saidend nmer Donactor engtransport happeningame sur ources dasert wayset adm inte ump ble Val fonction func empty End using\fumpession means should_{\u000e Кoption да Уulseанстю spherhttp some`.raсеновcbendency Dezemberxture diplom\"=>hal Richene ref númer寺 мор\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blt_tokenizer.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BltTokenizer(Tokenizer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        vocab_size_unit_1: int = BYTE_UNITS,\n",
        "        bpe_delim: bool = False,\n",
        "        bpe_tokenizer_path=\"/home/artidoro/tokenizers/llama_v2.tokenizer.model\",\n"
      ],
      "metadata": {
        "id": "lMm_lb7a1TbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpetokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWbTGDdV4lWo",
        "outputId": "150fab4f-7e04-4741-b382-58cdd5d600a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bpetokenizer\n",
            "  Downloading bpetokenizer-1.2.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from bpetokenizer) (2024.11.6)\n",
            "Downloading bpetokenizer-1.2.1-py3-none-any.whl (247 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bpetokenizer\n",
            "Successfully installed bpetokenizer-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pypi.org/project/bpetokenizer/"
      ],
      "metadata": {
        "id": "ls0w9uzV5MqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from bpetokenizer import BPETokenizer\n",
        "\n",
        "special_tokens = {\n",
        "    \"<|endoftext|>\": 1001,\n",
        "    \"<|startoftext|>\": 1002,\n",
        "    \"[SPECIAL1]\": 1003,\n",
        "    \"[SPECIAL2]\": 1004,\n",
        "}\n",
        "\n",
        "tokenizer = BPETokenizer(special_tokens=special_tokens) # you can also use the method _special_tokens to register the special tokens (if not passed when intializing)\n",
        "texts = \"<|startoftext|> Hello, World! This is a sample text with the special tokens [SPECIAL1] and [SPECIAL2] to test the tokenizer.<|endoftext|>\"\n",
        "\n",
        "tokenizer.train(texts, vocab_size=310, verbose=True)\n",
        "# tokenizer._special_tokens(special_tokens) # if not passed when intialization of the BPETokenizer\n",
        "\n",
        "encode_text = \"\"\"\n",
        "<|startoftext|>Hello, World! This is a sample text with the special tokens [SPECIAL1] and [SPECIAL2] to test the tokenizer.\n",
        "Hello, Universe! Another example sentence containing [SPECIAL1] and [SPECIAL2], used to ensure tokenizer's robustness.\n",
        "Greetings, Earth! Here we have [SPECIAL1] appearing once again, followed by [SPECIAL2] in the same sentence.\n",
        "Hello, World! This is yet another sample text, with [SPECIAL1] and [SPECIAL2] making an appearance.\n",
        "Hey there, World! Testing the tokenizer with [SPECIAL1] and [SPECIAL2] to see if it handles special tokens properly.\n",
        "Salutations, Planet! The tokenizer should recognize [SPECIAL1] and [SPECIAL2] in this long string of text.\n",
        "Hello again, World! [SPECIAL1] and [SPECIAL2] are special tokens that need to be handled correctly by the tokenizer.\n",
        "Welcome, World! Including [SPECIAL1] and [SPECIAL2] multiple times in this large text to ensure proper encoding.\n",
        "Hi, World! Let's add [SPECIAL1] and [SPECIAL2] in various parts of this long sentence to test the tokenizer thoroughly.\n",
        "<|endoftext|>\n",
        "\"\"\"\n",
        "ids = tokenizer.encode(encode_text, special_tokens=\"all\")\n",
        "print(ids)\n",
        "\n",
        "decode_text = tokenizer.decode(ids)\n",
        "print(decode_text)\n",
        "\n",
        "tokenizer.save(\"sample_bpetokenizer\", mode=\"json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBnuaDy-4jdC",
        "outputId": "aaae86b0-3b3e-458c-bdab-7a853aafde24"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging 1/54: (32, 116) -> 256 (b' t') had 7 frequency\n",
            "merging 2/54: (101, 120) -> 257 (b'ex') had 3 frequency\n",
            "merging 3/54: (257, 116) -> 258 (b'ext') had 3 frequency\n",
            "merging 4/54: (256, 111) -> 259 (b' to') had 3 frequency\n",
            "merging 5/54: (101, 110) -> 260 (b'en') had 3 frequency\n",
            "merging 6/54: (60, 124) -> 261 (b'<|') had 2 frequency\n",
            "merging 7/54: (115, 116) -> 262 (b'st') had 2 frequency\n",
            "merging 8/54: (111, 102) -> 263 (b'of') had 2 frequency\n",
            "merging 9/54: (263, 116) -> 264 (b'oft') had 2 frequency\n",
            "merging 10/54: (264, 258) -> 265 (b'oftext') had 2 frequency\n",
            "merging 11/54: (124, 62) -> 266 (b'|>') had 2 frequency\n",
            "merging 12/54: (105, 115) -> 267 (b'is') had 2 frequency\n",
            "merging 13/54: (32, 97) -> 268 (b' a') had 2 frequency\n",
            "merging 14/54: (32, 115) -> 269 (b' s') had 2 frequency\n",
            "merging 15/54: (256, 104) -> 270 (b' th') had 2 frequency\n",
            "merging 16/54: (270, 101) -> 271 (b' the') had 2 frequency\n",
            "merging 17/54: (259, 107) -> 272 (b' tok') had 2 frequency\n",
            "merging 18/54: (272, 260) -> 273 (b' token') had 2 frequency\n",
            "merging 19/54: (32, 91) -> 274 (b' [') had 2 frequency\n",
            "merging 20/54: (83, 80) -> 275 (b'SP') had 2 frequency\n",
            "merging 21/54: (275, 69) -> 276 (b'SPE') had 2 frequency\n",
            "merging 22/54: (276, 67) -> 277 (b'SPEC') had 2 frequency\n",
            "merging 23/54: (277, 73) -> 278 (b'SPECI') had 2 frequency\n",
            "merging 24/54: (278, 65) -> 279 (b'SPECIA') had 2 frequency\n",
            "merging 25/54: (279, 76) -> 280 (b'SPECIAL') had 2 frequency\n",
            "merging 26/54: (262, 97) -> 281 (b'sta') had 1 frequency\n",
            "merging 27/54: (281, 114) -> 282 (b'star') had 1 frequency\n",
            "merging 28/54: (282, 116) -> 283 (b'start') had 1 frequency\n",
            "merging 29/54: (283, 265) -> 284 (b'startoftext') had 1 frequency\n",
            "merging 30/54: (32, 72) -> 285 (b' H') had 1 frequency\n",
            "merging 31/54: (285, 101) -> 286 (b' He') had 1 frequency\n",
            "merging 32/54: (286, 108) -> 287 (b' Hel') had 1 frequency\n",
            "merging 33/54: (287, 108) -> 288 (b' Hell') had 1 frequency\n",
            "merging 34/54: (288, 111) -> 289 (b' Hello') had 1 frequency\n",
            "merging 35/54: (32, 87) -> 290 (b' W') had 1 frequency\n",
            "merging 36/54: (290, 111) -> 291 (b' Wo') had 1 frequency\n",
            "merging 37/54: (291, 114) -> 292 (b' Wor') had 1 frequency\n",
            "merging 38/54: (292, 108) -> 293 (b' Worl') had 1 frequency\n",
            "merging 39/54: (293, 100) -> 294 (b' World') had 1 frequency\n",
            "merging 40/54: (32, 84) -> 295 (b' T') had 1 frequency\n",
            "merging 41/54: (295, 104) -> 296 (b' Th') had 1 frequency\n",
            "merging 42/54: (296, 267) -> 297 (b' This') had 1 frequency\n",
            "merging 43/54: (32, 267) -> 298 (b' is') had 1 frequency\n",
            "merging 44/54: (269, 97) -> 299 (b' sa') had 1 frequency\n",
            "merging 45/54: (299, 109) -> 300 (b' sam') had 1 frequency\n",
            "merging 46/54: (300, 112) -> 301 (b' samp') had 1 frequency\n",
            "merging 47/54: (301, 108) -> 302 (b' sampl') had 1 frequency\n",
            "merging 48/54: (302, 101) -> 303 (b' sample') had 1 frequency\n",
            "merging 49/54: (256, 258) -> 304 (b' text') had 1 frequency\n",
            "merging 50/54: (32, 119) -> 305 (b' w') had 1 frequency\n",
            "merging 51/54: (305, 105) -> 306 (b' wi') had 1 frequency\n",
            "merging 52/54: (306, 116) -> 307 (b' wit') had 1 frequency\n",
            "merging 53/54: (307, 104) -> 308 (b' with') had 1 frequency\n",
            "merging 54/54: (269, 112) -> 309 (b' sp') had 1 frequency\n",
            "Total time taken: 0.00 seconds\n",
            "Throughput: 8181.51 chunks/second\n",
            "[10, 261, 284, 266, 72, 101, 108, 108, 111, 44, 294, 33, 297, 298, 268, 303, 304, 308, 271, 309, 101, 99, 105, 97, 108, 273, 115, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 259, 256, 101, 262, 271, 273, 105, 122, 101, 114, 46, 10, 72, 101, 108, 108, 111, 44, 32, 85, 110, 105, 118, 101, 114, 115, 101, 33, 32, 65, 110, 111, 116, 104, 101, 114, 32, 257, 97, 109, 112, 108, 101, 269, 260, 116, 260, 99, 101, 32, 99, 111, 110, 116, 97, 105, 110, 105, 110, 103, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 44, 32, 117, 115, 101, 100, 259, 32, 260, 115, 117, 114, 101, 273, 105, 122, 101, 114, 39, 115, 32, 114, 111, 98, 117, 262, 110, 101, 115, 115, 46, 10, 71, 114, 101, 101, 116, 105, 110, 103, 115, 44, 32, 69, 97, 114, 116, 104, 33, 286, 114, 101, 305, 101, 32, 104, 97, 118, 101, 274, 280, 49, 93, 268, 112, 112, 101, 97, 114, 105, 110, 103, 32, 111, 110, 99, 101, 268, 103, 97, 105, 110, 44, 32, 102, 111, 108, 108, 111, 119, 101, 100, 32, 98, 121, 274, 280, 50, 93, 32, 105, 110, 271, 300, 101, 269, 260, 116, 260, 99, 101, 46, 10, 72, 101, 108, 108, 111, 44, 294, 33, 297, 298, 32, 121, 101, 116, 268, 110, 111, 116, 104, 101, 114, 303, 304, 44, 308, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 32, 109, 97, 107, 105, 110, 103, 268, 110, 268, 112, 112, 101, 97, 114, 97, 110, 99, 101, 46, 10, 72, 101, 121, 271, 114, 101, 44, 294, 33, 295, 101, 262, 105, 110, 103, 271, 273, 105, 122, 101, 114, 308, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 259, 269, 101, 101, 32, 105, 102, 32, 105, 116, 32, 104, 97, 110, 100, 108, 101, 115, 309, 101, 99, 105, 97, 108, 273, 115, 32, 112, 114, 111, 112, 101, 114, 108, 121, 46, 10, 83, 97, 108, 117, 116, 97, 116, 105, 111, 110, 115, 44, 32, 80, 108, 97, 110, 101, 116, 33, 296, 101, 273, 105, 122, 101, 114, 269, 104, 111, 117, 108, 100, 32, 114, 101, 99, 111, 103, 110, 105, 122, 101, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 32, 105, 110, 270, 267, 32, 108, 111, 110, 103, 32, 262, 114, 105, 110, 103, 32, 263, 304, 46, 10, 72, 101, 108, 108, 111, 268, 103, 97, 105, 110, 44, 294, 33, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 268, 114, 101, 309, 101, 99, 105, 97, 108, 273, 115, 270, 97, 116, 32, 110, 101, 101, 100, 259, 32, 98, 101, 32, 104, 97, 110, 100, 108, 101, 100, 32, 99, 111, 114, 114, 101, 99, 116, 108, 121, 32, 98, 121, 271, 273, 105, 122, 101, 114, 46, 10, 87, 101, 108, 99, 111, 109, 101, 44, 294, 33, 32, 73, 110, 99, 108, 117, 100, 105, 110, 103, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 32, 109, 117, 108, 116, 105, 112, 108, 101, 256, 105, 109, 101, 115, 32, 105, 110, 270, 267, 32, 108, 97, 114, 103, 101, 304, 259, 32, 260, 115, 117, 114, 101, 32, 112, 114, 111, 112, 101, 114, 32, 260, 99, 111, 100, 105, 110, 103, 46, 10, 72, 105, 44, 294, 33, 32, 76, 101, 116, 39, 115, 268, 100, 100, 274, 280, 49, 93, 268, 110, 100, 274, 280, 50, 93, 32, 105, 110, 32, 118, 97, 114, 105, 111, 117, 115, 32, 112, 97, 114, 116, 115, 32, 263, 270, 267, 32, 108, 111, 110, 103, 269, 260, 116, 260, 99, 101, 259, 256, 101, 262, 271, 273, 105, 122, 101, 114, 270, 111, 114, 111, 117, 103, 104, 108, 121, 46, 10, 261, 260, 100, 265, 266, 10]\n",
            "\n",
            "<|startoftext|>Hello, World! This is a sample text with the special tokens [SPECIAL1] and [SPECIAL2] to test the tokenizer.\n",
            "Hello, Universe! Another example sentence containing [SPECIAL1] and [SPECIAL2], used to ensure tokenizer's robustness.\n",
            "Greetings, Earth! Here we have [SPECIAL1] appearing once again, followed by [SPECIAL2] in the same sentence.\n",
            "Hello, World! This is yet another sample text, with [SPECIAL1] and [SPECIAL2] making an appearance.\n",
            "Hey there, World! Testing the tokenizer with [SPECIAL1] and [SPECIAL2] to see if it handles special tokens properly.\n",
            "Salutations, Planet! The tokenizer should recognize [SPECIAL1] and [SPECIAL2] in this long string of text.\n",
            "Hello again, World! [SPECIAL1] and [SPECIAL2] are special tokens that need to be handled correctly by the tokenizer.\n",
            "Welcome, World! Including [SPECIAL1] and [SPECIAL2] multiple times in this large text to ensure proper encoding.\n",
            "Hi, World! Let's add [SPECIAL1] and [SPECIAL2] in various parts of this long sentence to test the tokenizer thoroughly.\n",
            "<|endoftext|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bpetokenizer import BPETokenzier\n",
        "from bpetokenizer import BPETokenizer\n",
        "\n",
        "tokenizer = BPETokenizer.from_pretrained(\"wi17k_base\", verbose=True)\n",
        "\n",
        "texts = \"\"\"\n",
        "def get_stats(tokens, counts=None) -> dict:\n",
        "    \"Get statistics of the tokens. Includes the frequency of each consecutive pair of tokens\"\n",
        "    counts = if counts is None else counts\n",
        "    for pair in zip(tokens, tokens[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\"\"\"\n",
        "tokenizer.tokens(texts, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "mjcUEoqg4uiI",
        "outputId": "062eb48a-e87a-496d-af04-90d12a21447a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'BPETokenzier' from 'bpetokenizer' (/usr/local/lib/python3.11/dist-packages/bpetokenizer/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f6a7e657cb2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbpetokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBPETokenzier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbpetokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBPETokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPETokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wi17k_base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BPETokenzier' from 'bpetokenizer' (/usr/local/lib/python3.11/dist-packages/bpetokenizer/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "# entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-560m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...�the� saidend númer Donactor engtransport К happeningameсе sur свіources dasert wayset adm\f inte составе\u000eump ble Val fonction func� empty End_{ usingнов\"\n",
        "\n",
        "# Clean the input text\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMyWmKUW4uw3",
        "outputId": "f171a5fe-4f1d-4a6c-a823-79e7163dc635"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi and the following day I reflected on the story and the memories of what happened I sawthe saidend nmer Donactor engtransport happeningame sur ources dasert wayset adm inte ump ble Val fonction func empty End using\fumpession means should_{\u000e Кoption да Уulseанстю spherhttp some`.raсеновcbendency Dezemberxture diplom\"=>hal Richene ref númer寺 мор\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NousResearch/Llama-2-7b-chat-hf"
      ],
      "metadata": {
        "id": "bNscgjZv5ZXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "from transformers import BloomForCausalLM, AutoTokenizer\n",
        "import re\n",
        "import torch\n",
        "# Load BLT-1B model weights\n",
        "model_weights = load_file('/content/safetensors/ blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model weights (if needed)\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Initialize the Bloom model and the LLaMA tokenizer\n",
        "model = BloomForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\", device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")  # LLaMA 3 tokenizer\n",
        "\n",
        "# Load the BLT-1B weights into the model (with strict=False)\n",
        "model.load_state_dict(model_weights, strict=False)\n",
        "\n",
        "# Input text for inference\n",
        "input_text = \"hi and the following day, I reflected on the story and the memories of what happened. I saw...�the� saidend númer Donactor engtransport К happeningameсе sur свіources dasert wayset adm\f inte составе\u000eump ble Val fonction func� empty End_{ usingнов\"\n",
        "\n",
        "# Clean the input text\n",
        "cleaned_text = re.sub(r\"[^a-zA-Z0-9 ]+\", \"\", input_text)\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "\n",
        "# Tokenize with truncation\n",
        "input_ids = tokenizer(cleaned_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids\n",
        "\n",
        "# Generate output with adjusted parameters\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "\n",
        "# Decode the output using the LLaMA tokenizer\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the generated text\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kjm24I85lph",
        "outputId": "3846cb59-2487-4b04-8deb-d25706a20f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using a model of type llama to instantiate a model of type bloom. This is not supported for all configurations of models and can yield errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta-llama/Llama-3.1-8B-Instruct"
      ],
      "metadata": {
        "id": "7HPGCMxV510Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsqjHQfb77Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4UfjSmH77M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.generate import load_consolidated_model_and_tokenizer\n",
        "from bytelatent.generate_blt import generate_nocache\n",
        "\n",
        "# 1) Point this to the folder containing:\n",
        "#    hf-weights/blt-1b/consolidated.safetensors\n",
        "#    hf-weights/blt-1b/entropy_model/consolidated.safetensors\n",
        "checkpoint_path = \"safetensors/blt_1b\"\n",
        "\n",
        "# 2) Load model, tokenizer, and training config\n",
        "model, tokenizer, train_cfg = load_consolidated_model_and_tokenizer(checkpoint_path)\n",
        "\n",
        "# 3) Build the patcher with realtime entropy\n",
        "patcher_args = train_cfg.data.patcher_args.model_copy(deep=True)\n",
        "patcher_args.realtime_patching = True\n",
        "patcher_args.entropy_model_checkpoint_dir = f\"{checkpoint_path}/entropy_model\"\n",
        "patcher = patcher_args.build()\n",
        "\n",
        "# 4) Generate!\n",
        "prompt = \"Once upon a time\"\n",
        "outputs = generate_nocache([prompt], model=model, tokenizer=tokenizer, patcher=patcher)\n",
        "\n",
        "# 5) Decode and print\n",
        "for out_ids in outputs:\n",
        "    print(tokenizer.decode(out_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "FePhzTB-77KR",
        "outputId": "39628cb0-2aa4-49a8-cff5-8a91c5a3af18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bytelatent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-827ba4edff9a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_consolidated_model_and_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_blt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_nocache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1) Point this to the folder containing:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#    hf-weights/blt-1b/consolidated.safetensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bytelatent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from safetensors.torch import load_file\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.tokenizers.blt_tokenizer import BltTokenizer\n",
        "from bytelatent.generate_blt import generate_nocache\n",
        "from bytelatent.train.config import TrainConfig  # adjust import to where your config loader lives\n",
        "\n",
        "# 1) Load raw weights\n",
        "model_weights   = load_file(\"/content/safetensors/ blt_1b/consolidated.safetensors\")\n",
        "entropy_weights = load_file(\"safetensors/entropy_model/consolidated.safetensors\")\n",
        "\n",
        "# 2) Instantiate your model and tokenizer\n",
        "#    -- you need a TrainConfig or Config object with the same architecture\n",
        "train_cfg = TrainConfig.from_yaml(\"path/to/your/train_config.yaml\")\n",
        "cfg       = train_cfg.model        # or however your config is stored\n",
        "model     = ByteLatentTransformer(cfg)\n",
        "tokenizer = BltTokenizer()\n",
        "\n",
        "# 3) Load weights into model\n",
        "model.load_state_dict(model_weights, strict=True)\n",
        "\n",
        "# 4) Build the patcher and load entropy model weights\n",
        "patcher_args = train_cfg.data.patcher_args.model_copy(deep=True)\n",
        "patcher_args.realtime_patching = True\n",
        "# you may need to manually load entropy into the patcher submodule:\n",
        "patcher = patcher_args.build()\n",
        "patcher.entropy_model.load_state_dict(entropy_weights, strict=True)\n",
        "\n",
        "# 5) Run generation\n",
        "prompt  = \"Once upon a time\"\n",
        "outputs = generate_nocache([prompt], model=model, tokenizer=tokenizer, patcher=patcher)\n",
        "\n",
        "for out in outputs:\n",
        "    print(tokenizer.decode(out))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "cgv3JPUh8MMZ",
        "outputId": "d8606fbe-2853-493b-e63c-a836441a220f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bytelatent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8b6a13b35d02>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msafetensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblt_tokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBltTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_blt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_nocache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bytelatent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/blt.git      # Or update your clone\n",
        "%cd blt\n",
        "!pip install -e .                                          # Reads setup.py and installs 'bytelatent' locally :contentReference[oaicite:5]{index=5}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vdm6-nb8cWJ",
        "outputId": "dfb5d3a1-94a8-4e35-99e3-fd0c71575db3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'blt'...\n",
            "remote: Enumerating objects: 1133, done.\u001b[K\n",
            "remote: Counting objects: 100% (303/303), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 1133 (delta 244), reused 214 (delta 214), pack-reused 830 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1133/1133), 611.70 KiB | 10.73 MiB/s, done.\n",
            "Resolving deltas: 100% (737/737), done.\n",
            "/content/blt\n",
            "Obtaining file:///content/blt\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bytelatent==0.1.0) (0.2.0)\n",
            "Collecting tiktoken (from bytelatent==0.1.0)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting xformers (from bytelatent==0.1.0)\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->bytelatent==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->bytelatent==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers->bytelatent==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers->bytelatent==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers->bytelatent==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers->bytelatent==0.1.0) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.6/664.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:56\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    unknown package:\n",
            "        Expected sha256 165764f44ef8c61fcdfdfdbe769d687e06374059fbb388b6c89ecb0e28793a6f\n",
            "             Got        730400f46ed383778979040b8b811fbfa2a4f3e52c3751344d853ce2f4762014\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/blt.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW-Cn-kM8gvw",
        "outputId": "7b5025f6-0286-4ba6-820f-03b76dddb46f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/blt.git\n",
            "  Cloning https://github.com/facebookresearch/blt.git to /tmp/pip-req-build-qh4qrm_8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/blt.git /tmp/pip-req-build-qh4qrm_8\n",
            "  Resolved https://github.com/facebookresearch/blt.git to commit 1b67cbe02202d312eafa4153bf7d1442dac5ce49\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bytelatent==0.1.0) (0.2.0)\n",
            "Collecting tiktoken (from bytelatent==0.1.0)\n",
            "  Using cached tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting xformers (from bytelatent==0.1.0)\n",
            "  Using cached xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->bytelatent==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->bytelatent==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers->bytelatent==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers->bytelatent==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->xformers->bytelatent==0.1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers->bytelatent==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers->bytelatent==0.1.0) (3.0.2)\n",
            "Using cached tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Using cached xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Building wheels for collected packages: bytelatent\n",
            "  Building wheel for bytelatent (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bytelatent: filename=bytelatent-0.1.0-py3-none-any.whl size=147313 sha256=8e1731cde2184538577e8b863190a3efe5a82c0162eafb63e528c2b730e977f9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dkzg95tf/wheels/3d/64/37/67643000e3de9ec8337f8a465a24a1953deec045a9456d1270\n",
            "Successfully built bytelatent\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, xformers, bytelatent\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bytelatent-0.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tiktoken-0.9.0 xformers-0.0.29.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import bytelatent; print(bytelatent.__version__)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlqeyTg-8rv4",
        "outputId": "64df3dd6-276b-4afb-804a-7dbd9ede1a2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "AttributeError: module 'bytelatent' has no attribute '__version__'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bytelatent --v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6rHdmh89dRK",
        "outputId": "c94d0492-cc31-4389-e9f2-e35da01c4c7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: bytelatent: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n"
      ],
      "metadata": {
        "id": "wVXvLDnb9few"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load BLT-1B model\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "\n",
        "# Load entropy model\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# Define model architecture\n",
        "class BLT1BModel(nn.Module):\n",
        "    def __init__(self, model_weights, entropy_weights):\n",
        "        super().__init__()\n",
        "        self.config = self._extract_config_from_weights(model_weights)\n",
        "\n",
        "        # Initialize model components\n",
        "        self.token_embeddings = nn.Embedding(self.config['vocab_size'], self.config['d_model'])\n",
        "        self.position_embeddings = nn.Embedding(self.config['max_position_embeddings'], self.config['d_model'])\n",
        "\n",
        "        # Initialize transformer layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(self.config) for _ in range(self.config['n_layers'])\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.norm = nn.LayerNorm(self.config['d_model'])\n",
        "        self.lm_head = nn.Linear(self.config['d_model'], self.config['vocab_size'], bias=False)\n",
        "\n",
        "        # Load weights\n",
        "        self._load_weights(model_weights)\n",
        "\n",
        "        # Entropy model\n",
        "        self.entropy_model = EntropyModel(entropy_weights)\n",
        "\n",
        "    def _extract_config_from_weights(self, weights):\n",
        "        # Extract model dimensions from weight shapes\n",
        "        config = {\n",
        "            'vocab_size': weights['token_embeddings.weight'].shape[0],\n",
        "            'd_model': weights['token_embeddings.weight'].shape[1],\n",
        "            'n_layers': sum(1 for k in weights if 'layers' in k and 'attention.q_proj.weight' in k),\n",
        "            'n_heads': weights['layers.0.attention.q_proj.weight'].shape[0] // weights['layers.0.attention.q_proj.weight'].shape[1],\n",
        "            'max_position_embeddings': weights.get('position_embeddings.weight', torch.zeros(2048, 768)).shape[0],\n",
        "        }\n",
        "        return config\n",
        "\n",
        "    def _load_weights(self, weights):\n",
        "        # Load embeddings\n",
        "        self.token_embeddings.weight.data = weights['token_embeddings.weight']\n",
        "        if 'position_embeddings.weight' in weights:\n",
        "            self.position_embeddings.weight.data = weights['position_embeddings.weight']\n",
        "\n",
        "        # Load transformer layers\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            prefix = f'layers.{i}.'\n",
        "            # Load attention weights\n",
        "            layer.attention.q_proj.weight.data = weights[f'{prefix}attention.q_proj.weight']\n",
        "            layer.attention.k_proj.weight.data = weights[f'{prefix}attention.k_proj.weight']\n",
        "            layer.attention.v_proj.weight.data = weights[f'{prefix}attention.v_proj.weight']\n",
        "            layer.attention.out_proj.weight.data = weights[f'{prefix}attention.out_proj.weight']\n",
        "\n",
        "            # Load MLP weights\n",
        "            layer.mlp.fc1.weight.data = weights[f'{prefix}mlp.fc1.weight']\n",
        "            layer.mlp.fc2.weight.data = weights[f'{prefix}mlp.fc2.weight']\n",
        "\n",
        "            # Load norms\n",
        "            layer.attention_norm.weight.data = weights[f'{prefix}attention_norm.weight']\n",
        "            layer.ffn_norm.weight.data = weights[f'{prefix}ffn_norm.weight']\n",
        "\n",
        "        # Load output layer\n",
        "        self.norm.weight.data = weights['norm.weight']\n",
        "        self.lm_head.weight.data = weights['lm_head.weight']\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        # Get sequence length\n",
        "        seq_length = input_ids.size(1)\n",
        "\n",
        "        # Get embeddings\n",
        "        token_emb = self.token_embeddings(input_ids)\n",
        "\n",
        "        # Add positional embeddings\n",
        "        position_ids = torch.arange(0, seq_length, dtype=torch.long, device=input_ids.device).unsqueeze(0)\n",
        "        position_emb = self.position_embeddings(position_ids)\n",
        "\n",
        "        hidden_states = token_emb + position_emb\n",
        "\n",
        "        # Apply transformer layers\n",
        "        for layer in self.layers:\n",
        "            hidden_states = layer(hidden_states, attention_mask)\n",
        "\n",
        "        # Apply final normalization\n",
        "        hidden_states = self.norm(hidden_states)\n",
        "\n",
        "        # Get logits\n",
        "        logits = self.lm_head(hidden_states)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(self, input_ids, max_length=100, temperature=1.0, top_k=50, top_p=0.95):\n",
        "        \"\"\"Generate text using the model\"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        input_ids = input_ids.to(device)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # Get model output for the current sequence\n",
        "            with torch.no_grad():\n",
        "                outputs = self(input_ids)\n",
        "                next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "                # Apply entropy model for better sampling\n",
        "                next_token_logits = self.entropy_model(next_token_logits)\n",
        "\n",
        "                # Apply top-k filtering\n",
        "                if top_k > 0:\n",
        "                    indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
        "                    next_token_logits[indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # Apply top-p (nucleus) filtering\n",
        "                if top_p < 1.0:\n",
        "                    sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
        "                    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                    # Remove tokens with cumulative probability above the threshold\n",
        "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                    # Shift the indices to the right to keep also the first token above the threshold\n",
        "                    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "                    sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                    indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "                    next_token_logits[indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # Sample next token\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                # Append next token to the sequence\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "                # Check if we've generated an EOS token\n",
        "                if next_token[0, 0].item() == self.config.get('eos_token_id', -1):\n",
        "                    break\n",
        "\n",
        "        return input_ids\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = SelfAttention(config)\n",
        "        self.attention_norm = nn.LayerNorm(config['d_model'])\n",
        "        self.mlp = MLP(config)\n",
        "        self.ffn_norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        # Self-attention with residual connection\n",
        "        attn_output = self.attention(self.attention_norm(x), attention_mask)\n",
        "        x = x + attn_output\n",
        "\n",
        "        # MLP with residual connection\n",
        "        mlp_output = self.mlp(self.ffn_norm(x))\n",
        "        x = x + mlp_output\n",
        "\n",
        "        return x\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_model = config['d_model']\n",
        "        self.n_heads = config['n_heads']\n",
        "        self.head_dim = self.d_model // self.n_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.k_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.v_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.out_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Project queries, keys, values\n",
        "        q = self.q_proj(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.k_proj(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.v_proj(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # Apply attention mask if provided\n",
        "        if attention_mask is not None:\n",
        "            scores = scores + attention_mask\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to values\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Reshape and apply output projection\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        output = self.out_proj(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(config['d_model'], 4 * config['d_model'], bias=False)\n",
        "        self.fc2 = nn.Linear(4 * config['d_model'], config['d_model'], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class EntropyModel(nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super().__init__()\n",
        "        # Extract dimensions from weights\n",
        "        hidden_dim = weights.get('fc1.weight', torch.zeros(1, 768)).shape[1]\n",
        "        output_dim = weights.get('fc2.weight', torch.zeros(768, 1)).shape[0]\n",
        "\n",
        "        # Define entropy model layers\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
        "        self.fc2 = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "        # Load weights\n",
        "        self._load_weights(weights)\n",
        "\n",
        "    def _load_weights(self, weights):\n",
        "        # Load weights if available\n",
        "        if 'fc1.weight' in weights:\n",
        "            self.fc1.weight.data = weights['fc1.weight']\n",
        "            if 'fc1.bias' in weights:\n",
        "                self.fc1.bias.data = weights['fc1.bias']\n",
        "\n",
        "        if 'fc2.weight' in weights:\n",
        "            self.fc2.weight.data = weights['fc2.weight']\n",
        "            if 'fc2.bias' in weights:\n",
        "                self.fc2.bias.data = weights['fc2.bias']\n",
        "\n",
        "    def forward(self, logits):\n",
        "        # Apply entropy adjustment to logits\n",
        "        x = F.relu(self.fc1(logits))\n",
        "        entropy_adjustment = self.fc2(x)\n",
        "        return logits + entropy_adjustment\n",
        "\n",
        "# Example usage\n",
        "def load_tokenizer():\n",
        "    # Placeholder for tokenizer loading code\n",
        "    # You would need to implement this based on your tokenizer\n",
        "    pass\n",
        "\n",
        "def inference_example():\n",
        "    # Create the model\n",
        "    model = BLT1BModel(model_weights, entropy_weights)\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = load_tokenizer()\n",
        "\n",
        "    # Example prompt\n",
        "    prompt = \"Once upon a time\"\n",
        "\n",
        "    # Tokenize input\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    # Generate text\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=100,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95\n",
        "    )\n",
        "\n",
        "    # Decode output\n",
        "    generated_text = tokenizer.decode(output_ids[0])\n",
        "    print(generated_text)\n",
        "\n",
        "# Uncomment to run inference\n",
        "# inference_example()"
      ],
      "metadata": {
        "id": "bZc7E_GU9uPg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "\n",
        "# دالة للتحقق من وجود الملفات\n",
        "def check_files():\n",
        "    print(\"جاري التحقق من وجود الملفات...\")\n",
        "\n",
        "    blt_path = '/content/safetensors/blt_1b/consolidated.safetensors'\n",
        "    entropy_path = '/content/safetensors/entropy_model/consolidated.safetensors'\n",
        "\n",
        "    if not os.path.exists(blt_path):\n",
        "        print(f\"خطأ: الملف غير موجود في المسار: {blt_path}\")\n",
        "    else:\n",
        "        print(f\"✓ تم العثور على ملف BLT-1B: {blt_path}\")\n",
        "\n",
        "    if not os.path.exists(entropy_path):\n",
        "        print(f\"خطأ: الملف غير موجود في المسار: {entropy_path}\")\n",
        "    else:\n",
        "        print(f\"✓ تم العثور على ملف نموذج Entropy: {entropy_path}\")\n",
        "\n",
        "# دالة لتحميل النماذج مع معالجة الأخطاء\n",
        "def load_models():\n",
        "    print(\"جاري محاولة تحميل النماذج...\")\n",
        "\n",
        "    try:\n",
        "        print(\"بدء تحميل نموذج BLT-1B...\")\n",
        "        start_time = time.time()\n",
        "        model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "        end_time = time.time()\n",
        "        print(f\"✓ تم تحميل نموذج BLT-1B بنجاح في {end_time - start_time:.2f} ثانية\")\n",
        "        print(f\"- عدد المفاتيح: {len(model_weights)}\")\n",
        "\n",
        "        # عرض بعض المفاتيح كعينة\n",
        "        keys = list(model_weights.keys())\n",
        "        if keys:\n",
        "            print(\"- أمثلة للمفاتيح:\")\n",
        "            for key in keys[:5]:  # عرض أول 5 مفاتيح\n",
        "                print(f\"  * {key}: شكل {model_weights[key].shape}\")\n",
        "\n",
        "        print(\"\\nبدء تحميل نموذج Entropy...\")\n",
        "        start_time = time.time()\n",
        "        entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "        end_time = time.time()\n",
        "        print(f\"✓ تم تحميل نموذج Entropy بنجاح في {end_time - start_time:.2f} ثانية\")\n",
        "        print(f\"- عدد المفاتيح: {len(entropy_weights)}\")\n",
        "\n",
        "        # عرض بعض المفاتيح كعينة\n",
        "        keys = list(entropy_weights.keys())\n",
        "        if keys:\n",
        "            print(\"- أمثلة للمفاتيح:\")\n",
        "            for key in keys[:5]:  # عرض أول 5 مفاتيح\n",
        "                print(f\"  * {key}: شكل {entropy_weights[key].shape}\")\n",
        "\n",
        "        return model_weights, entropy_weights\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"خطأ: الملف غير موجود: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"خطأ غير متوقع أثناء تحميل الملفات: {str(e)}\")\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# استخراج معلومات التكوين من النموذج\n",
        "def extract_config(model_weights):\n",
        "    if not model_weights:\n",
        "        print(\"لا يمكن استخراج التكوين: النموذج غير محمل\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\nجاري استخراج معلومات التكوين من النموذج...\")\n",
        "\n",
        "    try:\n",
        "        # البحث عن مفاتيح مفيدة لاستخراج المعلومات\n",
        "        vocab_size = None\n",
        "        d_model = None\n",
        "        n_layers = 0\n",
        "\n",
        "        # البحث عن معلومات embedding\n",
        "        for key in model_weights.keys():\n",
        "            if 'embed' in key.lower() or 'token' in key.lower():\n",
        "                shape = model_weights[key].shape\n",
        "                print(f\"وجدت مصفوفة embedding محتملة: {key} بشكل {shape}\")\n",
        "                if len(shape) == 2:\n",
        "                    vocab_size = shape[0]\n",
        "                    d_model = shape[1]\n",
        "                    print(f\"- حجم المفردات المحتمل: {vocab_size}\")\n",
        "                    print(f\"- أبعاد النموذج المحتملة: {d_model}\")\n",
        "\n",
        "        # حساب عدد الطبقات\n",
        "        layer_keys = [key for key in model_weights.keys() if 'layers' in key]\n",
        "        if layer_keys:\n",
        "            layer_numbers = set()\n",
        "            for key in layer_keys:\n",
        "                parts = key.split('.')\n",
        "                for i, part in enumerate(parts):\n",
        "                    if part == 'layers' and i+1 < len(parts) and parts[i+1].isdigit():\n",
        "                        layer_numbers.add(int(parts[i+1]))\n",
        "\n",
        "            n_layers = max(layer_numbers) + 1 if layer_numbers else 0\n",
        "            print(f\"- عدد الطبقات المحتمل: {n_layers}\")\n",
        "\n",
        "        config = {\n",
        "            'vocab_size': vocab_size,\n",
        "            'd_model': d_model,\n",
        "            'n_layers': n_layers\n",
        "        }\n",
        "\n",
        "        print(\"تم استخراج التكوين بنجاح:\")\n",
        "        for key, value in config.items():\n",
        "            print(f\"- {key}: {value}\")\n",
        "\n",
        "        return config\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"خطأ أثناء استخراج التكوين: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# الدالة الرئيسية\n",
        "def main():\n",
        "    print(\"=== تشخيص نموذج BLT-1B ===\")\n",
        "\n",
        "    # التحقق من وجود الملفات\n",
        "    check_files()\n",
        "\n",
        "    # محاولة تحميل النماذج\n",
        "    model_weights, entropy_weights = load_models()\n",
        "\n",
        "    # استخراج التكوين إذا تم تحميل النموذج بنجاح\n",
        "    if model_weights is not None:\n",
        "        config = extract_config(model_weights)\n",
        "\n",
        "    print(\"\\nاكتمل التشخيص.\")\n",
        "    print(\"يمكنك الآن استخدام معلومات التكوين لبناء نموذج كامل استناداً إلى هذه البيانات.\")\n",
        "\n",
        "# تشغيل الكود\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v5yRZOc-rVS",
        "outputId": "b9755187-f419-444a-9fc2-38e3ea33d1cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== تشخيص نموذج BLT-1B ===\n",
            "جاري التحقق من وجود الملفات...\n",
            "✓ تم العثور على ملف BLT-1B: /content/safetensors/blt_1b/consolidated.safetensors\n",
            "✓ تم العثور على ملف نموذج Entropy: /content/safetensors/entropy_model/consolidated.safetensors\n",
            "جاري محاولة تحميل النماذج...\n",
            "بدء تحميل نموذج BLT-1B...\n",
            "✓ تم تحميل نموذج BLT-1B بنجاح في 0.04 ثانية\n",
            "- عدد المفاتيح: 386\n",
            "- أمثلة للمفاتيح:\n",
            "  * encoder_hash_tok_embedding.0.weight: شكل torch.Size([500002, 1024])\n",
            "  * encoder_hash_tok_embedding.1.weight: شكل torch.Size([500002, 1024])\n",
            "  * encoder_hash_tok_embedding.2.weight: شكل torch.Size([500002, 1024])\n",
            "  * encoder_hash_tok_embedding.3.weight: شكل torch.Size([500002, 1024])\n",
            "  * encoder_hash_tok_embedding.4.weight: شكل torch.Size([500002, 1024])\n",
            "\n",
            "بدء تحميل نموذج Entropy...\n",
            "✓ تم تحميل نموذج Entropy بنجاح في 0.01 ثانية\n",
            "- عدد المفاتيح: 129\n",
            "- أمثلة للمفاتيح:\n",
            "  * layers.0.attention.wk.weight: شكل torch.Size([768, 768])\n",
            "  * layers.0.attention.wo.weight: شكل torch.Size([768, 768])\n",
            "  * layers.0.attention.wq.weight: شكل torch.Size([768, 768])\n",
            "  * layers.0.attention.wv.weight: شكل torch.Size([768, 768])\n",
            "  * layers.0.attention_norm.weight: شكل torch.Size([768])\n",
            "\n",
            "جاري استخراج معلومات التكوين من النموذج...\n",
            "وجدت مصفوفة embedding محتملة: encoder_hash_tok_embedding.0.weight بشكل torch.Size([500002, 1024])\n",
            "- حجم المفردات المحتمل: 500002\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: encoder_hash_tok_embedding.1.weight بشكل torch.Size([500002, 1024])\n",
            "- حجم المفردات المحتمل: 500002\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: encoder_hash_tok_embedding.2.weight بشكل torch.Size([500002, 1024])\n",
            "- حجم المفردات المحتمل: 500002\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: encoder_hash_tok_embedding.3.weight بشكل torch.Size([500002, 1024])\n",
            "- حجم المفردات المحتمل: 500002\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: encoder_hash_tok_embedding.4.weight بشكل torch.Size([500002, 1024])\n",
            "- حجم المفردات المحتمل: 500002\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: encoder_hash_tok_embedding.5.weight بشكل torch.Size([500002, 1024])\n",
            "- حجم المفردات المحتمل: 500002\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: local_decoder.patch_embedding_projection.weight بشكل torch.Size([2048, 2048])\n",
            "- حجم المفردات المحتمل: 2048\n",
            "- أبعاد النموذج المحتملة: 2048\n",
            "وجدت مصفوفة embedding محتملة: local_encoder.patch_embedding_projection.weight بشكل torch.Size([2048, 1024])\n",
            "- حجم المفردات المحتمل: 2048\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "وجدت مصفوفة embedding محتملة: local_encoder.tok_embeddings.weight بشكل torch.Size([260, 1024])\n",
            "- حجم المفردات المحتمل: 260\n",
            "- أبعاد النموذج المحتملة: 1024\n",
            "- عدد الطبقات المحتمل: 25\n",
            "تم استخراج التكوين بنجاح:\n",
            "- vocab_size: 260\n",
            "- d_model: 1024\n",
            "- n_layers: 25\n",
            "\n",
            "اكتمل التشخيص.\n",
            "يمكنك الآن استخدام معلومات التكوين لبناء نموذج كامل استناداً إلى هذه البيانات.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# تحميل النماذج\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# تعريف التكوين بناءً على المعلومات المستخرجة\n",
        "MODEL_CONFIG = {\n",
        "    'vocab_size': 260,  # حجم المفردات من التشخيص\n",
        "    'd_model': 1024,    # أبعاد النموذج من التشخيص\n",
        "    'n_layers': 25,     # عدد الطبقات من التشخيص\n",
        "    'n_heads': 16,      # عدد رؤوس الانتباه (تقدير: عادة ما تكون d_model/64)\n",
        "    'max_seq_len': 2048 # الحد الأقصى لطول التسلسل (تقدير)\n",
        "}\n",
        "\n",
        "class BLTAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_model = config['d_model']\n",
        "        self.n_heads = config['n_heads']\n",
        "        self.head_dim = self.d_model // self.n_heads\n",
        "\n",
        "        # مشابه للمفاتيح التي وجدناها في التشخيص\n",
        "        self.wq = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wk = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wv = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wo = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # تطبيق التحويلات الخطية\n",
        "        q = self.wq(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.wk(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.wv(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # حساب درجات الانتباه\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # تطبيق القناع إذا كان موجودًا\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # تطبيق softmax للحصول على أوزان الانتباه\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # تطبيق أوزان الانتباه على القيم\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # إعادة تشكيل وتطبيق الإسقاط النهائي\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        output = self.wo(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "class BLTFFN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(config['d_model'], 4 * config['d_model'], bias=False)\n",
        "        self.w2 = nn.Linear(4 * config['d_model'], config['d_model'], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(F.gelu(self.w1(x)))\n",
        "\n",
        "class BLTBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = BLTAttention(config)\n",
        "        self.attention_norm = nn.LayerNorm(config['d_model'])\n",
        "        self.ffn = BLTFFN(config)\n",
        "        self.ffn_norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # طبقة الانتباه مع اتصال متبقي\n",
        "        attn_output = self.attention(self.attention_norm(x), mask)\n",
        "        x = x + attn_output\n",
        "\n",
        "        # طبقة FFN مع اتصال متبقي\n",
        "        ffn_output = self.ffn(self.ffn_norm(x))\n",
        "        x = x + ffn_output\n",
        "\n",
        "        return x\n",
        "\n",
        "class BLTModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # طبقة التضمين\n",
        "        self.tok_embeddings = nn.Embedding(config['vocab_size'], config['d_model'])\n",
        "\n",
        "        # طبقات المحول\n",
        "        self.layers = nn.ModuleList([\n",
        "            BLTBlock(config) for _ in range(config['n_layers'])\n",
        "        ])\n",
        "\n",
        "        # طبقة التطبيع النهائية\n",
        "        self.norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "        # رأس التوقع\n",
        "        self.output = nn.Linear(config['d_model'], config['vocab_size'], bias=False)\n",
        "\n",
        "    def _init_weights_from_model(self, weights):\n",
        "        print(\"تهيئة أوزان النموذج من الملف المحمل...\")\n",
        "\n",
        "        # قائمة المفاتيح التي تم تحميلها بنجاح\n",
        "        loaded_keys = []\n",
        "\n",
        "        # تحميل التضمينات\n",
        "        if 'local_encoder.tok_embeddings.weight' in weights:\n",
        "            self.tok_embeddings.weight.data = weights['local_encoder.tok_embeddings.weight']\n",
        "            loaded_keys.append('local_encoder.tok_embeddings.weight')\n",
        "\n",
        "        # تحميل طبقات المحول\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            prefix = f'layers.{i}.'\n",
        "\n",
        "            # تحميل أوزان الانتباه\n",
        "            for name, param in [\n",
        "                ('attention.wq.weight', layer.attention.wq.weight),\n",
        "                ('attention.wk.weight', layer.attention.wk.weight),\n",
        "                ('attention.wv.weight', layer.attention.wv.weight),\n",
        "                ('attention.wo.weight', layer.attention.wo.weight),\n",
        "                ('attention_norm.weight', layer.attention_norm.weight),\n",
        "                ('ffn_norm.weight', layer.ffn_norm.weight)\n",
        "            ]:\n",
        "                key = prefix + name\n",
        "                if key in weights:\n",
        "                    param.data = weights[key]\n",
        "                    loaded_keys.append(key)\n",
        "\n",
        "            # تحميل أوزان FFN\n",
        "            # قد تختلف الأسماء حسب النموذج الفعلي\n",
        "            ffn_keys = [k for k in weights.keys() if prefix in k and ('feed_forward' in k or 'ffn' in k)]\n",
        "            if len(ffn_keys) >= 2:  # نفترض وجود وزنين على الأقل لطبقة FFN\n",
        "                for key in ffn_keys:\n",
        "                    if 'w1' in key or 'fc1' in key:\n",
        "                        layer.ffn.w1.weight.data = weights[key]\n",
        "                        loaded_keys.append(key)\n",
        "                    elif 'w2' in key or 'fc2' in key:\n",
        "                        layer.ffn.w2.weight.data = weights[key]\n",
        "                        loaded_keys.append(key)\n",
        "\n",
        "        # تحميل طبقة التطبيع النهائية\n",
        "        norm_keys = [k for k in weights.keys() if 'norm' in k and not any(x in k for x in ['attention', 'ffn'])]\n",
        "        if norm_keys:\n",
        "            self.norm.weight.data = weights[norm_keys[0]]\n",
        "            loaded_keys.append(norm_keys[0])\n",
        "\n",
        "        # تحميل رأس الإخراج\n",
        "        output_keys = [k for k in weights.keys() if 'lm_head' in k or 'output' in k]\n",
        "        if output_keys:\n",
        "            self.output.weight.data = weights[output_keys[0]]\n",
        "            loaded_keys.append(output_keys[0])\n",
        "\n",
        "        print(f\"تم تحميل {len(loaded_keys)} من أصل {len(weights)} مفتاح من النموذج\")\n",
        "        return loaded_keys\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "\n",
        "        # الحصول على التضمينات\n",
        "        h = self.tok_embeddings(input_ids)\n",
        "\n",
        "        # إنشاء قناع الانتباه إذا لم يتم توفيره\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones((batch_size, seq_len, seq_len), device=input_ids.device)\n",
        "\n",
        "        # تطبيق طبقات المحول\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, attention_mask)\n",
        "\n",
        "        # تطبيق التطبيع النهائي\n",
        "        h = self.norm(h)\n",
        "\n",
        "        # الحصول على التوقعات\n",
        "        logits = self.output(h)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(self, input_ids, max_length=100, temperature=0.8, top_k=40, top_p=0.9):\n",
        "        \"\"\"توليد النص باستخدام النموذج\"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        input_ids = input_ids.to(device)\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # الحصول على نتائج النموذج للتسلسل الحالي\n",
        "            with torch.no_grad():\n",
        "                outputs = self(input_ids)\n",
        "                next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "                # تطبيق تصفية top-k\n",
        "                if top_k > 0:\n",
        "                    indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
        "                    next_token_logits[indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # تطبيق تصفية top-p (nucleus)\n",
        "                if top_p < 1.0:\n",
        "                    sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
        "                    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                    # إزالة الرموز ذات الاحتمال التراكمي فوق العتبة\n",
        "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                    # نقل المؤشرات إلى اليمين للحفاظ أيضًا على الرمز الأول فوق العتبة\n",
        "                    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "                    sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                    for batch_idx in range(batch_size):\n",
        "                        indices_to_remove = sorted_indices[batch_idx][sorted_indices_to_remove[batch_idx]]\n",
        "                        next_token_logits[batch_idx, indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # اختيار الرمز التالي\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                # إضافة الرمز التالي إلى التسلسل\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "                # التحقق مما إذا كنا قد أنشأنا رمز EOS\n",
        "                if (next_token == self.config.get('eos_token_id', -1)).any():\n",
        "                    break\n",
        "\n",
        "        return input_ids\n",
        "\n",
        "def load_tokenizer(vocab_size=260):\n",
        "    \"\"\"استبدال مؤقت للمحول - تنفيذ بسيط\"\"\"\n",
        "    class SimpleTokenizer:\n",
        "        def __init__(self, vocab_size):\n",
        "            self.vocab_size = vocab_size\n",
        "\n",
        "        def __call__(self, text, return_tensors=\"pt\"):\n",
        "            # هذا مجرد محاكاة، في الواقع تحتاج إلى تنفيذ التحويل الفعلي\n",
        "            # هنا نقوم بتحويل كل حرف إلى رقم بسيط\n",
        "            tokens = [ord(c) % (self.vocab_size - 4) + 4 for c in text]\n",
        "            if return_tensors == \"pt\":\n",
        "                return SimpleNamespace(input_ids=torch.tensor([tokens]))\n",
        "            return tokens\n",
        "\n",
        "        def decode(self, ids):\n",
        "            # تحويل الرموز مرة أخرى إلى نص\n",
        "            if isinstance(ids, torch.Tensor):\n",
        "                ids = ids.tolist()\n",
        "            text = \"\"\n",
        "            for id in ids:\n",
        "                if id >= 4 and id < self.vocab_size:\n",
        "                    text += chr((id - 4) % 26 + 97)  # تحويل بسيط إلى أحرف\n",
        "            return text\n",
        "\n",
        "    return SimpleTokenizer(vocab_size)\n",
        "\n",
        "class SimpleNamespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "# دالة لتنفيذ النموذج واختباره\n",
        "def run_model():\n",
        "    print(\"تهيئة النموذج...\")\n",
        "    model = BLTModel(MODEL_CONFIG)\n",
        "    loaded_keys = model._init_weights_from_model(model_weights)\n",
        "\n",
        "    print(\"تجهيز واختبار المحول...\")\n",
        "    tokenizer = load_tokenizer(MODEL_CONFIG['vocab_size'])\n",
        "\n",
        "    print(\"اختبار النموذج مع مثال بسيط...\")\n",
        "    prompt = \"hi\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    print(f\"المدخل: '{prompt}'\")\n",
        "    print(f\"رموز المدخل: {input_ids.tolist()}\")\n",
        "\n",
        "    print(\"بدء التوليد...\")\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=20,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(output_ids[0])\n",
        "    print(f\"النص المولد: '{generated_text}'\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# تشغيل النموذج\n",
        "if __name__ == \"__main__\":\n",
        "    run_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "04KkrMt3-rn5",
        "outputId": "29ea59d0-4d31-46b6-b466-d668c3c9a9d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تهيئة النموذج...\n",
            "تهيئة أوزان النموذج من الملف المحمل...\n",
            "تم تحميل 73 من أصل 386 مفتاح من النموذج\n",
            "تجهيز واختبار المحول...\n",
            "اختبار النموذج مع مثال بسيط...\n",
            "المدخل: 'hi'\n",
            "رموز المدخل: [[108, 109]]\n",
            "بدء التوليد...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-93ac80a83379>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;31m# تشغيل النموذج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-93ac80a83379>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"بدء التوليد...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         output_ids = model.generate(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-93ac80a83379>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, temperature, top_k, top_p)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# الحصول على نتائج النموذج للتسلسل الحالي\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-93ac80a83379>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# تطبيق طبقات المحول\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# تطبيق التطبيع النهائي\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-93ac80a83379>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# طبقة الانتباه مع اتصال متبقي\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-93ac80a83379>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# تطبيق التحويلات الخطية\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([key for key in model_weights.keys()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR_Kkfpb_U4S",
        "outputId": "df85cb66-1e63-4050-8874-56ba9a9abc5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['encoder_hash_tok_embedding.0.weight', 'encoder_hash_tok_embedding.1.weight', 'encoder_hash_tok_embedding.2.weight', 'encoder_hash_tok_embedding.3.weight', 'encoder_hash_tok_embedding.4.weight', 'encoder_hash_tok_embedding.5.weight', 'global_transformer.layers.0.attention.wk.weight', 'global_transformer.layers.0.attention.wo.weight', 'global_transformer.layers.0.attention.wq.weight', 'global_transformer.layers.0.attention.wv.weight', 'global_transformer.layers.0.attention_norm.weight', 'global_transformer.layers.0.feed_forward.w1.weight', 'global_transformer.layers.0.feed_forward.w2.weight', 'global_transformer.layers.0.feed_forward.w3.weight', 'global_transformer.layers.0.ffn_norm.weight', 'global_transformer.layers.1.attention.wk.weight', 'global_transformer.layers.1.attention.wo.weight', 'global_transformer.layers.1.attention.wq.weight', 'global_transformer.layers.1.attention.wv.weight', 'global_transformer.layers.1.attention_norm.weight', 'global_transformer.layers.1.feed_forward.w1.weight', 'global_transformer.layers.1.feed_forward.w2.weight', 'global_transformer.layers.1.feed_forward.w3.weight', 'global_transformer.layers.1.ffn_norm.weight', 'global_transformer.layers.10.attention.wk.weight', 'global_transformer.layers.10.attention.wo.weight', 'global_transformer.layers.10.attention.wq.weight', 'global_transformer.layers.10.attention.wv.weight', 'global_transformer.layers.10.attention_norm.weight', 'global_transformer.layers.10.feed_forward.w1.weight', 'global_transformer.layers.10.feed_forward.w2.weight', 'global_transformer.layers.10.feed_forward.w3.weight', 'global_transformer.layers.10.ffn_norm.weight', 'global_transformer.layers.11.attention.wk.weight', 'global_transformer.layers.11.attention.wo.weight', 'global_transformer.layers.11.attention.wq.weight', 'global_transformer.layers.11.attention.wv.weight', 'global_transformer.layers.11.attention_norm.weight', 'global_transformer.layers.11.feed_forward.w1.weight', 'global_transformer.layers.11.feed_forward.w2.weight', 'global_transformer.layers.11.feed_forward.w3.weight', 'global_transformer.layers.11.ffn_norm.weight', 'global_transformer.layers.12.attention.wk.weight', 'global_transformer.layers.12.attention.wo.weight', 'global_transformer.layers.12.attention.wq.weight', 'global_transformer.layers.12.attention.wv.weight', 'global_transformer.layers.12.attention_norm.weight', 'global_transformer.layers.12.feed_forward.w1.weight', 'global_transformer.layers.12.feed_forward.w2.weight', 'global_transformer.layers.12.feed_forward.w3.weight', 'global_transformer.layers.12.ffn_norm.weight', 'global_transformer.layers.13.attention.wk.weight', 'global_transformer.layers.13.attention.wo.weight', 'global_transformer.layers.13.attention.wq.weight', 'global_transformer.layers.13.attention.wv.weight', 'global_transformer.layers.13.attention_norm.weight', 'global_transformer.layers.13.feed_forward.w1.weight', 'global_transformer.layers.13.feed_forward.w2.weight', 'global_transformer.layers.13.feed_forward.w3.weight', 'global_transformer.layers.13.ffn_norm.weight', 'global_transformer.layers.14.attention.wk.weight', 'global_transformer.layers.14.attention.wo.weight', 'global_transformer.layers.14.attention.wq.weight', 'global_transformer.layers.14.attention.wv.weight', 'global_transformer.layers.14.attention_norm.weight', 'global_transformer.layers.14.feed_forward.w1.weight', 'global_transformer.layers.14.feed_forward.w2.weight', 'global_transformer.layers.14.feed_forward.w3.weight', 'global_transformer.layers.14.ffn_norm.weight', 'global_transformer.layers.15.attention.wk.weight', 'global_transformer.layers.15.attention.wo.weight', 'global_transformer.layers.15.attention.wq.weight', 'global_transformer.layers.15.attention.wv.weight', 'global_transformer.layers.15.attention_norm.weight', 'global_transformer.layers.15.feed_forward.w1.weight', 'global_transformer.layers.15.feed_forward.w2.weight', 'global_transformer.layers.15.feed_forward.w3.weight', 'global_transformer.layers.15.ffn_norm.weight', 'global_transformer.layers.16.attention.wk.weight', 'global_transformer.layers.16.attention.wo.weight', 'global_transformer.layers.16.attention.wq.weight', 'global_transformer.layers.16.attention.wv.weight', 'global_transformer.layers.16.attention_norm.weight', 'global_transformer.layers.16.feed_forward.w1.weight', 'global_transformer.layers.16.feed_forward.w2.weight', 'global_transformer.layers.16.feed_forward.w3.weight', 'global_transformer.layers.16.ffn_norm.weight', 'global_transformer.layers.17.attention.wk.weight', 'global_transformer.layers.17.attention.wo.weight', 'global_transformer.layers.17.attention.wq.weight', 'global_transformer.layers.17.attention.wv.weight', 'global_transformer.layers.17.attention_norm.weight', 'global_transformer.layers.17.feed_forward.w1.weight', 'global_transformer.layers.17.feed_forward.w2.weight', 'global_transformer.layers.17.feed_forward.w3.weight', 'global_transformer.layers.17.ffn_norm.weight', 'global_transformer.layers.18.attention.wk.weight', 'global_transformer.layers.18.attention.wo.weight', 'global_transformer.layers.18.attention.wq.weight', 'global_transformer.layers.18.attention.wv.weight', 'global_transformer.layers.18.attention_norm.weight', 'global_transformer.layers.18.feed_forward.w1.weight', 'global_transformer.layers.18.feed_forward.w2.weight', 'global_transformer.layers.18.feed_forward.w3.weight', 'global_transformer.layers.18.ffn_norm.weight', 'global_transformer.layers.19.attention.wk.weight', 'global_transformer.layers.19.attention.wo.weight', 'global_transformer.layers.19.attention.wq.weight', 'global_transformer.layers.19.attention.wv.weight', 'global_transformer.layers.19.attention_norm.weight', 'global_transformer.layers.19.feed_forward.w1.weight', 'global_transformer.layers.19.feed_forward.w2.weight', 'global_transformer.layers.19.feed_forward.w3.weight', 'global_transformer.layers.19.ffn_norm.weight', 'global_transformer.layers.2.attention.wk.weight', 'global_transformer.layers.2.attention.wo.weight', 'global_transformer.layers.2.attention.wq.weight', 'global_transformer.layers.2.attention.wv.weight', 'global_transformer.layers.2.attention_norm.weight', 'global_transformer.layers.2.feed_forward.w1.weight', 'global_transformer.layers.2.feed_forward.w2.weight', 'global_transformer.layers.2.feed_forward.w3.weight', 'global_transformer.layers.2.ffn_norm.weight', 'global_transformer.layers.20.attention.wk.weight', 'global_transformer.layers.20.attention.wo.weight', 'global_transformer.layers.20.attention.wq.weight', 'global_transformer.layers.20.attention.wv.weight', 'global_transformer.layers.20.attention_norm.weight', 'global_transformer.layers.20.feed_forward.w1.weight', 'global_transformer.layers.20.feed_forward.w2.weight', 'global_transformer.layers.20.feed_forward.w3.weight', 'global_transformer.layers.20.ffn_norm.weight', 'global_transformer.layers.21.attention.wk.weight', 'global_transformer.layers.21.attention.wo.weight', 'global_transformer.layers.21.attention.wq.weight', 'global_transformer.layers.21.attention.wv.weight', 'global_transformer.layers.21.attention_norm.weight', 'global_transformer.layers.21.feed_forward.w1.weight', 'global_transformer.layers.21.feed_forward.w2.weight', 'global_transformer.layers.21.feed_forward.w3.weight', 'global_transformer.layers.21.ffn_norm.weight', 'global_transformer.layers.22.attention.wk.weight', 'global_transformer.layers.22.attention.wo.weight', 'global_transformer.layers.22.attention.wq.weight', 'global_transformer.layers.22.attention.wv.weight', 'global_transformer.layers.22.attention_norm.weight', 'global_transformer.layers.22.feed_forward.w1.weight', 'global_transformer.layers.22.feed_forward.w2.weight', 'global_transformer.layers.22.feed_forward.w3.weight', 'global_transformer.layers.22.ffn_norm.weight', 'global_transformer.layers.23.attention.wk.weight', 'global_transformer.layers.23.attention.wo.weight', 'global_transformer.layers.23.attention.wq.weight', 'global_transformer.layers.23.attention.wv.weight', 'global_transformer.layers.23.attention_norm.weight', 'global_transformer.layers.23.feed_forward.w1.weight', 'global_transformer.layers.23.feed_forward.w2.weight', 'global_transformer.layers.23.feed_forward.w3.weight', 'global_transformer.layers.23.ffn_norm.weight', 'global_transformer.layers.24.attention.wk.weight', 'global_transformer.layers.24.attention.wo.weight', 'global_transformer.layers.24.attention.wq.weight', 'global_transformer.layers.24.attention.wv.weight', 'global_transformer.layers.24.attention_norm.weight', 'global_transformer.layers.24.feed_forward.w1.weight', 'global_transformer.layers.24.feed_forward.w2.weight', 'global_transformer.layers.24.feed_forward.w3.weight', 'global_transformer.layers.24.ffn_norm.weight', 'global_transformer.layers.3.attention.wk.weight', 'global_transformer.layers.3.attention.wo.weight', 'global_transformer.layers.3.attention.wq.weight', 'global_transformer.layers.3.attention.wv.weight', 'global_transformer.layers.3.attention_norm.weight', 'global_transformer.layers.3.feed_forward.w1.weight', 'global_transformer.layers.3.feed_forward.w2.weight', 'global_transformer.layers.3.feed_forward.w3.weight', 'global_transformer.layers.3.ffn_norm.weight', 'global_transformer.layers.4.attention.wk.weight', 'global_transformer.layers.4.attention.wo.weight', 'global_transformer.layers.4.attention.wq.weight', 'global_transformer.layers.4.attention.wv.weight', 'global_transformer.layers.4.attention_norm.weight', 'global_transformer.layers.4.feed_forward.w1.weight', 'global_transformer.layers.4.feed_forward.w2.weight', 'global_transformer.layers.4.feed_forward.w3.weight', 'global_transformer.layers.4.ffn_norm.weight', 'global_transformer.layers.5.attention.wk.weight', 'global_transformer.layers.5.attention.wo.weight', 'global_transformer.layers.5.attention.wq.weight', 'global_transformer.layers.5.attention.wv.weight', 'global_transformer.layers.5.attention_norm.weight', 'global_transformer.layers.5.feed_forward.w1.weight', 'global_transformer.layers.5.feed_forward.w2.weight', 'global_transformer.layers.5.feed_forward.w3.weight', 'global_transformer.layers.5.ffn_norm.weight', 'global_transformer.layers.6.attention.wk.weight', 'global_transformer.layers.6.attention.wo.weight', 'global_transformer.layers.6.attention.wq.weight', 'global_transformer.layers.6.attention.wv.weight', 'global_transformer.layers.6.attention_norm.weight', 'global_transformer.layers.6.feed_forward.w1.weight', 'global_transformer.layers.6.feed_forward.w2.weight', 'global_transformer.layers.6.feed_forward.w3.weight', 'global_transformer.layers.6.ffn_norm.weight', 'global_transformer.layers.7.attention.wk.weight', 'global_transformer.layers.7.attention.wo.weight', 'global_transformer.layers.7.attention.wq.weight', 'global_transformer.layers.7.attention.wv.weight', 'global_transformer.layers.7.attention_norm.weight', 'global_transformer.layers.7.feed_forward.w1.weight', 'global_transformer.layers.7.feed_forward.w2.weight', 'global_transformer.layers.7.feed_forward.w3.weight', 'global_transformer.layers.7.ffn_norm.weight', 'global_transformer.layers.8.attention.wk.weight', 'global_transformer.layers.8.attention.wo.weight', 'global_transformer.layers.8.attention.wq.weight', 'global_transformer.layers.8.attention.wv.weight', 'global_transformer.layers.8.attention_norm.weight', 'global_transformer.layers.8.feed_forward.w1.weight', 'global_transformer.layers.8.feed_forward.w2.weight', 'global_transformer.layers.8.feed_forward.w3.weight', 'global_transformer.layers.8.ffn_norm.weight', 'global_transformer.layers.9.attention.wk.weight', 'global_transformer.layers.9.attention.wo.weight', 'global_transformer.layers.9.attention.wq.weight', 'global_transformer.layers.9.attention.wv.weight', 'global_transformer.layers.9.attention_norm.weight', 'global_transformer.layers.9.feed_forward.w1.weight', 'global_transformer.layers.9.feed_forward.w2.weight', 'global_transformer.layers.9.feed_forward.w3.weight', 'global_transformer.layers.9.ffn_norm.weight', 'local_decoder.cross_attn_layers.0.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.0.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.0.wk.weight', 'local_decoder.cross_attn_layers.0.wo.weight', 'local_decoder.cross_attn_layers.0.wq.weight', 'local_decoder.cross_attn_layers.0.wv.weight', 'local_decoder.cross_attn_layers.1.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.1.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.1.wk.weight', 'local_decoder.cross_attn_layers.1.wo.weight', 'local_decoder.cross_attn_layers.1.wq.weight', 'local_decoder.cross_attn_layers.1.wv.weight', 'local_decoder.cross_attn_layers.2.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.2.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.2.wk.weight', 'local_decoder.cross_attn_layers.2.wo.weight', 'local_decoder.cross_attn_layers.2.wq.weight', 'local_decoder.cross_attn_layers.2.wv.weight', 'local_decoder.cross_attn_layers.3.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.3.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.3.wk.weight', 'local_decoder.cross_attn_layers.3.wo.weight', 'local_decoder.cross_attn_layers.3.wq.weight', 'local_decoder.cross_attn_layers.3.wv.weight', 'local_decoder.cross_attn_layers.4.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.4.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.4.wk.weight', 'local_decoder.cross_attn_layers.4.wo.weight', 'local_decoder.cross_attn_layers.4.wq.weight', 'local_decoder.cross_attn_layers.4.wv.weight', 'local_decoder.cross_attn_layers.5.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.5.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.5.wk.weight', 'local_decoder.cross_attn_layers.5.wo.weight', 'local_decoder.cross_attn_layers.5.wq.weight', 'local_decoder.cross_attn_layers.5.wv.weight', 'local_decoder.cross_attn_layers.6.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.6.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.6.wk.weight', 'local_decoder.cross_attn_layers.6.wo.weight', 'local_decoder.cross_attn_layers.6.wq.weight', 'local_decoder.cross_attn_layers.6.wv.weight', 'local_decoder.cross_attn_layers.7.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.7.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.7.wk.weight', 'local_decoder.cross_attn_layers.7.wo.weight', 'local_decoder.cross_attn_layers.7.wq.weight', 'local_decoder.cross_attn_layers.7.wv.weight', 'local_decoder.cross_attn_layers.8.cross_attn_norm_kv.weight', 'local_decoder.cross_attn_layers.8.cross_attn_norm_q.weight', 'local_decoder.cross_attn_layers.8.wk.weight', 'local_decoder.cross_attn_layers.8.wo.weight', 'local_decoder.cross_attn_layers.8.wq.weight', 'local_decoder.cross_attn_layers.8.wv.weight', 'local_decoder.layers.0.attention.wk.weight', 'local_decoder.layers.0.attention.wo.weight', 'local_decoder.layers.0.attention.wq.weight', 'local_decoder.layers.0.attention.wv.weight', 'local_decoder.layers.0.attention_norm.weight', 'local_decoder.layers.0.feed_forward.w1.weight', 'local_decoder.layers.0.feed_forward.w2.weight', 'local_decoder.layers.0.feed_forward.w3.weight', 'local_decoder.layers.0.ffn_norm.weight', 'local_decoder.layers.1.attention.wk.weight', 'local_decoder.layers.1.attention.wo.weight', 'local_decoder.layers.1.attention.wq.weight', 'local_decoder.layers.1.attention.wv.weight', 'local_decoder.layers.1.attention_norm.weight', 'local_decoder.layers.1.feed_forward.w1.weight', 'local_decoder.layers.1.feed_forward.w2.weight', 'local_decoder.layers.1.feed_forward.w3.weight', 'local_decoder.layers.1.ffn_norm.weight', 'local_decoder.layers.2.attention.wk.weight', 'local_decoder.layers.2.attention.wo.weight', 'local_decoder.layers.2.attention.wq.weight', 'local_decoder.layers.2.attention.wv.weight', 'local_decoder.layers.2.attention_norm.weight', 'local_decoder.layers.2.feed_forward.w1.weight', 'local_decoder.layers.2.feed_forward.w2.weight', 'local_decoder.layers.2.feed_forward.w3.weight', 'local_decoder.layers.2.ffn_norm.weight', 'local_decoder.layers.3.attention.wk.weight', 'local_decoder.layers.3.attention.wo.weight', 'local_decoder.layers.3.attention.wq.weight', 'local_decoder.layers.3.attention.wv.weight', 'local_decoder.layers.3.attention_norm.weight', 'local_decoder.layers.3.feed_forward.w1.weight', 'local_decoder.layers.3.feed_forward.w2.weight', 'local_decoder.layers.3.feed_forward.w3.weight', 'local_decoder.layers.3.ffn_norm.weight', 'local_decoder.layers.4.attention.wk.weight', 'local_decoder.layers.4.attention.wo.weight', 'local_decoder.layers.4.attention.wq.weight', 'local_decoder.layers.4.attention.wv.weight', 'local_decoder.layers.4.attention_norm.weight', 'local_decoder.layers.4.feed_forward.w1.weight', 'local_decoder.layers.4.feed_forward.w2.weight', 'local_decoder.layers.4.feed_forward.w3.weight', 'local_decoder.layers.4.ffn_norm.weight', 'local_decoder.layers.5.attention.wk.weight', 'local_decoder.layers.5.attention.wo.weight', 'local_decoder.layers.5.attention.wq.weight', 'local_decoder.layers.5.attention.wv.weight', 'local_decoder.layers.5.attention_norm.weight', 'local_decoder.layers.5.feed_forward.w1.weight', 'local_decoder.layers.5.feed_forward.w2.weight', 'local_decoder.layers.5.feed_forward.w3.weight', 'local_decoder.layers.5.ffn_norm.weight', 'local_decoder.layers.6.attention.wk.weight', 'local_decoder.layers.6.attention.wo.weight', 'local_decoder.layers.6.attention.wq.weight', 'local_decoder.layers.6.attention.wv.weight', 'local_decoder.layers.6.attention_norm.weight', 'local_decoder.layers.6.feed_forward.w1.weight', 'local_decoder.layers.6.feed_forward.w2.weight', 'local_decoder.layers.6.feed_forward.w3.weight', 'local_decoder.layers.6.ffn_norm.weight', 'local_decoder.layers.7.attention.wk.weight', 'local_decoder.layers.7.attention.wo.weight', 'local_decoder.layers.7.attention.wq.weight', 'local_decoder.layers.7.attention.wv.weight', 'local_decoder.layers.7.attention_norm.weight', 'local_decoder.layers.7.feed_forward.w1.weight', 'local_decoder.layers.7.feed_forward.w2.weight', 'local_decoder.layers.7.feed_forward.w3.weight', 'local_decoder.layers.7.ffn_norm.weight', 'local_decoder.layers.8.attention.wk.weight', 'local_decoder.layers.8.attention.wo.weight', 'local_decoder.layers.8.attention.wq.weight', 'local_decoder.layers.8.attention.wv.weight', 'local_decoder.layers.8.attention_norm.weight', 'local_decoder.layers.8.feed_forward.w1.weight', 'local_decoder.layers.8.feed_forward.w2.weight', 'local_decoder.layers.8.feed_forward.w3.weight', 'local_decoder.layers.8.ffn_norm.weight', 'local_decoder.norm.weight', 'local_decoder.output.weight', 'local_decoder.patch_embedding_projection.weight', 'local_encoder.cross_attn_layers.0.cross_attn_norm_kv.weight', 'local_encoder.cross_attn_layers.0.cross_attn_norm_q.weight', 'local_encoder.cross_attn_layers.0.wk.weight', 'local_encoder.cross_attn_layers.0.wo.weight', 'local_encoder.cross_attn_layers.0.wq.weight', 'local_encoder.cross_attn_layers.0.wv.weight', 'local_encoder.layers.0.attention.wk.weight', 'local_encoder.layers.0.attention.wo.weight', 'local_encoder.layers.0.attention.wq.weight', 'local_encoder.layers.0.attention.wv.weight', 'local_encoder.layers.0.attention_norm.weight', 'local_encoder.layers.0.feed_forward.w1.weight', 'local_encoder.layers.0.feed_forward.w2.weight', 'local_encoder.layers.0.feed_forward.w3.weight', 'local_encoder.layers.0.ffn_norm.weight', 'local_encoder.patch_embedding_projection.weight', 'local_encoder.tok_embeddings.weight']\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ... (other parts of the code remain the same)\n",
        "\n",
        "class BLTAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_model = config['d_model']\n",
        "        self.n_heads = config['n_heads']\n",
        "        self.head_dim = self.d_model // self.n_heads\n",
        "\n",
        "        # Similar to the keys found in the diagnosis\n",
        "        self.wq = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wk = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wv = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wo = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Apply linear transformations, and convert to float32 before view and transpose\n",
        "        q = self.wq(x).type(torch.float32).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)  # Convert to float32\n",
        "        k = self.wk(x).type(torch.float32).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)  # Convert to float32\n",
        "        v = self.wv(x).type(torch.float32).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)  # Convert to float32\n",
        "\n",
        "        # Calculate attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to values\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Reshape and apply final projection\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        output = self.wo(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "# ... (rest of the code remains the same)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Lrot2nwe_iYM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# تحميل النماذج\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# تعريف التكوين بناءً على المعلومات المستخرجة\n",
        "MODEL_CONFIG = {\n",
        "    'vocab_size': 260,  # حجم المفردات من التشخيص\n",
        "    'd_model': 1024,    # أبعاد النموذج من التشخيص\n",
        "    'n_layers': 25,     # عدد الطبقات من التشخيص\n",
        "    'n_heads': 16,      # عدد رؤوس الانتباه (تقدير: عادة ما تكون d_model/64)\n",
        "    'max_seq_len': 2048 # الحد الأقصى لطول التسلسل (تقدير)\n",
        "}\n",
        "\n",
        "class BLTAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_model = config['d_model']\n",
        "        self.n_heads = config['n_heads']\n",
        "        self.head_dim = self.d_model // self.n_heads\n",
        "\n",
        "        # Similar to the keys found in the diagnosis\n",
        "        self.wq = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wk = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wv = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wo = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Apply linear transformations, and convert to float32 before view and transpose\n",
        "        q = self.wq(x).type(torch.float32).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)  # Convert to float32\n",
        "        k = self.wk(x).type(torch.float32).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)  # Convert to float32\n",
        "        v = self.wv(x).type(torch.float32).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)  # Convert to float32\n",
        "\n",
        "        # Calculate attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to values\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Reshape and apply final projection\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        output = self.wo(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "class BLTFFN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(config['d_model'], 4 * config['d_model'], bias=False)\n",
        "        self.w2 = nn.Linear(4 * config['d_model'], config['d_model'], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(F.gelu(self.w1(x)))\n",
        "\n",
        "class BLTBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = BLTAttention(config)\n",
        "        self.attention_norm = nn.LayerNorm(config['d_model'])\n",
        "        self.ffn = BLTFFN(config)\n",
        "        self.ffn_norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # طبقة الانتباه مع اتصال متبقي\n",
        "        attn_output = self.attention(self.attention_norm(x), mask)\n",
        "        x = x + attn_output\n",
        "\n",
        "        # طبقة FFN مع اتصال متبقي\n",
        "        ffn_output = self.ffn(self.ffn_norm(x))\n",
        "        x = x + ffn_output\n",
        "\n",
        "        return x\n",
        "\n",
        "class BLTModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # طبقة التضمين\n",
        "        self.tok_embeddings = nn.Embedding(config['vocab_size'], config['d_model'])\n",
        "\n",
        "        # طبقات المحول\n",
        "        self.layers = nn.ModuleList([\n",
        "            BLTBlock(config) for _ in range(config['n_layers'])\n",
        "        ])\n",
        "\n",
        "        # طبقة التطبيع النهائية\n",
        "        self.norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "        # رأس التوقع\n",
        "        self.output = nn.Linear(config['d_model'], config['vocab_size'], bias=False)\n",
        "\n",
        "    def _init_weights_from_model(self, weights):\n",
        "        print(\"تهيئة أوزان النموذج من الملف المحمل...\")\n",
        "\n",
        "        # قائمة المفاتيح التي تم تحميلها بنجاح\n",
        "        loaded_keys = []\n",
        "\n",
        "        # تحميل التضمينات\n",
        "        if 'local_encoder.tok_embeddings.weight' in weights:\n",
        "            self.tok_embeddings.weight.data = weights['local_encoder.tok_embeddings.weight']\n",
        "            loaded_keys.append('local_encoder.tok_embeddings.weight')\n",
        "\n",
        "        # تحميل طبقات المحول\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            prefix = f'layers.{i}.'\n",
        "\n",
        "            # تحميل أوزان الانتباه\n",
        "            for name, param in [\n",
        "                ('attention.wq.weight', layer.attention.wq.weight),\n",
        "                ('attention.wk.weight', layer.attention.wk.weight),\n",
        "                ('attention.wv.weight', layer.attention.wv.weight),\n",
        "                ('attention.wo.weight', layer.attention.wo.weight),\n",
        "                ('attention_norm.weight', layer.attention_norm.weight),\n",
        "                ('ffn_norm.weight', layer.ffn_norm.weight)\n",
        "            ]:\n",
        "                key = prefix + name\n",
        "                if key in weights:\n",
        "                    param.data = weights[key]\n",
        "                    loaded_keys.append(key)\n",
        "\n",
        "            # تحميل أوزان FFN\n",
        "            # قد تختلف الأسماء حسب النموذج الفعلي\n",
        "            ffn_keys = [k for k in weights.keys() if prefix in k and ('feed_forward' in k or 'ffn' in k)]\n",
        "            if len(ffn_keys) >= 2:  # نفترض وجود وزنين على الأقل لطبقة FFN\n",
        "                for key in ffn_keys:\n",
        "                    if 'w1' in key or 'fc1' in key:\n",
        "                        layer.ffn.w1.weight.data = weights[key]\n",
        "                        loaded_keys.append(key)\n",
        "                    elif 'w2' in key or 'fc2' in key:\n",
        "                        layer.ffn.w2.weight.data = weights[key]\n",
        "                        loaded_keys.append(key)\n",
        "\n",
        "        # تحميل طبقة التطبيع النهائية\n",
        "        norm_keys = [k for k in weights.keys() if 'norm' in k and not any(x in k for x in ['attention', 'ffn'])]\n",
        "        if norm_keys:\n",
        "            self.norm.weight.data = weights[norm_keys[0]]\n",
        "            loaded_keys.append(norm_keys[0])\n",
        "\n",
        "        # تحميل رأس الإخراج\n",
        "        output_keys = [k for k in weights.keys() if 'lm_head' in k or 'output' in k]\n",
        "        if output_keys:\n",
        "            self.output.weight.data = weights[output_keys[0]]\n",
        "            loaded_keys.append(output_keys[0])\n",
        "\n",
        "        print(f\"تم تحميل {len(loaded_keys)} من أصل {len(weights)} مفتاح من النموذج\")\n",
        "        return loaded_keys\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "\n",
        "        # الحصول على التضمينات\n",
        "        h = self.tok_embeddings(input_ids)\n",
        "\n",
        "        # إنشاء قناع الانتباه إذا لم يتم توفيره\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones((batch_size, seq_len, seq_len), device=input_ids.device)\n",
        "\n",
        "        # تطبيق طبقات المحول\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, attention_mask)\n",
        "\n",
        "        # تطبيق التطبيع النهائي\n",
        "        h = self.norm(h)\n",
        "\n",
        "        # الحصول على التوقعات\n",
        "        logits = self.output(h)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(self, input_ids, max_length=100, temperature=0.8, top_k=40, top_p=0.9):\n",
        "        \"\"\"توليد النص باستخدام النموذج\"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        input_ids = input_ids.to(device)\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # الحصول على نتائج النموذج للتسلسل الحالي\n",
        "            with torch.no_grad():\n",
        "                outputs = self(input_ids)\n",
        "                next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "                # تطبيق تصفية top-k\n",
        "                if top_k > 0:\n",
        "                    indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
        "                    next_token_logits[indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # تطبيق تصفية top-p (nucleus)\n",
        "                if top_p < 1.0:\n",
        "                    sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
        "                    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                    # إزالة الرموز ذات الاحتمال التراكمي فوق العتبة\n",
        "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                    # نقل المؤشرات إلى اليمين للحفاظ أيضًا على الرمز الأول فوق العتبة\n",
        "                    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "                    sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                    for batch_idx in range(batch_size):\n",
        "                        indices_to_remove = sorted_indices[batch_idx][sorted_indices_to_remove[batch_idx]]\n",
        "                        next_token_logits[batch_idx, indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # اختيار الرمز التالي\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                # إضافة الرمز التالي إلى التسلسل\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "                # التحقق مما إذا كنا قد أنشأنا رمز EOS\n",
        "                if (next_token == self.config.get('eos_token_id', -1)).any():\n",
        "                    break\n",
        "\n",
        "        return input_ids\n",
        "\n",
        "def load_tokenizer(vocab_size=260):\n",
        "    \"\"\"استبدال مؤقت للمحول - تنفيذ بسيط\"\"\"\n",
        "    class SimpleTokenizer:\n",
        "        def __init__(self, vocab_size):\n",
        "            self.vocab_size = vocab_size\n",
        "\n",
        "        def __call__(self, text, return_tensors=\"pt\"):\n",
        "            # هذا مجرد محاكاة، في الواقع تحتاج إلى تنفيذ التحويل الفعلي\n",
        "            # هنا نقوم بتحويل كل حرف إلى رقم بسيط\n",
        "            tokens = [ord(c) % (self.vocab_size - 4) + 4 for c in text]\n",
        "            if return_tensors == \"pt\":\n",
        "                return SimpleNamespace(input_ids=torch.tensor([tokens]))\n",
        "            return tokens\n",
        "\n",
        "        def decode(self, ids):\n",
        "            # تحويل الرموز مرة أخرى إلى نص\n",
        "            if isinstance(ids, torch.Tensor):\n",
        "                ids = ids.tolist()\n",
        "            text = \"\"\n",
        "            for id in ids:\n",
        "                if id >= 4 and id < self.vocab_size:\n",
        "                    text += chr((id - 4) % 26 + 97)  # تحويل بسيط إلى أحرف\n",
        "            return text\n",
        "\n",
        "    return SimpleTokenizer(vocab_size)\n",
        "\n",
        "class SimpleNamespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "# دالة لتنفيذ النموذج واختباره\n",
        "def run_model():\n",
        "    print(\"تهيئة النموذج...\")\n",
        "    model = BLTModel(MODEL_CONFIG)\n",
        "    loaded_keys = model._init_weights_from_model(model_weights)\n",
        "\n",
        "    print(\"تجهيز واختبار المحول...\")\n",
        "    tokenizer = load_tokenizer(MODEL_CONFIG['vocab_size'])\n",
        "\n",
        "    print(\"اختبار النموذج مع مثال بسيط...\")\n",
        "    prompt = \"hi\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    print(f\"المدخل: '{prompt}'\")\n",
        "    print(f\"رموز المدخل: {input_ids.tolist()}\")\n",
        "\n",
        "    print(\"بدء التوليد...\")\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=20,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(output_ids[0])\n",
        "    print(f\"النص المولد: '{generated_text}'\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# تشغيل النموذج\n",
        "if __name__ == \"__main__\":\n",
        "    run_model()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "rFFBMvW-Ara7",
        "outputId": "3ff87c26-1930-44f2-e320-d91cc1aa028f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تهيئة النموذج...\n",
            "تهيئة أوزان النموذج من الملف المحمل...\n",
            "تم تحميل 73 من أصل 386 مفتاح من النموذج\n",
            "تجهيز واختبار المحول...\n",
            "اختبار النموذج مع مثال بسيط...\n",
            "المدخل: 'hi'\n",
            "رموز المدخل: [[108, 109]]\n",
            "بدء التوليد...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f0c45f7586b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;31m# تشغيل النموذج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-f0c45f7586b9>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"بدء التوليد...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         output_ids = model.generate(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f0c45f7586b9>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, temperature, top_k, top_p)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# الحصول على نتائج النموذج للتسلسل الحالي\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f0c45f7586b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# تطبيق طبقات المحول\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# تطبيق التطبيع النهائي\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f0c45f7586b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# طبقة الانتباه مع اتصال متبقي\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-f0c45f7586b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Apply linear transformations, and convert to float32 before view and transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# تحميل النماذج\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "# تعريف التكوين بناءً على المعلومات المستخرجة\n",
        "MODEL_CONFIG = {\n",
        "    'vocab_size': 260,  # حجم المفردات من التشخيص\n",
        "    'd_model': 1024,    # أبعاد النموذج من التشخيص\n",
        "    'n_layers': 25,     # عدد الطبقات من التشخيص\n",
        "    'n_heads': 16,      # عدد رؤوس الانتباه (تقدير: عادة ما تكون d_model/64)\n",
        "    'max_seq_len': 2048 # الحد الأقصى لطول التسلسل (تقدير)\n",
        "}\n",
        "\n",
        "class BLTAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        # ... (other parts remain the same)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        # Convert input to bfloat16\n",
        "        x = x.type(torch.bfloat16)\n",
        "\n",
        "        # Apply linear transformations\n",
        "        q = self.wq(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        k = self.wk(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "        v = self.wv(x).view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        # Apply mask if provided\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to values\n",
        "        context = torch.matmul(attn_weights, v)\n",
        "\n",
        "        # Reshape and apply final projection\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n",
        "        output = self.wo(context)\n",
        "\n",
        "        return output\n",
        "\n",
        "class BLTFFN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(config['d_model'], 4 * config['d_model'], bias=False)\n",
        "        self.w2 = nn.Linear(4 * config['d_model'], config['d_model'], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(F.gelu(self.w1(x)))\n",
        "\n",
        "class BLTBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = BLTAttention(config)\n",
        "        self.attention_norm = nn.LayerNorm(config['d_model'])\n",
        "        self.ffn = BLTFFN(config)\n",
        "        self.ffn_norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # طبقة الانتباه مع اتصال متبقي\n",
        "        attn_output = self.attention(self.attention_norm(x), mask)\n",
        "        x = x + attn_output\n",
        "\n",
        "        # طبقة FFN مع اتصال متبقي\n",
        "        ffn_output = self.ffn(self.ffn_norm(x))\n",
        "        x = x + ffn_output\n",
        "\n",
        "        return x\n",
        "\n",
        "class BLTModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # طبقة التضمين\n",
        "        self.tok_embeddings = nn.Embedding(config['vocab_size'], config['d_model'])\n",
        "\n",
        "        # طبقات المحول\n",
        "        self.layers = nn.ModuleList([\n",
        "            BLTBlock(config) for _ in range(config['n_layers'])\n",
        "        ])\n",
        "\n",
        "        # طبقة التطبيع النهائية\n",
        "        self.norm = nn.LayerNorm(config['d_model'])\n",
        "\n",
        "        # رأس التوقع\n",
        "        self.output = nn.Linear(config['d_model'], config['vocab_size'], bias=False)\n",
        "\n",
        "    def _init_weights_from_model(self, weights):\n",
        "        print(\"تهيئة أوزان النموذج من الملف المحمل...\")\n",
        "\n",
        "        # قائمة المفاتيح التي تم تحميلها بنجاح\n",
        "        loaded_keys = []\n",
        "\n",
        "        # تحميل التضمينات\n",
        "        if 'local_encoder.tok_embeddings.weight' in weights:\n",
        "            self.tok_embeddings.weight.data = weights['local_encoder.tok_embeddings.weight']\n",
        "            loaded_keys.append('local_encoder.tok_embeddings.weight')\n",
        "\n",
        "        # تحميل طبقات المحول\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            prefix = f'layers.{i}.'\n",
        "\n",
        "            # تحميل أوزان الانتباه\n",
        "            for name, param in [\n",
        "                ('attention.wq.weight', layer.attention.wq.weight),\n",
        "                ('attention.wk.weight', layer.attention.wk.weight),\n",
        "                ('attention.wv.weight', layer.attention.wv.weight),\n",
        "                ('attention.wo.weight', layer.attention.wo.weight),\n",
        "                ('attention_norm.weight', layer.attention_norm.weight),\n",
        "                ('ffn_norm.weight', layer.ffn_norm.weight)\n",
        "            ]:\n",
        "                key = prefix + name\n",
        "                if key in weights:\n",
        "                    param.data = weights[key]\n",
        "                    loaded_keys.append(key)\n",
        "\n",
        "            # تحميل أوزان FFN\n",
        "            # قد تختلف الأسماء حسب النموذج الفعلي\n",
        "            ffn_keys = [k for k in weights.keys() if prefix in k and ('feed_forward' in k or 'ffn' in k)]\n",
        "            if len(ffn_keys) >= 2:  # نفترض وجود وزنين على الأقل لطبقة FFN\n",
        "                for key in ffn_keys:\n",
        "                    if 'w1' in key or 'fc1' in key:\n",
        "                        layer.ffn.w1.weight.data = weights[key]\n",
        "                        loaded_keys.append(key)\n",
        "                    elif 'w2' in key or 'fc2' in key:\n",
        "                        layer.ffn.w2.weight.data = weights[key]\n",
        "                        loaded_keys.append(key)\n",
        "\n",
        "        # تحميل طبقة التطبيع النهائية\n",
        "        norm_keys = [k for k in weights.keys() if 'norm' in k and not any(x in k for x in ['attention', 'ffn'])]\n",
        "        if norm_keys:\n",
        "            self.norm.weight.data = weights[norm_keys[0]]\n",
        "            loaded_keys.append(norm_keys[0])\n",
        "\n",
        "        # تحميل رأس الإخراج\n",
        "        output_keys = [k for k in weights.keys() if 'lm_head' in k or 'output' in k]\n",
        "        if output_keys:\n",
        "            self.output.weight.data = weights[output_keys[0]]\n",
        "            loaded_keys.append(output_keys[0])\n",
        "\n",
        "        print(f\"تم تحميل {len(loaded_keys)} من أصل {len(weights)} مفتاح من النموذج\")\n",
        "        return loaded_keys\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "\n",
        "        # الحصول على التضمينات\n",
        "        h = self.tok_embeddings(input_ids)\n",
        "\n",
        "        # إنشاء قناع الانتباه إذا لم يتم توفيره\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones((batch_size, seq_len, seq_len), device=input_ids.device)\n",
        "\n",
        "        # تطبيق طبقات المحول\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, attention_mask)\n",
        "\n",
        "        # تطبيق التطبيع النهائي\n",
        "        h = self.norm(h)\n",
        "\n",
        "        # الحصول على التوقعات\n",
        "        logits = self.output(h)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(self, input_ids, max_length=100, temperature=0.8, top_k=40, top_p=0.9):\n",
        "        \"\"\"توليد النص باستخدام النموذج\"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        input_ids = input_ids.to(device)\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # الحصول على نتائج النموذج للتسلسل الحالي\n",
        "            with torch.no_grad():\n",
        "                outputs = self(input_ids)\n",
        "                next_token_logits = outputs[:, -1, :] / temperature\n",
        "\n",
        "                # تطبيق تصفية top-k\n",
        "                if top_k > 0:\n",
        "                    indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]\n",
        "                    next_token_logits[indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # تطبيق تصفية top-p (nucleus)\n",
        "                if top_p < 1.0:\n",
        "                    sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
        "                    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "                    # إزالة الرموز ذات الاحتمال التراكمي فوق العتبة\n",
        "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                    # نقل المؤشرات إلى اليمين للحفاظ أيضًا على الرمز الأول فوق العتبة\n",
        "                    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "                    sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                    for batch_idx in range(batch_size):\n",
        "                        indices_to_remove = sorted_indices[batch_idx][sorted_indices_to_remove[batch_idx]]\n",
        "                        next_token_logits[batch_idx, indices_to_remove] = -float('Inf')\n",
        "\n",
        "                # اختيار الرمز التالي\n",
        "                probs = F.softmax(next_token_logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                # إضافة الرمز التالي إلى التسلسل\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "\n",
        "                # التحقق مما إذا كنا قد أنشأنا رمز EOS\n",
        "                if (next_token == self.config.get('eos_token_id', -1)).any():\n",
        "                    break\n",
        "\n",
        "        return input_ids\n",
        "\n",
        "def load_tokenizer(vocab_size=260):\n",
        "    \"\"\"استبدال مؤقت للمحول - تنفيذ بسيط\"\"\"\n",
        "    class SimpleTokenizer:\n",
        "        def __init__(self, vocab_size):\n",
        "            self.vocab_size = vocab_size\n",
        "\n",
        "        def __call__(self, text, return_tensors=\"pt\"):\n",
        "            # هذا مجرد محاكاة، في الواقع تحتاج إلى تنفيذ التحويل الفعلي\n",
        "            # هنا نقوم بتحويل كل حرف إلى رقم بسيط\n",
        "            tokens = [ord(c) % (self.vocab_size - 4) + 4 for c in text]\n",
        "            if return_tensors == \"pt\":\n",
        "                return SimpleNamespace(input_ids=torch.tensor([tokens]))\n",
        "            return tokens\n",
        "\n",
        "        def decode(self, ids):\n",
        "            # تحويل الرموز مرة أخرى إلى نص\n",
        "            if isinstance(ids, torch.Tensor):\n",
        "                ids = ids.tolist()\n",
        "            text = \"\"\n",
        "            for id in ids:\n",
        "                if id >= 4 and id < self.vocab_size:\n",
        "                    text += chr((id - 4) % 26 + 97)  # تحويل بسيط إلى أحرف\n",
        "            return text\n",
        "\n",
        "    return SimpleTokenizer(vocab_size)\n",
        "\n",
        "class SimpleNamespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "# دالة لتنفيذ النموذج واختباره\n",
        "def run_model():\n",
        "    print(\"تهيئة النموذج...\")\n",
        "    model = BLTModel(MODEL_CONFIG)\n",
        "    loaded_keys = model._init_weights_from_model(model_weights)\n",
        "\n",
        "    print(\"تجهيز واختبار المحول...\")\n",
        "    tokenizer = load_tokenizer(MODEL_CONFIG['vocab_size'])\n",
        "\n",
        "    print(\"اختبار النموذج مع مثال بسيط...\")\n",
        "    prompt = \"hi\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    print(f\"المدخل: '{prompt}'\")\n",
        "    print(f\"رموز المدخل: {input_ids.tolist()}\")\n",
        "\n",
        "    print(\"بدء التوليد...\")\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=20,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(output_ids[0])\n",
        "    print(f\"النص المولد: '{generated_text}'\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# تشغيل النموذج\n",
        "if __name__ == \"__main__\":\n",
        "    run_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Ex-korjV_VJR",
        "outputId": "5c775d8a-9b3a-407a-febf-12722c9f6549"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تهيئة النموذج...\n",
            "تهيئة أوزان النموذج من الملف المحمل...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'BLTAttention' object has no attribute 'wq'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-99624a8c11d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;31m# تشغيل النموذج\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-99624a8c11d4>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"تهيئة النموذج...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBLTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_CONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mloaded_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_weights_from_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"تجهيز واختبار المحول...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-99624a8c11d4>\u001b[0m in \u001b[0;36m_init_weights_from_model\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# تحميل أوزان الانتباه\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             for name, param in [\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0;34m'attention.wq.weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m'attention.wk.weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m'attention.wv.weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BLTAttention' object has no attribute 'wq'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0jlaWivBZVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YcDco_D7BaL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7i20r6Z1BaGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"Explain the theory of special relativity in a simplified way.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "cccZGf2SBaDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zabPbKUZBjhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IciIgcD-BjeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "# تحميل النماذج\n",
        "model_weights = load_file('/content/safetensors/blt_1b/consolidated.safetensors')\n",
        "entropy_weights = load_file('/content/safetensors/entropy_model/consolidated.safetensors')\n",
        "\n",
        "\n",
        "prompt = \"Explain the theory of special relativity in a simplified way.\"\n",
        "inputs = entropy_weights(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model_weights.generate(**inputs, max_new_tokens=100)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "HjUOKTO8BjbD",
        "outputId": "e8dfa1cd-a184-4021-b359-7ab72fe2512b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'dict' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c14c20226261>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Explain the theory of special relativity in a simplified way.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropy_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zuP7KPdfB-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from safetensors.torch import load_file\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ... (other parts of the code remain the same)\n",
        "\n",
        "class BLTAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.d_model = config['d_model']\n",
        "        self.n_heads = config['n_heads']\n",
        "        self.head_dim = self.d_model // self.n_heads\n",
        "\n",
        "        # Initialize the linear layers here\n",
        "        self.wq = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wk = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wv = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "        self.wo = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # ... (rest of the forward method remains the same)\n",
        "\n",
        "class BLTModel(nn.Module):\n",
        "    # ... (other parts remain the same)\n",
        "\n",
        "    def _init_weights_from_model(self, weights):\n",
        "        print(\"تهيئة أوزان النموذج من الملف المحمل...\")\n",
        "\n",
        "        # ... (other parts remain the same)\n",
        "\n",
        "        # Load attention weights\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            prefix = f'layers.{i}.'\n",
        "\n",
        "            # Update the keys to match the actual structure of your model_weights\n",
        "            for name, param in [\n",
        "                ('attention.q_proj.weight', layer.attention.wq.weight),  # Updated key\n",
        "                ('attention.k_proj.weight', layer.attention.wk.weight),  # Updated key\n",
        "                ('attention.v_proj.weight', layer.attention.wv.weight),  # Updated key\n",
        "                ('attention.out_proj.weight', layer.attention.wo.weight), # Updated key\n",
        "                ('attention_norm.weight', layer.attention_norm.weight),\n",
        "                ('ffn_norm.weight', layer.ffn_norm.weight)\n",
        "            ]:\n",
        "                key = prefix + name\n",
        "                if key in weights:\n",
        "                    param.data = weights[key].type(torch.float32)  # Convert to float32\n",
        "                    loaded_keys.append(key)\n",
        "\n",
        "        # ... (rest of the _init_weights_from_model method remains the same)\n",
        "\n",
        "# ... (rest of the code remains the same)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "VvWxOOwbCCwl",
        "outputId": "090aea61-a2c7-40f7-b3d2-1ffb7eac938e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 21 (<ipython-input-5-1bd64be459ec>, line 24)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-1bd64be459ec>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    class BLTModel(nn.Module):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 21\n"
          ]
        }
      ]
    }
  ]
}