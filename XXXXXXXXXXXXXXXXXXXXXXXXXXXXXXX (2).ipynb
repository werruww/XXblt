{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuJ5prxTo-YL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8E6s9szo_El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5BOd2FBo_Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git clone https://github.com/facebookresearch/blt\n",
        "cd blt\n",
        "conda create -n blt python=3.12\n",
        "conda activate blt\n",
        "pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "pip install ninja\n",
        "pip install -v -U git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148\n",
        "pip install -r requirements.txt\n",
        "conda activate blt"
      ],
      "metadata": {
        "id": "6HynIMuFo_KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/blt\n",
        "%cd blt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La5D8M2XpDMC",
        "outputId": "2f040641-2ebf-405f-d5ac-de81d1c3bed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'blt'...\n",
            "remote: Enumerating objects: 1168, done.\u001b[K\n",
            "remote: Counting objects: 100% (340/340), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 1168 (delta 259), reused 229 (delta 220), pack-reused 828 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1168/1168), 703.57 KiB | 2.10 MiB/s, done.\n",
            "Resolving deltas: 100% (751/751), done.\n",
            "/content/blt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "!pip install ninja\n",
        "!pip install -v -U git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E00aJsrMpFEV",
        "outputId": "67d9dfe8-150b-4bcc-f53a-6f2ce02978df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/nightly/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/torch-2.6.0.dev20241112%2Bcu121-cp311-cp311-linux_x86_64.whl (768.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.0/768.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-triton==3.1.0+cf34004b8a (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.1.0%2Bcf34004b8a-cp311-cp311-linux_x86_64.whl (239.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/239.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: pytorch-triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 pytorch-triton-3.1.0+cf34004b8a torch-2.6.0.dev20241112+cu121\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.4\n",
            "Using pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n",
            "Collecting git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Cloning https://github.com/facebookresearch/xformers.git (to revision de742ec3d64bd83b1184cc043e541f15d270c148) to /tmp/pip-req-build-mzf203xk\n",
            "  Running command git version\n",
            "  git version 2.34.1\n",
            "  Running command git clone --filter=blob:none https://github.com/facebookresearch/xformers.git /tmp/pip-req-build-mzf203xk\n",
            "  Cloning into '/tmp/pip-req-build-mzf203xk'...\n",
            "  Updating files:   0% (2/1090)\n",
            "  Updating files:   1% (11/1090)\n",
            "  Updating files:   2% (22/1090)\n",
            "  Updating files:   3% (33/1090)\n",
            "  Updating files:   4% (44/1090)\n",
            "  Updating files:   5% (55/1090)\n",
            "  Updating files:   6% (66/1090)\n",
            "  Updating files:   7% (77/1090)\n",
            "  Updating files:   8% (88/1090)\n",
            "  Updating files:   9% (99/1090)\n",
            "  Updating files:  10% (109/1090)\n",
            "  Updating files:  11% (120/1090)\n",
            "  Updating files:  12% (131/1090)\n",
            "  Updating files:  13% (142/1090)\n",
            "  Updating files:  14% (153/1090)\n",
            "  Updating files:  15% (164/1090)\n",
            "  Updating files:  16% (175/1090)\n",
            "  Updating files:  17% (186/1090)\n",
            "  Updating files:  18% (197/1090)\n",
            "  Updating files:  19% (208/1090)\n",
            "  Updating files:  20% (218/1090)\n",
            "  Updating files:  21% (229/1090)\n",
            "  Updating files:  22% (240/1090)\n",
            "  Updating files:  23% (251/1090)\n",
            "  Updating files:  24% (262/1090)\n",
            "  Updating files:  25% (273/1090)\n",
            "  Updating files:  26% (284/1090)\n",
            "  Updating files:  27% (295/1090)\n",
            "  Updating files:  28% (306/1090)\n",
            "  Updating files:  29% (317/1090)\n",
            "  Updating files:  30% (327/1090)\n",
            "  Updating files:  31% (338/1090)\n",
            "  Updating files:  32% (349/1090)\n",
            "  Updating files:  33% (360/1090)\n",
            "  Updating files:  34% (371/1090)\n",
            "  Updating files:  35% (382/1090)\n",
            "  Updating files:  36% (393/1090)\n",
            "  Updating files:  37% (404/1090)\n",
            "  Updating files:  38% (415/1090)\n",
            "  Updating files:  39% (426/1090)\n",
            "  Updating files:  40% (436/1090)\n",
            "  Updating files:  41% (447/1090)\n",
            "  Updating files:  42% (458/1090)\n",
            "  Updating files:  43% (469/1090)\n",
            "  Updating files:  44% (480/1090)\n",
            "  Updating files:  45% (491/1090)\n",
            "  Updating files:  46% (502/1090)\n",
            "  Updating files:  47% (513/1090)\n",
            "  Updating files:  48% (524/1090)\n",
            "  Updating files:  49% (535/1090)\n",
            "  Updating files:  50% (545/1090)\n",
            "  Updating files:  51% (556/1090)\n",
            "  Updating files:  52% (567/1090)\n",
            "  Updating files:  53% (578/1090)\n",
            "  Updating files:  54% (589/1090)\n",
            "  Updating files:  55% (600/1090)\n",
            "  Updating files:  56% (611/1090)\n",
            "  Updating files:  57% (622/1090)\n",
            "  Updating files:  58% (633/1090)\n",
            "  Updating files:  59% (644/1090)\n",
            "  Updating files:  60% (654/1090)\n",
            "  Updating files:  61% (665/1090)\n",
            "  Updating files:  62% (676/1090)\n",
            "  Updating files:  63% (687/1090)\n",
            "  Updating files:  64% (698/1090)\n",
            "  Updating files:  65% (709/1090)\n",
            "  Updating files:  66% (720/1090)\n",
            "  Updating files:  67% (731/1090)\n",
            "  Updating files:  68% (742/1090)\n",
            "  Updating files:  69% (753/1090)\n",
            "  Updating files:  70% (763/1090)\n",
            "  Updating files:  71% (774/1090)\n",
            "  Updating files:  72% (785/1090)\n",
            "  Updating files:  73% (796/1090)\n",
            "  Updating files:  74% (807/1090)\n",
            "  Updating files:  75% (818/1090)\n",
            "  Updating files:  76% (829/1090)\n",
            "  Updating files:  77% (840/1090)\n",
            "  Updating files:  78% (851/1090)\n",
            "  Updating files:  79% (862/1090)\n",
            "  Updating files:  80% (872/1090)\n",
            "  Updating files:  81% (883/1090)\n",
            "  Updating files:  82% (894/1090)\n",
            "  Updating files:  83% (905/1090)\n",
            "  Updating files:  84% (916/1090)\n",
            "  Updating files:  85% (927/1090)\n",
            "  Updating files:  86% (938/1090)\n",
            "  Updating files:  87% (949/1090)\n",
            "  Updating files:  88% (960/1090)\n",
            "  Updating files:  89% (971/1090)\n",
            "  Updating files:  90% (981/1090)\n",
            "  Updating files:  91% (992/1090)\n",
            "  Updating files:  92% (1003/1090)\n",
            "  Updating files:  93% (1014/1090)\n",
            "  Updating files:  94% (1025/1090)\n",
            "  Updating files:  95% (1036/1090)\n",
            "  Updating files:  96% (1047/1090)\n",
            "  Updating files:  97% (1058/1090)\n",
            "  Updating files:  98% (1069/1090)\n",
            "  Updating files:  99% (1080/1090)\n",
            "  Updating files: 100% (1090/1090)\n",
            "  Updating files: 100% (1090/1090), done.\n",
            "  Running command git show-ref de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command git rev-parse -q --verify 'sha^de742ec3d64bd83b1184cc043e541f15d270c148'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/xformers.git de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command git rev-parse FETCH_HEAD\n",
            "  de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command git rev-parse HEAD\n",
            "  8fc8ec5a4d6498ff81c0c418b89bbaf133ae3a44\n",
            "  Running command git checkout -q de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Resolved https://github.com/facebookresearch/xformers.git to commit de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Running command git rev-parse HEAD\n",
            "  de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'third_party/flash-attention/version.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-eiaihj8y/xformers.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.4 in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.29+de742ec.d20250508) (2.6.0.dev20241112+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers==0.0.29+de742ec.d20250508) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.1.105)\n",
            "Requirement already satisfied: pytorch-triton==3.1.0+cf34004b8a in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (3.1.0+cf34004b8a)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4->xformers==0.0.29+de742ec.d20250508) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4->xformers==0.0.29+de742ec.d20250508) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4->xformers==0.0.29+de742ec.d20250508) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4->xformers==0.0.29+de742ec.d20250508) (3.0.2)\n",
            "Building wheels for collected packages: xformers\n",
            "  Running command git rev-parse HEAD\n",
            "  de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command git show-ref de742ec3d64bd83b1184cc043e541f15d270c148\n",
            "  Running command python setup.py bdist_wheel\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/_deprecation_warning.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/test.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/checkpoint.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/utils.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/attn_bias_utils.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/info.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  copying xformers/_cpp_lib.py -> build/lib.linux-x86_64-cpython-311/xformers\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/input_projection.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/simplicial_embedding.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/reversible.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/residual.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/patch_embedding.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/activations.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  copying xformers/components/multi_head_dispatch.py -> build/lib.linux-x86_64-cpython-311/xformers/components\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/device_limits.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/profiler.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/find_slowest.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/api.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/profiler_dcgm.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  copying xformers/profiler/profile_analyzer.py -> build/lib.linux-x86_64-cpython-311/xformers/profiler\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/triton\n",
            "  copying xformers/triton/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/triton\n",
            "  copying xformers/triton/vararg_kernel.py -> build/lib.linux-x86_64-cpython-311/xformers/triton\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/bert_padding.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  copying xformers/_flash_attn/fused_softmax.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/helpers\n",
            "  copying xformers/helpers/test_utils.py -> build/lib.linux-x86_64-cpython-311/xformers/helpers\n",
            "  copying xformers/helpers/hierarchical_configs.py -> build/lib.linux-x86_64-cpython-311/xformers/helpers\n",
            "  copying xformers/helpers/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/helpers\n",
            "  copying xformers/helpers/timm_sparse_attention.py -> build/lib.linux-x86_64-cpython-311/xformers/helpers\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  copying xformers/factory/weight_init.py -> build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  copying xformers/factory/block_configs.py -> build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  copying xformers/factory/model_factory.py -> build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  copying xformers/factory/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  copying xformers/factory/block_factory.py -> build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  copying xformers/factory/hydra_helper.py -> build/lib.linux-x86_64-cpython-311/xformers/factory\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_revnet.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_core.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_indexing.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/utils.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_multi_head_dispatch.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_sp24.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/seqpar.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/rmsnorm.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/sp24.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/common.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/swiglu_op.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/modpar_layers.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/indexing.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/unbind.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/tiled_matmul.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/rope_padded.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/differentiable_collectives.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  copying xformers/ops/ipc.py -> build/lib.linux-x86_64-cpython-311/xformers/ops\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/sparse\n",
            "  copying xformers/sparse/blocksparse_tensor.py -> build/lib.linux-x86_64-cpython-311/xformers/sparse\n",
            "  copying xformers/sparse/_csr_ops.py -> build/lib.linux-x86_64-cpython-311/xformers/sparse\n",
            "  copying xformers/sparse/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/sparse\n",
            "  copying xformers/sparse/utils.py -> build/lib.linux-x86_64-cpython-311/xformers/sparse\n",
            "  copying xformers/sparse/csr_tensor.py -> build/lib.linux-x86_64-cpython-311/xformers/sparse\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/linformer.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/global_tokens.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/attention_patterns.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/scaled_dot_product.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/sparsity_config.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/fourier_mix.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/visual.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/lambda_layer.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/utils.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/favor.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/random.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/ortho.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/local.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/base.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/compositional.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/pooling.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/core.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/nystrom.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/attention_mask.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  copying xformers/components/attention/_sputnik_sparse.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/components/feedforward\n",
            "  copying xformers/components/feedforward/mlp.py -> build/lib.linux-x86_64-cpython-311/xformers/components/feedforward\n",
            "  copying xformers/components/feedforward/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/components/feedforward\n",
            "  copying xformers/components/feedforward/conv_mlp.py -> build/lib.linux-x86_64-cpython-311/xformers/components/feedforward\n",
            "  copying xformers/components/feedforward/mixture_of_experts.py -> build/lib.linux-x86_64-cpython-311/xformers/components/feedforward\n",
            "  copying xformers/components/feedforward/base.py -> build/lib.linux-x86_64-cpython-311/xformers/components/feedforward\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  copying xformers/components/positional_embedding/vocab.py -> build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  copying xformers/components/positional_embedding/param.py -> build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  copying xformers/components/positional_embedding/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  copying xformers/components/positional_embedding/sine.py -> build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  copying xformers/components/positional_embedding/rotary.py -> build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  copying xformers/components/positional_embedding/base.py -> build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps\n",
            "  copying xformers/components/attention/feature_maps/softmax.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps\n",
            "  copying xformers/components/attention/feature_maps/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps\n",
            "  copying xformers/components/attention/feature_maps/base.py -> build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils\n",
            "  copying xformers/_flash_attn/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils\n",
            "  copying xformers/_flash_attn/utils/pretrained.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils\n",
            "  copying xformers/_flash_attn/utils/benchmark.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils\n",
            "  copying xformers/_flash_attn/utils/generation.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils\n",
            "  copying xformers/_flash_attn/utils/distributed.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules\n",
            "  copying xformers/_flash_attn/modules/embedding.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules\n",
            "  copying xformers/_flash_attn/modules/mlp.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules\n",
            "  copying xformers/_flash_attn/modules/mha.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules\n",
            "  copying xformers/_flash_attn/modules/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules\n",
            "  copying xformers/_flash_attn/modules/block.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers\n",
            "  copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers\n",
            "  copying xformers/_flash_attn/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers\n",
            "  copying xformers/_flash_attn/layers/rotary.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/btlm.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/falcon.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/bert.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/gptj.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/gpt.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/vit.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/baichuan.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/llama.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/bigcode.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  copying xformers/_flash_attn/models/opt.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/losses\n",
            "  copying xformers/_flash_attn/losses/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/losses\n",
            "  copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/losses\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops\n",
            "  copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops\n",
            "  copying xformers/_flash_attn/ops/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops\n",
            "  copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops\n",
            "  copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops\n",
            "  copying xformers/_flash_attn/ops/activations.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  copying xformers/benchmarks/LRA/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code\n",
            "  copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code\n",
            "  copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code\n",
            "  copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  copying xformers/ops/_triton/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/_triton\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/common.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/flash3.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/ck_decoder.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/ck.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/flash.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/dispatch.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/triton_splitk.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/ck_splitk.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/attn_bias.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  copying xformers/ops/fmha/cutlass.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha\n",
            "  creating build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/_triton\n",
            "  copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/_triton\n",
            "  copying xformers/ops/fmha/_triton/__init__.py -> build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/_triton\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "    warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n",
            "    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "  building 'xformers._C' extension\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/autograd\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/fmha\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24\n",
            "  creating /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda\n",
            "  /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2008: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.\n",
            "  If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "    warnings.warn(\n",
            "  Emitting ninja build file /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/build.ninja...\n",
            "  Compiling objects...\n",
            "  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "  [1/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/attention.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/attention.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [2/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/matmul.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cpu/matmul.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [3/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/autograd/matmul.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/autograd/matmul.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/autograd/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [4/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sddmm.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cpu/sddmm.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [5/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sparse_softmax.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cpu/sparse_softmax.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [6/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/spmm.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cpu/spmm.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [7/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/fmha/attention_cutlass_rand_uniform.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cuda/fmha/attention_cutlass_rand_uniform.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/fmha/attention_cutlass_rand_uniform.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 218054 bytes gmem, 72 bytes cmem[3], 112 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN71_GLOBAL__N__5954686e_33_attention_cutlass_rand_uniform_cu_f6c39a24_193919rand_uniform_kernelIfEEvlllfN2at15PhiloxCudaStateEPT_l' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN71_GLOBAL__N__5954686e_33_attention_cutlass_rand_uniform_cu_f6c39a24_193919rand_uniform_kernelIfEEvlllfN2at15PhiloxCudaStateEPT_l\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 42 registers, 424 bytes cmem[0]\n",
            "  [8/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/matmul.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cuda/matmul.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/matmul.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN46_GLOBAL__N__428dcae1_9_matmul_cu_f6c39a24_198430matmul_with_sparse_mask_kernelIN3c104HalfEEEvN2at27GenericPackedTensorAccessorIT_Lm1ENS3_16DefaultPtrTraitsElEENS4_IS5_Lm3ES6_lEES8_NS4_IlLm2ES6_lEE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN46_GLOBAL__N__428dcae1_9_matmul_cu_f6c39a24_198430matmul_with_sparse_mask_kernelIN3c104HalfEEEvN2at27GenericPackedTensorAccessorIT_Lm1ENS3_16DefaultPtrTraitsElEENS4_IS5_Lm3ES6_lEES8_NS4_IlLm2ES6_lEE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 40 registers, 528 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN46_GLOBAL__N__428dcae1_9_matmul_cu_f6c39a24_198430matmul_with_sparse_mask_kernelIfEEvN2at27GenericPackedTensorAccessorIT_Lm1ENS1_16DefaultPtrTraitsElEENS2_IS3_Lm3ES4_lEES6_NS2_IlLm2ES4_lEE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN46_GLOBAL__N__428dcae1_9_matmul_cu_f6c39a24_198430matmul_with_sparse_mask_kernelIfEEvN2at27GenericPackedTensorAccessorIT_Lm1ENS1_16DefaultPtrTraitsElEENS2_IS3_Lm3ES4_lEES6_NS2_IlLm2ES4_lEE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 528 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN46_GLOBAL__N__428dcae1_9_matmul_cu_f6c39a24_198430matmul_with_sparse_mask_kernelIdEEvN2at27GenericPackedTensorAccessorIT_Lm1ENS1_16DefaultPtrTraitsElEENS2_IS3_Lm3ES4_lEES6_NS2_IlLm2ES4_lEE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN46_GLOBAL__N__428dcae1_9_matmul_cu_f6c39a24_198430matmul_with_sparse_mask_kernelIdEEvN2at27GenericPackedTensorAccessorIT_Lm1ENS1_16DefaultPtrTraitsElEENS2_IS3_Lm3ES4_lEES6_NS2_IlLm2ES4_lEE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 528 bytes cmem[0]\n",
            "  [9/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sddmm.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cuda/sddmm.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sddmm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2IfLi1ELi32ELi32ELi32ELi1EEEviiiPKiS3_S3_PKfS5_Pfi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2IfLi1ELi32ELi32ELi32ELi1EEEviiiPKiS3_S3_PKfS5_Pfi\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 91 registers, 128 bytes smem, 420 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2I6float2Li2ELi32ELi32ELi16ELi1EEEviiiPKiS4_S4_PKfS6_Pfi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2I6float2Li2ELi32ELi32ELi16ELi1EEEviiiPKiS4_S4_PKfS6_Pfi\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 114 registers, 256 bytes smem, 420 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2I6float4Li4ELi32ELi32ELi8ELi1EEEviiiPKiS4_S4_PKfS6_Pfi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2I6float4Li4ELi32ELi32ELi8ELi1EEEviiiPKiS4_S4_PKfS6_Pfi\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 132 registers, 512 bytes smem, 420 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2I6float4Li4ELi32ELi32ELi8ELi0EEEviiiPKiS4_S4_PKfS6_Pfi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik40_GLOBAL__N__5f575198_8_sddmm_cu_76d5abc216CudaSddmmKernel2I6float4Li4ELi32ELi32ELi8ELi0EEEviiiPKiS4_S4_PKfS6_Pfi\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 128 registers, 512 bytes smem, 420 bytes cmem[0]\n",
            "  [10/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sparse_softmax.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cuda/sparse_softmax.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sparse_softmax.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik50_GLOBAL__N__6b0d318d_17_sparse_softmax_cu_4ff6710c19SparseSoftmaxKernelEiiPKfPKiS4_S4_Pfi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik50_GLOBAL__N__6b0d318d_17_sparse_softmax_cu_4ff6710c19SparseSoftmaxKernelEiiPKfPKiS4_S4_Pfi\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 16 registers, 404 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_Z27SparseSoftmaxBackwardKerneliiPKfS0_PKiS2_S2_Pfi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _Z27SparseSoftmaxBackwardKerneliiPKfS0_PKiS2_S2_Pfi\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 14 registers, 412 bytes cmem[0]\n",
            "  [11/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sddmm2_cuda.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cuda/sddmm2_cuda.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sddmm2_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7ge_spmm14sddmmCSR1ScaleIfEEviiimPiS1_PT_S3_S3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7ge_spmm14sddmmCSR1ScaleIfEEviiimPiS1_PT_S3_S3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 61 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7ge_spmm14sddmmCSR2ScaleIfEEviiimPiS1_PT_S3_S3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7ge_spmm14sddmmCSR2ScaleIfEEviiimPiS1_PT_S3_S3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7ge_spmm14sddmmCOO1ScaleIfEEviiimPiS1_PT_S3_S3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7ge_spmm14sddmmCOO1ScaleIfEEviiimPiS1_PT_S3_S3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 61 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7ge_spmm14sddmmCOO2ScaleIfEEviiimPiS1_PT_S3_S3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7ge_spmm14sddmmCOO2ScaleIfEEviiimPiS1_PT_S3_S3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7ge_spmm14sddmmCOO4ScaleIfEEviiimPiS1_PT_S3_S3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7ge_spmm14sddmmCOO4ScaleIfEEviiimPiS1_PT_S3_S3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 74 registers, 416 bytes cmem[0]\n",
            "  [12/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/spmm.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/cuda/spmm.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/spmm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIfffLi1ELi32ELi32ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES5_PKNS6_11ScalarIndexES9_PKfPS7_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIfffLi1ELi32ELi32ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES5_PKNS6_11ScalarIndexES9_PKfPS7_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 82 registers, 256 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIfffLi1ELi32ELi32ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES5_PKNS6_11ScalarIndexES9_PKfPS7_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIfffLi1ELi32ELi32ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES5_PKNS6_11ScalarIndexES9_PKfPS7_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 72 registers, 256 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float2S3_Li2ELi32ELi32ELi16ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float2S3_Li2ELi32ELi32ELi16ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 114 registers, 512 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float2S3_Li2ELi32ELi32ELi16ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float2S3_Li2ELi32ELi32ELi16ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 114 registers, 512 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 168 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 176 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi64ELi8ELi4ELi0ELb1ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi64ELi8ELi4ELi0ELb1ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 128 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi64ELi8ELi4ELi0ELb1ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi64ELi8ELi4ELi0ELb1ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 254 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 128 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4S3_Li4ELi32ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 164 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 114 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 114 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 104 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float46float2Li4ELi32ELi16ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 104 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 84 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 72 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 74 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float4fLi4ELi32ELi8ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 72 registers, 1024 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float26float4Li4ELi16ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIf6float26float4Li4ELi16ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 102 registers, 512 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float26float4Li4ELi16ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIf6float26float4Li4ELi16ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES7_PKNS8_11ScalarIndexESB_PKfPS9_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 102 registers, 512 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIff6float4Li4ELi8ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIff6float4Li4ELi8ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 66 registers, 256 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIff6float4Li4ELi8ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIff6float4Li4ELi8ELi32ELi8ELi4ELi0ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 256 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIff6float4Li1ELi32ELi128ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c57Kernel2INS_10SpmmConfigIff6float4Li1ELi32ELi128ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 166 registers, 256 bytes smem, 428 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIff6float4Li1ELi32ELi128ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7sputnik39_GLOBAL__N__0b3b7516_7_spmm_cu_4ffa47c517KernelWithBounds2INS_10SpmmConfigIff6float4Li1ELi32ELi128ELi32ELi4ELi1ELb0ELi8EEEEEviiiPKiPKNT_11ScalarValueES6_PKNS7_11ScalarIndexESA_PKfPS8_i\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 168 registers, 256 bytes smem, 428 bytes cmem[0]\n",
            "  [13/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/sddmm.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/sddmm.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [14/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/matmul.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/matmul.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [15/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/sparse_softmax.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/sparse_softmax.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [16/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/spmm.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/attention/spmm.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [17/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/memset_32b.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sequence_parallel_fused/memset_32b.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/memset_32b.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [18/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/nvcc_info.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/nvcc_info.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/nvcc_info.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  [19/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/synchronization.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sequence_parallel_fused/synchronization.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/synchronization.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [20/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/memset_32b_kernels.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sequence_parallel_fused/memset_32b_kernels.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/memset_32b_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  [21/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/meta_utils.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/meta_utils.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/meta_utils.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 8 bytes gmem, 64 bytes cmem[4]\n",
            "  [22/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/gemm.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/gemm.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 8 bytes gmem, 64 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi64ELi128EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ESY_Li16EEELSV_1EfNSE_8RowMajorENSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S11_fS13_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_S13_SD_SF_fS13_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEES13_EENS25_20TileIteratorTensorOpIS1H_S1K_fS13_EENS1W_18SharedLoadIteratorINS23_18CompactedThreadMapEfLi32EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi64ELi128EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ESY_Li16EEELSV_1EfNSE_8RowMajorENSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S11_fS13_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_S13_SD_SF_fS13_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEES13_EENS25_20TileIteratorTensorOpIS1H_S1K_fS13_EENS1W_18SharedLoadIteratorINS23_18CompactedThreadMapEfLi32EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 744 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_8RowMajorELi0ENSG_INSH_ILi128ELi64EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSX_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSX_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEESX_EENS25_20TileIteratorTensorOpIS1H_S1K_fSX_EENS1W_18SharedLoadIteratorINS23_18CompactedThreadMapEfLi32EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_8RowMajorELi0ENSG_INSH_ILi128ELi64EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSX_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSX_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEESX_EENS25_20TileIteratorTensorOpIS1H_S1K_fSX_EENS1W_18SharedLoadIteratorINS23_18CompactedThreadMapEfLi32EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 62 registers, 744 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi64ELi128EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ES10_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSX_Li0ES1A_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S13_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_20TileIteratorTensorOpIS1I_S1L_fSF_EENS1X_18SharedLoadIteratorINS24_18CompactedThreadMapEfLi32EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi64ELi128EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ES10_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSX_Li0ES1A_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S13_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_20TileIteratorTensorOpIS1I_S1L_fSF_EENS1X_18SharedLoadIteratorINS24_18CompactedThreadMapEfLi32EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 744 bytes cmem[0], 8 bytes cmem[2]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi128ELi64EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtNSE_11ColumnMajorELi0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_S1D_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_20TileIteratorTensorOpIS1I_S1L_fSF_EENS1X_18SharedLoadIteratorINS24_18CompactedThreadMapEfLi32EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_10bfloat16_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi128ELi64EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtNSE_11ColumnMajorELi0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_S1D_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_20TileIteratorTensorOpIS1I_S1L_fSF_EENS1X_18SharedLoadIteratorINS24_18CompactedThreadMapEfLi32EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 744 bytes cmem[0], 8 bytes cmem[2]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi64ELi128EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ESY_Li16EEELSV_1EfNSE_8RowMajorENSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S11_fS13_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_S13_SD_SF_fS13_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEES13_EENS25_25TileIteratorTensorOpMixedIS1H_S1K_fLi32ELi16ELi8ELi8ELb0EEENS1W_23SharedLoadIteratorMixedINS23_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi64ELi128EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ESY_Li16EEELSV_1EfNSE_8RowMajorENSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S11_fS13_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_S13_SD_SF_fS13_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEES13_EENS25_25TileIteratorTensorOpMixedIS1H_S1K_fLi32ELi16ELi8ELi8ELb0EEENS1W_23SharedLoadIteratorMixedINS23_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 744 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_8RowMajorELi0ENSG_INSH_ILi128ELi64EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSX_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSX_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEESX_EENS25_25TileIteratorTensorOpMixedIS1H_S1K_fLi32ELi16ELi8ELi8ELb0EEENS1W_23SharedLoadIteratorMixedINS23_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi256ELi32EEELi256ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_8RowMajorELi0ENSG_INSH_ILi128ELi64EEELi256ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSX_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSF_Li0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSX_NS1F_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1S_S1S_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1R_Li1ENS1W_22PredicatedTileIteratorINS1W_26OutputTileOptimalThreadMapINS1W_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS20_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1V_4warp24FragmentIteratorTensorOpIS1H_S1K_fNSL_IfLi4ELb1EEESX_EENS25_25TileIteratorTensorOpMixedIS1H_S1K_fLi32ELi16ELi8ELi8ELb0EEENS1W_23SharedLoadIteratorMixedINS23_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1V_6thread17LinearCombinationISD_Li8EffLNS2E_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 62 registers, 744 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi64ELi128EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ES10_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSX_Li0ES1A_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S13_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_25TileIteratorTensorOpMixedIS1I_S1L_fLi32ELi16ELi8ELi8ELb0EEENS1X_23SharedLoadIteratorMixedINS24_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi64ELi128EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi64EEELi1ES10_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtSX_Li0ES1A_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S13_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_25TileIteratorTensorOpMixedIS1I_S1L_fLi32ELi16ELi8ELi8ELb0EEENS1X_23SharedLoadIteratorMixedINS24_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 62 registers, 744 bytes cmem[0], 8 bytes cmem[2]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi128ELi64EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtNSE_11ColumnMajorELi0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_S1D_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_25TileIteratorTensorOpMixedIS1I_S1L_fLi32ELi16ELi8ELi8ELb0EEENS1X_23SharedLoadIteratorMixedINS24_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel10SparseGemmINS1_11threadblock19SparseMmaMultistageINS1_9GemmShapeILi256ELi128ELi64EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi256ELi32EEENS_6half_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi256EEELi256ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi64ELi128EEESD_SF_Li0ENSG_INSH_ILi128ELi64EEELi256ENSH_ILi8ELi4EEELi8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESZ_Li16EEELSV_1EfSF_NSA_INSB_ILi256ELi4EEEtNSE_22ColumnMajorInterleavedILi2EEELi1ENS8_30PitchLinearStripminedThreadMapINSH_ILi512ELi2EEELi128ELi8EEENSL_ItLi8ELb0EEELb0ESN_EENSP_INSB_ILi512ELi2EEEtNSE_11ColumnMajorELi0ES19_Li16EEELSV_1ENS4_15SparseMmaPolicyINS1_4warp17SparseMmaTensorOpINS6_ILi64ELi64ELi64EEESD_SR_SD_S12_fSF_NS1G_17MmaTensorOpPolicyINST_9SparseMmaINS6_ILi16ELi8ELi32EEELi32ESD_SF_SD_S1D_fSF_NST_13OpMultiplyAddELNST_12SPFormatType4KindE0EEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1T_S1T_Li1EEELi4EbEENS_8epilogue11threadblock8EpilogueIS7_S1S_Li1ENS1X_22PredicatedTileIteratorINS1X_26OutputTileOptimalThreadMapINS1X_15OutputTileShapeILi128ELi8ELi4ELi1ELi1EEENS21_ILi1ELi8ELi1ELi1ELi8EEELi256ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1W_4warp24FragmentIteratorTensorOpIS1I_S1L_fNSL_IfLi4ELb1EEESF_EENS26_25TileIteratorTensorOpMixedIS1I_S1L_fLi32ELi16ELi8ELi8ELb0EEENS1X_23SharedLoadIteratorMixedINS24_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1W_6thread17LinearCombinationISD_Li8EffLNS2F_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS4_30GemmIdentityThreadblockSwizzleILi3EEELb0EEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 62 registers, 744 bytes cmem[0], 8 bytes cmem[2]\n",
            "  [23/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/sparse24.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [24/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/synchronization_kernels.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sequence_parallel_fused/synchronization_kernels.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/synchronization_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 317 bytes gmem, 80 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN64_GLOBAL__N__e2ac1b78_26_synchronization_kernels_cu_f6c39a24_337318wait_values_kernelESt5arrayIPiLm8EEmim' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN64_GLOBAL__N__e2ac1b78_26_synchronization_kernels_cu_f6c39a24_337318wait_values_kernelESt5arrayIPiLm8EEmim\n",
            "      64 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 27 registers, 64 bytes cumulative stack size, 440 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN64_GLOBAL__N__e2ac1b78_26_synchronization_kernels_cu_f6c39a24_337319write_values_kernelESt5arrayIPiLm8EEmi' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN64_GLOBAL__N__e2ac1b78_26_synchronization_kernels_cu_f6c39a24_337319write_values_kernelESt5arrayIPiLm8EEmi\n",
            "      64 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 20 registers, 64 bytes cumulative stack size, 428 bytes cmem[0]\n",
            "  [25/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_apply.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/sparse24_apply.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_apply.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN55_GLOBAL__N__881af683_17_sparse24_apply_cu_f6c39a24_395321sparse24_apply_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN55_GLOBAL__N__881af683_17_sparse24_apply_cu_f6c39a24_395321sparse24_apply_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 107 registers, 424 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN55_GLOBAL__N__881af683_17_sparse24_apply_cu_f6c39a24_395321sparse24_apply_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN55_GLOBAL__N__881af683_17_sparse24_apply_cu_f6c39a24_395321sparse24_apply_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 107 registers, 424 bytes cmem[0]\n",
            "  [26/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_apply_dense_output.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/sparse24_apply_dense_output.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_apply_dense_output.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass10bfloat16_tELb0ELb1EEEvNS_6ParamsIT_EE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass10bfloat16_tELb0ELb1EEEvNS_6ParamsIT_EE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 58 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass10bfloat16_tELb1ELb1EEEvNS_6ParamsIT_EE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass10bfloat16_tELb1ELb1EEEvNS_6ParamsIT_EE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 50 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass6half_tELb0ELb1EEEvNS_6ParamsIT_EE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass6half_tELb0ELb1EEEvNS_6ParamsIT_EE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 82 registers, 416 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass6half_tELb1ELb1EEEvNS_6ParamsIT_EE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN68_GLOBAL__N__bf63448f_30_sparse24_apply_dense_output_cu_440feaf2_407929sparse24_apply_dense_output_kIN7cutlass6half_tELb1ELb1EEEvNS_6ParamsIT_EE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 82 registers, 416 bytes cmem[0]\n",
            "  [27/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_largest_mask_2d.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/sparse24_largest_mask_2d.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_largest_mask_2d.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass10bfloat16_tELb1EEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass10bfloat16_tELb1EEEvNT_6ParamsE\n",
            "      8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 70 registers, 8 bytes cumulative stack size, 400 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass6half_tELb1EEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass6half_tELb1EEEvNT_6ParamsE\n",
            "      8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 8 bytes cumulative stack size, 400 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass10bfloat16_tELb0EEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass10bfloat16_tELb0EEEvNT_6ParamsE\n",
            "      8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 63 registers, 8 bytes cumulative stack size, 400 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass6half_tELb0EEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _Z27sparse24_largest_mask_2d_cuI14Sp24MaskKernelIN7cutlass6half_tELb0EEEvNT_6ParamsE\n",
            "      8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 64 registers, 8 bytes cumulative stack size, 400 bytes cmem[0]\n",
            "  [28/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_pack_test.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/sparse24_pack_test.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_pack_test.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN59_GLOBAL__N__3506ffbb_21_sparse24_pack_test_cu_440feaf2_451224meta_shuffle_test_kernelEN2at27GenericPackedTensorAccessorIlLm3ENS0_16DefaultPtrTraitsElEES3_b' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN59_GLOBAL__N__3506ffbb_21_sparse24_pack_test_cu_440feaf2_451224meta_shuffle_test_kernelEN2at27GenericPackedTensorAccessorIlLm3ENS0_16DefaultPtrTraitsElEES3_b\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 20 registers, 465 bytes cmem[0]\n",
            "  [29/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/dual_gemm_silu_identity_mul.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/swiglu/cuda/dual_gemm_silu_identity_mul.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/dual_gemm_silu_identity_mul.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 872 bytes gmem, 96 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel8DualGemmINS1_11threadblock17DualMmaMultistageINS1_9GemmShapeILi128ELi64ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_10bfloat16_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi128EEELi128ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi64EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi32ELi64EEELi128ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi1ESZ_Li16EEELSV_1ES10_S13_fSF_NS4_9MmaPolicyINS1_4warp11MmaTensorOpINS6_ILi64ELi32ELi32EEESD_SR_SD_S12_fSF_NS15_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1G_Li1EEES1H_Li3ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1F_Li1ENS1L_22PredicatedTileIteratorINS1L_26OutputTileOptimalThreadMapINS1L_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1P_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1K_4warp24FragmentIteratorTensorOpIS17_S1A_fNSL_IfLi4ELb1EEESF_EENS1U_20TileIteratorTensorOpIS17_S1A_fSF_EENS1L_18SharedLoadIteratorINS1S_18CompactedThreadMapEfLi32EEENS1K_6thread17LinearCombinationISD_Li8EffLNS23_9ScaleType4KindE1ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEES2A_NS23_14LeftSiLUAndMulISD_Li8ESD_fLS27_2EEENS4_30GemmIdentityThreadblockSwizzleILi2EEELb0ELb1ELb1EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel8DualGemmINS1_11threadblock17DualMmaMultistageINS1_9GemmShapeILi128ELi64ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_10bfloat16_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi128EEELi128ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi64EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi32ELi64EEELi128ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi1ESZ_Li16EEELSV_1ES10_S13_fSF_NS4_9MmaPolicyINS1_4warp11MmaTensorOpINS6_ILi64ELi32ELi32EEESD_SR_SD_S12_fSF_NS15_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1G_Li1EEES1H_Li3ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1F_Li1ENS1L_22PredicatedTileIteratorINS1L_26OutputTileOptimalThreadMapINS1L_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1P_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1K_4warp24FragmentIteratorTensorOpIS17_S1A_fNSL_IfLi4ELb1EEESF_EENS1U_20TileIteratorTensorOpIS17_S1A_fSF_EENS1L_18SharedLoadIteratorINS1S_18CompactedThreadMapEfLi32EEENS1K_6thread17LinearCombinationISD_Li8EffLNS23_9ScaleType4KindE1ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEES2A_NS23_14LeftSiLUAndMulISD_Li8ESD_fLS27_2EEENS4_30GemmIdentityThreadblockSwizzleILi2EEELb0ELb1ELb1EEEEEvNT_6ParamsE\n",
            "      8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 80 registers, 8 bytes cumulative stack size, 1072 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass6KernelINS_4gemm6kernel8DualGemmINS1_11threadblock17DualMmaMultistageINS1_9GemmShapeILi128ELi64ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_6half_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi128EEELi128ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi64EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi32ELi64EEELi128ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi1ESZ_Li16EEELSV_1ES10_S13_fSF_NS4_9MmaPolicyINS1_4warp11MmaTensorOpINS6_ILi64ELi32ELi32EEESD_SR_SD_S12_fSF_NS15_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1G_Li1EEES1H_Li3ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1F_Li1ENS1L_22PredicatedTileIteratorINS1L_26OutputTileOptimalThreadMapINS1L_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1P_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1K_4warp24FragmentIteratorTensorOpIS17_S1A_fNSL_IfLi4ELb1EEESF_EENS1U_25TileIteratorTensorOpMixedIS17_S1A_fLi32ELi16ELi8ELi8ELb0EEENS1L_23SharedLoadIteratorMixedINS1S_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1K_6thread17LinearCombinationISD_Li8EffLNS23_9ScaleType4KindE1ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEES2A_NS23_14LeftSiLUAndMulISD_Li8ESD_fLS27_2EEENS4_30GemmIdentityThreadblockSwizzleILi2EEELb0ELb1ELb1EEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass6KernelINS_4gemm6kernel8DualGemmINS1_11threadblock17DualMmaMultistageINS1_9GemmShapeILi128ELi64ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_6half_tENS_6layout8RowMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi32ELi128EEELi128ENSH_ILi4ELi8EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_37RowMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi0ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi64EEESD_NSE_11ColumnMajorELi0ENSG_INSH_ILi32ELi64EEELi128ESJ_Li8EEESM_Lb0ESN_EENSP_ISW_SD_NSE_40ColumnMajorTensorOpMultiplicandCrosswiseILi16ELi32EEELi1ESZ_Li16EEELSV_1ES10_S13_fSF_NS4_9MmaPolicyINS1_4warp11MmaTensorOpINS6_ILi64ELi32ELi32EEESD_SR_SD_S12_fSF_NS15_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SF_SD_SX_fSF_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELi1ELb0EbEENSB_ILi0ELi0EEES1G_Li1EEES1H_Li3ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1F_Li1ENS1L_22PredicatedTileIteratorINS1L_26OutputTileOptimalThreadMapINS1L_15OutputTileShapeILi64ELi8ELi2ELi1ELi1EEENS1P_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1K_4warp24FragmentIteratorTensorOpIS17_S1A_fNSL_IfLi4ELb1EEESF_EENS1U_25TileIteratorTensorOpMixedIS17_S1A_fLi32ELi16ELi8ELi8ELb0EEENS1L_23SharedLoadIteratorMixedINS1S_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1K_6thread17LinearCombinationISD_Li8EffLNS23_9ScaleType4KindE1ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEES2A_NS23_14LeftSiLUAndMulISD_Li8ESD_fLS27_2EEENS4_30GemmIdentityThreadblockSwizzleILi2EEELb0ELb1ELb1EEEEEvNT_6ParamsE\n",
            "      8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 80 registers, 8 bytes cumulative stack size, 1072 bytes cmem[0]\n",
            "  [30/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_pack.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/sparse24/sparse24_pack.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_pack.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas warning : Value of minnctapersm for entry _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_ is out of range. minnctapersm will be ignored\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 147 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 157 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 144 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 150 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 150 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass10bfloat16_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 145 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 147 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 152 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_15MetadataCutlassENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 146 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_5AbsOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 150 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_10Causal1122INS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 149 registers, 457 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN54_GLOBAL__N__76823a08_16_sparse24_pack_cu_f6c39a24_440134sparse24_sparsify_both_ways_kernelIN8xformers4sp2411KernelTypesIN7cutlass6half_tEEENS2_18MetadataCuSparseLtENS2_19LargestValuesGreedyINS2_10IdentityOpEEEEEvNT_6ParamsET0_T1_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 149 registers, 457 bytes cmem[0]\n",
            "  [31/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/swiglu_op.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/swiglu/swiglu_op.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/swiglu_op.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  [32/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/gemm_fused_operand_sum.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/swiglu/cuda/gemm_fused_operand_sum.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/gemm_fused_operand_sum.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 8 bytes gmem, 64 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass7Kernel2INS_4gemm6kernel18GemmWithKReductionINS1_11threadblock26MmaWithReductionMultistageINS1_9GemmShapeILi128ELi128ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_10bfloat16_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi32EEELi128ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi128EEESD_NSE_8RowMajorELi0ESK_SM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESK_Li16EEELSV_1EfSX_NS4_9MmaPolicyINS1_4warp24MmaWithReductionTensorOpINS6_ILi64ELi64ELi32EEESD_SR_SD_S10_fSX_NS13_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELb1ELi1ELb0EbEENSB_ILi0ELi0EEES1E_Li1EEELi4ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1D_Li1ENS1J_22PredicatedTileIteratorINS1J_26OutputTileOptimalThreadMapINS1J_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1N_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1I_4warp24FragmentIteratorTensorOpIS15_S18_fNSL_IfLi4ELb1EEESX_EENS1S_20TileIteratorTensorOpIS15_S18_fSX_EENS1J_18SharedLoadIteratorINS1Q_18CompactedThreadMapEfLi32EEENS1I_6thread17LinearCombinationISD_Li8EffLNS21_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS1J_22EpilogueGemmKReductionIfSD_S7_S1D_Lb1EEENS4_30GemmIdentityThreadblockSwizzleILi8EEEEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass7Kernel2INS_4gemm6kernel18GemmWithKReductionINS1_11threadblock26MmaWithReductionMultistageINS1_9GemmShapeILi128ELi128ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_10bfloat16_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi32EEELi128ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi128EEESD_NSE_8RowMajorELi0ESK_SM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESK_Li16EEELSV_1EfSX_NS4_9MmaPolicyINS1_4warp24MmaWithReductionTensorOpINS6_ILi64ELi64ELi32EEESD_SR_SD_S10_fSX_NS13_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELb1ELi1ELb0EbEENSB_ILi0ELi0EEES1E_Li1EEELi4ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1D_Li1ENS1J_22PredicatedTileIteratorINS1J_26OutputTileOptimalThreadMapINS1J_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1N_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1I_4warp24FragmentIteratorTensorOpIS15_S18_fNSL_IfLi4ELb1EEESX_EENS1S_20TileIteratorTensorOpIS15_S18_fSX_EENS1J_18SharedLoadIteratorINS1Q_18CompactedThreadMapEfLi32EEENS1I_6thread17LinearCombinationISD_Li8EffLNS21_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi1ELi1EEENS1J_22EpilogueGemmKReductionIfSD_S7_S1D_Lb1EEENS4_30GemmIdentityThreadblockSwizzleILi8EEEEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 56 registers, 712 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN7cutlass7Kernel2INS_4gemm6kernel18GemmWithKReductionINS1_11threadblock26MmaWithReductionMultistageINS1_9GemmShapeILi128ELi128ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_6half_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi32EEELi128ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi128EEESD_NSE_8RowMajorELi0ESK_SM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESK_Li16EEELSV_1EfSX_NS4_9MmaPolicyINS1_4warp24MmaWithReductionTensorOpINS6_ILi64ELi64ELi32EEESD_SR_SD_S10_fSX_NS13_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELb1ELi1ELb0EbEENSB_ILi0ELi0EEES1E_Li1EEELi4ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1D_Li1ENS1J_22PredicatedTileIteratorINS1J_26OutputTileOptimalThreadMapINS1J_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1N_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1I_4warp24FragmentIteratorTensorOpIS15_S18_fNSL_IfLi4ELb1EEESX_EENS1S_25TileIteratorTensorOpMixedIS15_S18_fLi32ELi16ELi8ELi8ELb0EEENS1J_23SharedLoadIteratorMixedINS1Q_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1I_6thread17LinearCombinationISD_Li8EffLNS21_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS1J_22EpilogueGemmKReductionIfSD_S7_S1D_Lb1EEENS4_30GemmIdentityThreadblockSwizzleILi8EEEEEEEvNT_6ParamsE' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN7cutlass7Kernel2INS_4gemm6kernel18GemmWithKReductionINS1_11threadblock26MmaWithReductionMultistageINS1_9GemmShapeILi128ELi128ELi32EEENS_9transform11threadblock28PredicatedTileAccessIteratorINS_11MatrixShapeILi128ELi32EEENS_6half_tENS_6layout11ColumnMajorELi1ENS8_29PitchLinearWarpRakedThreadMapINS_16PitchLinearShapeILi128ELi32EEELi128ENSH_ILi8ELi4EEELi8EEENS_5ArrayISD_Li8ELb0EEELb0ENSE_9NoPermuteEEENS9_25RegularTileAccessIteratorISC_SD_NSE_40ColumnMajorTensorOpMultiplicandCongruousILi16ELi64EEELi1ESK_Li16EEELNS_4arch14CacheOperation4KindE1ENSA_INSB_ILi32ELi128EEESD_NSE_8RowMajorELi0ESK_SM_Lb0ESN_EENSP_ISW_SD_NSE_37RowMajorTensorOpMultiplicandCongruousILi16ELi64EEELi0ESK_Li16EEELSV_1EfSX_NS4_9MmaPolicyINS1_4warp24MmaWithReductionTensorOpINS6_ILi64ELi64ELi32EEESD_SR_SD_S10_fSX_NS13_17MmaTensorOpPolicyINST_3MmaINS6_ILi16ELi8ELi16EEELi32ESD_SX_SD_SF_fSX_NST_13OpMultiplyAddEEENSB_ILi1ELi1EEEEELb1ELi1ELb0EbEENSB_ILi0ELi0EEES1E_Li1EEELi4ELNS1_23SharedMemoryClearOptionE0EbEENS_8epilogue11threadblock8EpilogueIS7_S1D_Li1ENS1J_22PredicatedTileIteratorINS1J_26OutputTileOptimalThreadMapINS1J_15OutputTileShapeILi128ELi8ELi2ELi1ELi1EEENS1N_ILi1ELi8ELi1ELi1ELi8EEELi128ELi8ELi16EEESD_Lb0ESN_Lb0EEENS1I_4warp24FragmentIteratorTensorOpIS15_S18_fNSL_IfLi4ELb1EEESX_EENS1S_25TileIteratorTensorOpMixedIS15_S18_fLi32ELi16ELi8ELi8ELb0EEENS1J_23SharedLoadIteratorMixedINS1Q_18CompactedThreadMapEfLi32ELi16ELi8ELi8ELb0EEENS1I_6thread17LinearCombinationISD_Li8EffLNS21_9ScaleType4KindE0ELNS_15FloatRoundStyleE2ESD_EENSB_ILi0ELi8EEELi2ELi1EEENS1J_22EpilogueGemmKReductionIfSD_S7_S1D_Lb1EEENS4_30GemmIdentityThreadblockSwizzleILi8EEEEEEEvNT_6ParamsE\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 53 registers, 712 bytes cmem[0]\n",
            "  [33/34] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/silu_bw_fused.o.d -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/swiglu/cuda/silu_bw_fused.cu -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/silu_bw_fused.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "  ptxas info    : 6 bytes gmem, 48 bytes cmem[4]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 30 registers, 1624 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 32 registers, 418 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 28 registers, 1624 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 32 registers, 418 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 28 registers, 1624 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 34 registers, 418 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 44 registers, 1624 bytes cmem[0], 88 bytes cmem[2]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb1EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 44 registers, 418 bytes cmem[0], 88 bytes cmem[2]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 30 registers, 1624 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE2_clEvEUlN3c108BFloat16ESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 32 registers, 418 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 28 registers, 1624 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE1_clEvEUlN3c104HalfESE_SE_E_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESL_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 32 registers, 418 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 28 registers, 1624 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE0_clEvEUlfffE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 34 registers, 418 bytes cmem[0]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE16OffsetCalculatorILi3EjLb0EESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 44 registers, 1624 bytes cmem[0], 88 bytes cmem[2]\n",
            "  ptxas info    : Compiling entry function '_ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_' for 'sm_75'\n",
            "  ptxas info    : Function properties for _ZN2at6native54_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505045unrolled_elementwise_kernel_for_multi_outputsILi3EZZZN52_INTERNAL_e9a3ca45_16_silu_bw_fused_cu_440feaf2_505054_GLOBAL__N__e9a3ca45_16_silu_bw_fused_cu_440feaf2_505013silu_bw_fusedILb0EEESt5tupleIJNS_6TensorES7_EERKS7_SA_SA_ENKUlvE_clEvENKUlvE_clEvEUldddE_NS_6detail5ArrayIPcLi6EEE23TrivialOffsetCalculatorILi3EjESJ_EEviT0_T1_T2_T3_\n",
            "      0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "  ptxas info    : Used 44 registers, 418 bytes cmem[0], 88 bytes cmem[2]\n",
            "  [34/34] c++ -MMD -MF /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/swiglu_packedw.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-req-build-mzf203xk/xformers/csrc -I/tmp/pip-req-build-mzf203xk/third_party/sputnik -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/tools/util/include -I/tmp/pip-req-build-mzf203xk/third_party/cutlass/examples -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /tmp/pip-req-build-mzf203xk/xformers/csrc/swiglu/swiglu_packedw.cpp -o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/swiglu_packedw.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/attention.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/autograd/matmul.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/matmul.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sddmm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/sparse_softmax.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cpu/spmm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/fmha/attention_cutlass_rand_uniform.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/matmul.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sddmm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sddmm2_cuda.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/sparse_softmax.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/cuda/spmm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/matmul.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/sddmm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/sparse_softmax.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/attention/spmm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/nvcc_info.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/memset_32b.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/memset_32b_kernels.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/synchronization.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sequence_parallel_fused/synchronization_kernels.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/gemm.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/meta_utils.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_apply.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_apply_dense_output.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_largest_mask_2d.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_pack.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/sparse24/sparse24_pack_test.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/dual_gemm_silu_identity_mul.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/gemm_fused_operand_sum.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/cuda/silu_bw_fused.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/swiglu_op.o /tmp/pip-req-build-mzf203xk/build/temp.linux-x86_64-cpython-311/xformers/csrc/swiglu/swiglu_packedw.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/xformers/_C.so\n",
            "  /usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Please avoid running ``setup.py`` directly.\n",
            "          Instead, use pypa/build, pypa/installer or other\n",
            "          standards-based tools.\n",
            "\n",
            "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    self.initialize_options()\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_deprecation_warning.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/version.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/test.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/checkpoint.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/input_projection.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/linformer.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/components/attention/feature_maps\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps/softmax.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention/feature_maps\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention/feature_maps\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/feature_maps/base.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention/feature_maps\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/global_tokens.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/attention_patterns.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/scaled_dot_product.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/sparsity_config.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/fourier_mix.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/visual.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/lambda_layer.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/utils.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/favor.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/random.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/ortho.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/local.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/base.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/compositional.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/pooling.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/core.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/nystrom.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/attention_mask.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/attention/_sputnik_sparse.py -> build/bdist.linux-x86_64/wheel/./xformers/components/attention\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/components/feedforward\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/feedforward/mlp.py -> build/bdist.linux-x86_64/wheel/./xformers/components/feedforward\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/feedforward/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/components/feedforward\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/feedforward/conv_mlp.py -> build/bdist.linux-x86_64/wheel/./xformers/components/feedforward\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/feedforward/mixture_of_experts.py -> build/bdist.linux-x86_64/wheel/./xformers/components/feedforward\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/feedforward/base.py -> build/bdist.linux-x86_64/wheel/./xformers/components/feedforward\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/simplicial_embedding.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/reversible.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding/vocab.py -> build/bdist.linux-x86_64/wheel/./xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding/param.py -> build/bdist.linux-x86_64/wheel/./xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding/sine.py -> build/bdist.linux-x86_64/wheel/./xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding/rotary.py -> build/bdist.linux-x86_64/wheel/./xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/positional_embedding/base.py -> build/bdist.linux-x86_64/wheel/./xformers/components/positional_embedding\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/residual.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/patch_embedding.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/activations.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/components/multi_head_dispatch.py -> build/bdist.linux-x86_64/wheel/./xformers/components\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_C.so -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/device_limits.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/profiler.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/profiler_dcgm_impl.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/find_slowest.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/api.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/profiler_dcgm.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/profiler/profile_analyzer.py -> build/bdist.linux-x86_64/wheel/./xformers/profiler\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/triton/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/triton/vararg_kernel.py -> build/bdist.linux-x86_64/wheel/./xformers/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/utils.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/attn_bias_utils.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/info.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/bert_padding.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/flash_attn_triton.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/flash_attn_triton_og.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/flash_attn_interface.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/utils\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/utils\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils/pretrained.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/utils\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils/benchmark.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/utils\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils/generation.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/utils\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/utils/distributed.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/utils\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/modules\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules/embedding.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/modules\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules/mlp.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/modules\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules/mha.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/modules\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/modules\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/modules/block.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/modules\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/layers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers/patch_embed.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/layers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/layers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/layers/rotary.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/layers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/btlm.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/falcon.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/bert.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/gptj.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/gpt_neox.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/gpt.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/vit.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/baichuan.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/llama.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/bigcode.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/models/opt.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/models\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/losses\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/losses/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/losses\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/losses/cross_entropy.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/losses\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/flash_blocksparse_attention.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/layer_norm.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/rms_norm.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/mlp.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/linear.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/rotary.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/k_activations.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/triton/cross_entropy.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops/triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/fused_dense.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/ops/activations.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_flash_attn/fused_softmax.py -> build/bdist.linux-x86_64/wheel/./xformers/_flash_attn\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/cpp_lib.json -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/helpers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/helpers/test_utils.py -> build/bdist.linux-x86_64/wheel/./xformers/helpers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/helpers/hierarchical_configs.py -> build/bdist.linux-x86_64/wheel/./xformers/helpers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/helpers/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/helpers\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/helpers/timm_sparse_attention.py -> build/bdist.linux-x86_64/wheel/./xformers/helpers\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/factory\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/factory/weight_init.py -> build/bdist.linux-x86_64/wheel/./xformers/factory\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/factory/block_configs.py -> build/bdist.linux-x86_64/wheel/./xformers/factory\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/factory/model_factory.py -> build/bdist.linux-x86_64/wheel/./xformers/factory\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/factory/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/factory\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/factory/block_factory.py -> build/bdist.linux-x86_64/wheel/./xformers/factory\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/factory/hydra_helper.py -> build/bdist.linux-x86_64/wheel/./xformers/factory\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_revnet.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_core.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_sddmm.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_swiglu.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_merge_attentions.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_attn_decoding.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_indexing.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_tiled_matmul.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_nystrom_utils.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/utils.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_multi_head_dispatch.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_mem_eff_attention.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/benchmarks/LRA\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/benchmarks/LRA/code\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code/model_wrapper.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA/code\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code/dataset.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA/code\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/code/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA/code\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/batch_submit.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/run_with_submitit.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/run_tasks.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/batch_fetch_results.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/LRA/run_grid_search.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks/LRA\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_sp24.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/bdist.linux-x86_64/wheel/./xformers/benchmarks\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/seqpar.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/rmsnorm.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/sp24.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/common.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/swiglu_op.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/modpar_layers.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/indexing.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/sequence_parallel_fused_ops.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/unbind.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/tiled_matmul.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/rope_padded.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/differentiable_collectives.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/ops/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/_triton/k_index_select_cat.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/_triton/rmsnorm_kernels.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/_triton/k_scaled_index_add.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/_triton/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/_triton/tiled_matmul_kernels.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/_triton/rope_padded_kernels.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/_triton\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/torch_attention_compat.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/common.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/flash3.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/ck_decoder.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/ck.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/flash.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/dispatch.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/triton_splitk.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/ck_splitk.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/attn_bias.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/ops/fmha/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/_triton/splitk_kernels.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/_triton/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha/_triton\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/fmha/cutlass.py -> build/bdist.linux-x86_64/wheel/./xformers/ops/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/ops/ipc.py -> build/bdist.linux-x86_64/wheel/./xformers/ops\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers/sparse\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/sparse/blocksparse_tensor.py -> build/bdist.linux-x86_64/wheel/./xformers/sparse\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/sparse/_csr_ops.py -> build/bdist.linux-x86_64/wheel/./xformers/sparse\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/sparse/__init__.py -> build/bdist.linux-x86_64/wheel/./xformers/sparse\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/sparse/utils.py -> build/bdist.linux-x86_64/wheel/./xformers/sparse\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/sparse/csr_tensor.py -> build/bdist.linux-x86_64/wheel/./xformers/sparse\n",
            "  copying build/lib.linux-x86_64-cpython-311/xformers/_cpp_lib.py -> build/bdist.linux-x86_64/wheel/./xformers\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating xformers.egg-info\n",
            "  writing xformers.egg-info/PKG-INFO\n",
            "  writing dependency_links to xformers.egg-info/dependency_links.txt\n",
            "  writing requirements to xformers.egg-info/requires.txt\n",
            "  writing top-level names to xformers.egg-info/top_level.txt\n",
            "  writing manifest file 'xformers.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'xformers.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'third_party/flash-attention/version.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'xformers.egg-info/SOURCES.txt'\n",
            "  Copying xformers.egg-info to build/bdist.linux-x86_64/wheel/./xformers-0.0.29+de742ec.d20250508-py3.11.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/xformers-0.0.29+de742ec.d20250508.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-xh6arjy3/xformers-0.0.29+de742ec.d20250508-cp311-cp311-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'xformers/_C.so'\n",
            "  adding 'xformers/__init__.py'\n",
            "  adding 'xformers/_cpp_lib.py'\n",
            "  adding 'xformers/_deprecation_warning.py'\n",
            "  adding 'xformers/attn_bias_utils.py'\n",
            "  adding 'xformers/checkpoint.py'\n",
            "  adding 'xformers/cpp_lib.json'\n",
            "  adding 'xformers/info.py'\n",
            "  adding 'xformers/test.py'\n",
            "  adding 'xformers/utils.py'\n",
            "  adding 'xformers/version.py'\n",
            "  adding 'xformers/_flash_attn/__init__.py'\n",
            "  adding 'xformers/_flash_attn/bert_padding.py'\n",
            "  adding 'xformers/_flash_attn/flash_attn_interface.py'\n",
            "  adding 'xformers/_flash_attn/flash_attn_triton.py'\n",
            "  adding 'xformers/_flash_attn/flash_attn_triton_og.py'\n",
            "  adding 'xformers/_flash_attn/flash_blocksparse_attention.py'\n",
            "  adding 'xformers/_flash_attn/flash_blocksparse_attn_interface.py'\n",
            "  adding 'xformers/_flash_attn/fused_softmax.py'\n",
            "  adding 'xformers/_flash_attn/layers/__init__.py'\n",
            "  adding 'xformers/_flash_attn/layers/patch_embed.py'\n",
            "  adding 'xformers/_flash_attn/layers/rotary.py'\n",
            "  adding 'xformers/_flash_attn/losses/__init__.py'\n",
            "  adding 'xformers/_flash_attn/losses/cross_entropy.py'\n",
            "  adding 'xformers/_flash_attn/models/__init__.py'\n",
            "  adding 'xformers/_flash_attn/models/baichuan.py'\n",
            "  adding 'xformers/_flash_attn/models/bert.py'\n",
            "  adding 'xformers/_flash_attn/models/bigcode.py'\n",
            "  adding 'xformers/_flash_attn/models/btlm.py'\n",
            "  adding 'xformers/_flash_attn/models/falcon.py'\n",
            "  adding 'xformers/_flash_attn/models/gpt.py'\n",
            "  adding 'xformers/_flash_attn/models/gpt_neox.py'\n",
            "  adding 'xformers/_flash_attn/models/gptj.py'\n",
            "  adding 'xformers/_flash_attn/models/llama.py'\n",
            "  adding 'xformers/_flash_attn/models/opt.py'\n",
            "  adding 'xformers/_flash_attn/models/vit.py'\n",
            "  adding 'xformers/_flash_attn/modules/__init__.py'\n",
            "  adding 'xformers/_flash_attn/modules/block.py'\n",
            "  adding 'xformers/_flash_attn/modules/embedding.py'\n",
            "  adding 'xformers/_flash_attn/modules/mha.py'\n",
            "  adding 'xformers/_flash_attn/modules/mlp.py'\n",
            "  adding 'xformers/_flash_attn/ops/__init__.py'\n",
            "  adding 'xformers/_flash_attn/ops/activations.py'\n",
            "  adding 'xformers/_flash_attn/ops/fused_dense.py'\n",
            "  adding 'xformers/_flash_attn/ops/layer_norm.py'\n",
            "  adding 'xformers/_flash_attn/ops/rms_norm.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/__init__.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/cross_entropy.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/k_activations.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/layer_norm.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/linear.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/mlp.py'\n",
            "  adding 'xformers/_flash_attn/ops/triton/rotary.py'\n",
            "  adding 'xformers/_flash_attn/utils/__init__.py'\n",
            "  adding 'xformers/_flash_attn/utils/benchmark.py'\n",
            "  adding 'xformers/_flash_attn/utils/distributed.py'\n",
            "  adding 'xformers/_flash_attn/utils/generation.py'\n",
            "  adding 'xformers/_flash_attn/utils/pretrained.py'\n",
            "  adding 'xformers/benchmarks/__init__.py'\n",
            "  adding 'xformers/benchmarks/benchmark_attn_decoding.py'\n",
            "  adding 'xformers/benchmarks/benchmark_core.py'\n",
            "  adding 'xformers/benchmarks/benchmark_indexing.py'\n",
            "  adding 'xformers/benchmarks/benchmark_mem_eff_attention.py'\n",
            "  adding 'xformers/benchmarks/benchmark_merge_attentions.py'\n",
            "  adding 'xformers/benchmarks/benchmark_multi_head_dispatch.py'\n",
            "  adding 'xformers/benchmarks/benchmark_nystrom_utils.py'\n",
            "  adding 'xformers/benchmarks/benchmark_revnet.py'\n",
            "  adding 'xformers/benchmarks/benchmark_sddmm.py'\n",
            "  adding 'xformers/benchmarks/benchmark_sequence_parallel_fused.py'\n",
            "  adding 'xformers/benchmarks/benchmark_sp24.py'\n",
            "  adding 'xformers/benchmarks/benchmark_swiglu.py'\n",
            "  adding 'xformers/benchmarks/benchmark_tiled_matmul.py'\n",
            "  adding 'xformers/benchmarks/utils.py'\n",
            "  adding 'xformers/benchmarks/LRA/__init__.py'\n",
            "  adding 'xformers/benchmarks/LRA/batch_fetch_results.py'\n",
            "  adding 'xformers/benchmarks/LRA/batch_submit.py'\n",
            "  adding 'xformers/benchmarks/LRA/run_grid_search.py'\n",
            "  adding 'xformers/benchmarks/LRA/run_tasks.py'\n",
            "  adding 'xformers/benchmarks/LRA/run_with_submitit.py'\n",
            "  adding 'xformers/benchmarks/LRA/code/__init__.py'\n",
            "  adding 'xformers/benchmarks/LRA/code/dataset.py'\n",
            "  adding 'xformers/benchmarks/LRA/code/model_wrapper.py'\n",
            "  adding 'xformers/components/__init__.py'\n",
            "  adding 'xformers/components/activations.py'\n",
            "  adding 'xformers/components/input_projection.py'\n",
            "  adding 'xformers/components/multi_head_dispatch.py'\n",
            "  adding 'xformers/components/patch_embedding.py'\n",
            "  adding 'xformers/components/residual.py'\n",
            "  adding 'xformers/components/reversible.py'\n",
            "  adding 'xformers/components/simplicial_embedding.py'\n",
            "  adding 'xformers/components/attention/__init__.py'\n",
            "  adding 'xformers/components/attention/_sputnik_sparse.py'\n",
            "  adding 'xformers/components/attention/attention_mask.py'\n",
            "  adding 'xformers/components/attention/attention_patterns.py'\n",
            "  adding 'xformers/components/attention/base.py'\n",
            "  adding 'xformers/components/attention/compositional.py'\n",
            "  adding 'xformers/components/attention/core.py'\n",
            "  adding 'xformers/components/attention/favor.py'\n",
            "  adding 'xformers/components/attention/fourier_mix.py'\n",
            "  adding 'xformers/components/attention/global_tokens.py'\n",
            "  adding 'xformers/components/attention/lambda_layer.py'\n",
            "  adding 'xformers/components/attention/linformer.py'\n",
            "  adding 'xformers/components/attention/local.py'\n",
            "  adding 'xformers/components/attention/nystrom.py'\n",
            "  adding 'xformers/components/attention/ortho.py'\n",
            "  adding 'xformers/components/attention/pooling.py'\n",
            "  adding 'xformers/components/attention/random.py'\n",
            "  adding 'xformers/components/attention/scaled_dot_product.py'\n",
            "  adding 'xformers/components/attention/sparsity_config.py'\n",
            "  adding 'xformers/components/attention/utils.py'\n",
            "  adding 'xformers/components/attention/visual.py'\n",
            "  adding 'xformers/components/attention/feature_maps/__init__.py'\n",
            "  adding 'xformers/components/attention/feature_maps/base.py'\n",
            "  adding 'xformers/components/attention/feature_maps/softmax.py'\n",
            "  adding 'xformers/components/feedforward/__init__.py'\n",
            "  adding 'xformers/components/feedforward/base.py'\n",
            "  adding 'xformers/components/feedforward/conv_mlp.py'\n",
            "  adding 'xformers/components/feedforward/mixture_of_experts.py'\n",
            "  adding 'xformers/components/feedforward/mlp.py'\n",
            "  adding 'xformers/components/positional_embedding/__init__.py'\n",
            "  adding 'xformers/components/positional_embedding/base.py'\n",
            "  adding 'xformers/components/positional_embedding/param.py'\n",
            "  adding 'xformers/components/positional_embedding/rotary.py'\n",
            "  adding 'xformers/components/positional_embedding/sine.py'\n",
            "  adding 'xformers/components/positional_embedding/vocab.py'\n",
            "  adding 'xformers/factory/__init__.py'\n",
            "  adding 'xformers/factory/block_configs.py'\n",
            "  adding 'xformers/factory/block_factory.py'\n",
            "  adding 'xformers/factory/hydra_helper.py'\n",
            "  adding 'xformers/factory/model_factory.py'\n",
            "  adding 'xformers/factory/weight_init.py'\n",
            "  adding 'xformers/helpers/__init__.py'\n",
            "  adding 'xformers/helpers/hierarchical_configs.py'\n",
            "  adding 'xformers/helpers/test_utils.py'\n",
            "  adding 'xformers/helpers/timm_sparse_attention.py'\n",
            "  adding 'xformers/ops/__init__.py'\n",
            "  adding 'xformers/ops/common.py'\n",
            "  adding 'xformers/ops/differentiable_collectives.py'\n",
            "  adding 'xformers/ops/indexing.py'\n",
            "  adding 'xformers/ops/ipc.py'\n",
            "  adding 'xformers/ops/modpar_layers.py'\n",
            "  adding 'xformers/ops/rmsnorm.py'\n",
            "  adding 'xformers/ops/rope_padded.py'\n",
            "  adding 'xformers/ops/seqpar.py'\n",
            "  adding 'xformers/ops/sequence_parallel_fused_ops.py'\n",
            "  adding 'xformers/ops/sp24.py'\n",
            "  adding 'xformers/ops/swiglu_op.py'\n",
            "  adding 'xformers/ops/tiled_matmul.py'\n",
            "  adding 'xformers/ops/unbind.py'\n",
            "  adding 'xformers/ops/_triton/__init__.py'\n",
            "  adding 'xformers/ops/_triton/k_index_select_cat.py'\n",
            "  adding 'xformers/ops/_triton/k_scaled_index_add.py'\n",
            "  adding 'xformers/ops/_triton/rmsnorm_kernels.py'\n",
            "  adding 'xformers/ops/_triton/rope_padded_kernels.py'\n",
            "  adding 'xformers/ops/_triton/tiled_matmul_kernels.py'\n",
            "  adding 'xformers/ops/fmha/__init__.py'\n",
            "  adding 'xformers/ops/fmha/attn_bias.py'\n",
            "  adding 'xformers/ops/fmha/ck.py'\n",
            "  adding 'xformers/ops/fmha/ck_decoder.py'\n",
            "  adding 'xformers/ops/fmha/ck_splitk.py'\n",
            "  adding 'xformers/ops/fmha/common.py'\n",
            "  adding 'xformers/ops/fmha/cutlass.py'\n",
            "  adding 'xformers/ops/fmha/dispatch.py'\n",
            "  adding 'xformers/ops/fmha/flash.py'\n",
            "  adding 'xformers/ops/fmha/flash3.py'\n",
            "  adding 'xformers/ops/fmha/torch_attention_compat.py'\n",
            "  adding 'xformers/ops/fmha/triton_splitk.py'\n",
            "  adding 'xformers/ops/fmha/_triton/__init__.py'\n",
            "  adding 'xformers/ops/fmha/_triton/splitk_kernels.py'\n",
            "  adding 'xformers/profiler/__init__.py'\n",
            "  adding 'xformers/profiler/api.py'\n",
            "  adding 'xformers/profiler/device_limits.py'\n",
            "  adding 'xformers/profiler/find_slowest.py'\n",
            "  adding 'xformers/profiler/profile_analyzer.py'\n",
            "  adding 'xformers/profiler/profiler.py'\n",
            "  adding 'xformers/profiler/profiler_dcgm.py'\n",
            "  adding 'xformers/profiler/profiler_dcgm_impl.py'\n",
            "  adding 'xformers/sparse/__init__.py'\n",
            "  adding 'xformers/sparse/_csr_ops.py'\n",
            "  adding 'xformers/sparse/blocksparse_tensor.py'\n",
            "  adding 'xformers/sparse/csr_tensor.py'\n",
            "  adding 'xformers/sparse/utils.py'\n",
            "  adding 'xformers/triton/__init__.py'\n",
            "  adding 'xformers/triton/vararg_kernel.py'\n",
            "  adding 'xformers-0.0.29+de742ec.d20250508.dist-info/LICENSE'\n",
            "  adding 'xformers-0.0.29+de742ec.d20250508.dist-info/METADATA'\n",
            "  adding 'xformers-0.0.29+de742ec.d20250508.dist-info/WHEEL'\n",
            "  adding 'xformers-0.0.29+de742ec.d20250508.dist-info/top_level.txt'\n",
            "  adding 'xformers-0.0.29+de742ec.d20250508.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for xformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xformers: filename=xformers-0.0.29+de742ec.d20250508-cp311-cp311-linux_x86_64.whl size=14878184 sha256=e0ba03c4527ee5ec1b6e4b894de1e924a890bcf83997b86c715882b6cd67fcb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/6b/f4/6a0199acc811817e733a8748cd0b6959acc83836c57d238492\n",
            "Successfully built xformers\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.29+de742ec.d20250508\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 2))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting msgspec (from -r requirements.txt (line 3))\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting rouge-score (from -r requirements.txt (line 4))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from -r requirements.txt (line 5))\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Collecting tiktoken (from -r requirements.txt (line 7))\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting blobfile (from -r requirements.txt (line 8))\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.19.10)\n",
            "Collecting viztracer (from -r requirements.txt (line 10))\n",
            "  Downloading viztracer-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (26 kB)\n",
            "Collecting lm-eval (from -r requirements.txt (line 11))\n",
            "  Downloading lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.15.2)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (12.0.0)\n",
            "Collecting datatrove (from -r requirements.txt (line 14))\n",
            "  Downloading datatrove-0.5.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (3.10.18)\n",
            "Collecting luigi (from -r requirements.txt (line 16))\n",
            "  Downloading luigi-3.6.0.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.11.4)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (5.5.0)\n",
            "Collecting submitit (from -r requirements.txt (line 19))\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (0.15.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (13.9.4)\n",
            "Requirement already satisfied: huggingface-hub==0.30.* in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (0.30.2)\n",
            "Requirement already satisfied: fsspec[full] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2025.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.*->-r requirements.txt (line 23)) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.*->-r requirements.txt (line 23)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.*->-r requirements.txt (line 23)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.*->-r requirements.txt (line 23)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.*->-r requirements.txt (line 23)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.*->-r requirements.txt (line 23)) (4.13.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 2))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r requirements.txt (line 4)) (1.17.0)\n",
            "Collecting portalocker (from sacrebleu->-r requirements.txt (line 5))\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->-r requirements.txt (line 5)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->-r requirements.txt (line 5))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->-r requirements.txt (line 5)) (5.4.0)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile->-r requirements.txt (line 8))\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 9)) (75.2.0)\n",
            "Collecting objprint>=0.3.0 (from viztracer->-r requirements.txt (line 10))\n",
            "  Downloading objprint-0.3.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (1.6.0)\n",
            "Collecting evaluate (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting jsonlines (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (0.15.2)\n",
            "Collecting pybind11>=2.6.2 (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (1.6.1)\n",
            "Collecting sqlitedict (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (2.6.0.dev20241112+cu121)\n",
            "Collecting tqdm-multiprocess (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (4.51.3)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (0.23.0)\n",
            "Collecting dill (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting word2number (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 11)) (10.7.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->-r requirements.txt (line 13)) (12.570.86)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from datatrove->-r requirements.txt (line 14)) (4.12.3)\n",
            "Collecting loguru>=0.7.0 (from datatrove->-r requirements.txt (line 14))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting multiprocess (from datatrove->-r requirements.txt (line 14))\n",
            "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.5 in /usr/local/lib/python3.11/dist-packages (from luigi->-r requirements.txt (line 16)) (2.9.0.post0)\n",
            "Collecting tenacity<9,>=8 (from luigi->-r requirements.txt (line 16))\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tornado<7,>=5.0 in /usr/local/lib/python3.11/dist-packages (from luigi->-r requirements.txt (line 16)) (6.4.2)\n",
            "Collecting python-daemon (from luigi->-r requirements.txt (line 16))\n",
            "  Downloading python_daemon-3.1.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 17)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 17)) (0.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 18)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 18)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 18)) (1.37.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 19)) (3.1.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->-r requirements.txt (line 20)) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 21)) (2.19.1)\n",
            "Collecting adlfs (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading adlfs-2024.12.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (3.11.15)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (2024.12.1)\n",
            "Requirement already satisfied: distributed in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (2024.12.1)\n",
            "Collecting dropbox (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading dropbox-12.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting dropboxdrivefs (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading dropboxdrivefs-1.4.1.tar.gz (7.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fusepy (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (2025.3.2)\n",
            "Collecting libarchive-c (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading libarchive_c-5.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting ocifs (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading ocifs-1.3.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (1.6.3)\n",
            "Collecting paramiko (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyarrow>=1 in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (18.1.0)\n",
            "Requirement already satisfied: pygit2 in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 22)) (1.18.0)\n",
            "Collecting s3fs (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting smbprotocol (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading smbprotocol-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval->-r requirements.txt (line 11)) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 22)) (1.20.0)\n",
            "Collecting dill (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval->-r requirements.txt (line 11)) (2.2.2)\n",
            "Collecting xxhash (from datasets>=2.16.0->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datatrove->-r requirements.txt (line 14))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.16.0->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting accelerate>=0.26.0 (from lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting fsspec[full] (from -r requirements.txt (line 22))\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9)) (4.0.12)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 18)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 18)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 18)) (0.24.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 21)) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.*->-r requirements.txt (line 23)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.*->-r requirements.txt (line 23)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.*->-r requirements.txt (line 23)) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval->-r requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval->-r requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.1.105)\n",
            "Requirement already satisfied: pytorch-triton==3.1.0+cf34004b8a in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (3.1.0+cf34004b8a)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm-eval->-r requirements.txt (line 11)) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm-eval->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm-eval->-r requirements.txt (line 11)) (0.21.1)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-datalake-store<0.1,>=0.0.53 (from adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting azure-identity (from adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading azure_identity-1.22.0-py3-none-any.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.17.0 (from adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask->fsspec[full]->-r requirements.txt (line 22)) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask->fsspec[full]->-r requirements.txt (line 22)) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask->fsspec[full]->-r requirements.txt (line 22)) (8.7.0)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 22)) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 22)) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 22)) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 22)) (3.1.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 22)) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair->-r requirements.txt (line 18)) (3.0.2)\n",
            "Collecting stone<3.3.3,>=2 (from dropbox->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading stone-3.3.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 22)) (4.4.2)\n",
            "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gcsfs (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading gcsfs-2025.3.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.3.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 22)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 22)) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 22)) (2.19.0)\n",
            "Collecting oci>=2.43.1 (from ocifs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading oci-2.151.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (6.2.0)\n",
            "Requirement already satisfied: bokeh<3.8.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (3.7.2)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (3.8)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 22)) (3.0.4)\n",
            "Collecting bcrypt>=3.2 (from paramiko->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.11/dist-packages (from paramiko->fsspec[full]->-r requirements.txt (line 22)) (43.0.3)\n",
            "Collecting pynacl>=1.5 (from paramiko->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: cffi>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from pygit2->fsspec[full]->-r requirements.txt (line 22)) (1.17.1)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->-r requirements.txt (line 11))\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting lockfile>=0.10 (from python-daemon->luigi->-r requirements.txt (line 16))\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading aiobotocore-2.22.0-py3-none-any.whl.metadata (24 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs (from fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading s3fs-2025.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pyspnego (from smbprotocol->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading pyspnego-0.11.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.37.4,>=1.37.2 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading botocore-1.37.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 22)) (1.17.2)\n",
            "Collecting msal<2,>=1.16.0 (from azure-datalake-store<0.1,>=0.0.53->adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading msal-1.32.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.17.0->adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.8.0,>=3.5.0->panel->fsspec[full]->-r requirements.txt (line 22)) (1.3.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.8.0,>=3.5.0->panel->fsspec[full]->-r requirements.txt (line 22)) (11.2.1)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.8.0,>=3.5.0->panel->fsspec[full]->-r requirements.txt (line 22)) (2025.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.17.0->pygit2->fsspec[full]->-r requirements.txt (line 22)) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 9)) (5.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask->fsspec[full]->-r requirements.txt (line 22)) (3.21.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in /usr/local/lib/python3.11/dist-packages (from oci>=2.43.1->ocifs->fsspec[full]->-r requirements.txt (line 22)) (24.2.1)\n",
            "Requirement already satisfied: pytz>=2016.10 in /usr/local/lib/python3.11/dist-packages (from oci>=2.43.1->ocifs->fsspec[full]->-r requirements.txt (line 22)) (2025.2)\n",
            "Collecting circuitbreaker<3.0.0,>=1.3.1 (from oci>=2.43.1->ocifs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading circuitbreaker-2.1.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.11/dist-packages (from stone<3.3.3,>=2->dropbox->fsspec[full]->-r requirements.txt (line 22)) (3.11)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->adlfs->fsspec[full]->-r requirements.txt (line 22))\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel->fsspec[full]->-r requirements.txt (line 22)) (0.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (1.7.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel->fsspec[full]->-r requirements.txt (line 22)) (1.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (1.26.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs->fsspec[full]->-r requirements.txt (line 22)) (2.10.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->fsspec[full]->-r requirements.txt (line 22)) (3.2.2)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading viztracer-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datatrove-0.5.0-py3-none-any.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objprint-0.3.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading adlfs-2024.12.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dropbox-12.0.2-py3-none-any.whl (572 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.1/572.1 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gcsfs-2025.3.0-py2.py3-none-any.whl (36 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading libarchive_c-5.2-py3-none-any.whl (15 kB)\n",
            "Downloading ocifs-1.3.2-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_daemon-3.1.2-py3-none-any.whl (30 kB)\n",
            "Downloading s3fs-2025.3.0-py3-none-any.whl (30 kB)\n",
            "Downloading smbprotocol-1.15.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading aiobotocore-2.22.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading oci-2.151.0-py3-none-any.whl (30.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stone-3.3.1-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.3/162.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading azure_identity-1.22.0-py3-none-any.whl (185 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.5/185.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspnego-0.11.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.37.3-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading circuitbreaker-2.1.3-py3-none-any.whl (7.7 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading msal-1.32.3-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, rouge-score, luigi, dropboxdrivefs, fusepy, sqlitedict, word2number\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=dc2c0d5669490cf5231e570f1e502459de6a9995017be56195902fa1793a0cd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=f212b3d3ce2b7fcb4d833c0d2fe2831b3bc3c0a7809e2502c2e96cdb45c257c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "  Building wheel for luigi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for luigi: filename=luigi-3.6.0-py3-none-any.whl size=1093756 sha256=beab71f809531e09bb44ffbbcad5c8086cc1b9d5a71656b8adda5ee5a32408f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/3c/af6674483adf7af53c451451c24b1e330e00b6fe1cc70bb96a\n",
            "  Building wheel for dropboxdrivefs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dropboxdrivefs: filename=dropboxdrivefs-1.4.1-py3-none-any.whl size=8239 sha256=a936bfa2b2681df9a554d7aa68c06ee5b43a250c708a3f1f6926501b5ff64486\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/fd/ae/739b6fd4bbedc3c90dd265e6c4719ccd861cd7519fc49c1f06\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=403096a5ff1ec88849fadf42aba0cc6c9a23b46a55b548e0cd0b425932c39734\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/4a/86/fdda91f8b8ebb0a70e4181dc2423b1f70c3c2d3bd1158685b5\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=d25fc5b7ded26c9291f4ef40bf26bde2f456a33779fc15c2e849099603bbc419\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=b7831624b3af13979d2f9731332feda2e4e1ceb9620c3c6bc8abf9fd7f944dd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built antlr4-python3-runtime rouge-score luigi dropboxdrivefs fusepy sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, lockfile, libarchive-c, fusepy, circuitbreaker, antlr4-python3-runtime, xxhash, tenacity, tcolorpy, submitit, stone, python-daemon, pycryptodomex, pybind11, portalocker, pathvalidate, omegaconf, objprint, msgspec, mbstrdecoder, loguru, jsonlines, jmespath, isodate, fsspec, dill, colorama, bcrypt, aioitertools, viztracer, typepy, tqdm-multiprocess, tiktoken, sacrebleu, rouge-score, pynacl, multiprocess, luigi, dropbox, botocore, blobfile, azure-core, pyspnego, paramiko, dropboxdrivefs, datatrove, azure-storage-blob, aiobotocore, smbprotocol, s3fs, oci, msal, datasets, DataProperty, tabledata, ocifs, msal-extensions, evaluate, azure-datalake-store, pytablewriter, gcsfs, azure-identity, lm-eval, adlfs\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: gcsfs\n",
            "    Found existing installation: gcsfs 2025.3.2\n",
            "    Uninstalling gcsfs-2025.3.2:\n",
            "      Successfully uninstalled gcsfs-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.6.0.dev20241112+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.1.0 adlfs-2024.12.0 aiobotocore-2.22.0 aioitertools-0.12.0 antlr4-python3-runtime-4.9.3 azure-core-1.34.0 azure-datalake-store-0.0.53 azure-identity-1.22.0 azure-storage-blob-12.25.1 bcrypt-4.3.0 blobfile-3.0.0 botocore-1.37.3 circuitbreaker-2.1.3 colorama-0.4.6 datasets-3.6.0 datatrove-0.5.0 dill-0.3.8 dropbox-12.0.2 dropboxdrivefs-1.4.1 evaluate-0.4.3 fsspec-2025.3.0 fusepy-3.0.1 gcsfs-2025.3.0 isodate-0.7.2 jmespath-1.0.1 jsonlines-4.0.0 libarchive-c-5.2 lm-eval-0.4.8 lockfile-0.12.2 loguru-0.7.3 luigi-3.6.0 mbstrdecoder-1.1.4 msal-1.32.3 msal-extensions-1.3.1 msgspec-0.19.0 multiprocess-0.70.16 objprint-0.3.0 oci-2.151.0 ocifs-1.3.2 omegaconf-2.3.0 paramiko-3.5.1 pathvalidate-3.2.3 portalocker-3.1.1 pybind11-2.13.6 pycryptodomex-3.22.0 pynacl-1.5.0 pyspnego-0.11.2 pytablewriter-1.2.1 python-daemon-3.1.2 rouge-score-0.1.2 s3fs-2025.3.0 sacrebleu-2.5.1 smbprotocol-1.15.0 sqlitedict-2.1.0 stone-3.3.1 submitit-1.5.2 tabledata-1.3.4 tcolorpy-0.1.7 tenacity-8.5.0 tiktoken-0.9.0 tqdm-multiprocess-0.0.11 typepy-1.3.4 viztracer-1.0.3 word2number-1.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "7a5971122b8e4d5a8f1a022e4e8caaac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nBGKU15ZpLbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"My test prompt\""
      ],
      "metadata": {
        "id": "TmK_PkcnqFWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"hi\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "488y1eTJqybT",
        "outputId": "74f33f60-56cc-46c9-d307-ddd5df0e97af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mload_transformers\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(blt_model)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(tok_and_patcher)                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m source == \u001b[33m\"\u001b[0m\u001b[33mhub\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0mentropy_model = \u001b[1;4mLMTransformer.from_pretrained(entropy_repo)\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0mblt_model = ByteLatentTransformer.from_pretrained(blt_repo)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0mtok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_r \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer = tok_and_patcher.tokenizer_args.build()             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      blt_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     blt_repo = \u001b[33m'facebook/blt-1b'\u001b[0m      \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  entropy_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m entropy_repo = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       prompt = \u001b[33m'hi'\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       source = \u001b[33m'hub'\u001b[0m                  \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             arg_name = \u001b[33m'pretrained_model_name_or_path'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            arg_value = \u001b[33m'facebook/blt-entropy'\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 args = \u001b[1m(\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'bytelatent.transformer.LMTransformer'\u001b[0m\u001b[1m>\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[33m'facebook/blt-entropy'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[1m)\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m check_use_auth_token = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            has_token = \u001b[94mFalse\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            signature = \u001b[1m<\u001b[0m\u001b[1;95mSignature\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mcls: Type\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39m~T\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpretrained_model_name_or_path: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, *, force_download: bool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mresume_download: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mbool\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, proxies: \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mOptional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mDict\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, token: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, bool, \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mNoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, cache_dir: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path, NoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, local_files_only:\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mbool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, revision: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39m**model_kwargs\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -> ~T\u001b[0m\u001b[1m>\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m566\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m._hub_mixin_inject_config \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m model_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_kwargs[\u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m] = config                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0minstance = \u001b[96mcls\u001b[0m._from_pretrained(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_id=\u001b[96mstr\u001b[0m(model_id),                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0mcache_dir=cache_dir,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        config = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   config_file = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m pretrained_model_name_or_path = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰────────────────────────────────────────────────────────╯\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m789\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_from_pretrained\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0m**model_kwargs,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   \u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Load Pytorch pretrained weights and return the loaded model\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m789 \u001b[2m│   │   \u001b[0mmodel = \u001b[1;4;96mcls\u001b[0m\u001b[1;4m(**model_kwargs)\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m os.path.isdir(model_id):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m791 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading weights from local directory\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_file = os.path.join(model_id, constants.SAFETENSORS_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m─────────────────\u001b[0m\u001b[33m─╮\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     map_location = \u001b[33m'cpu'\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           strict = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────╯\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mLMTransformer.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \n",
            "\u001b[32m'args'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aM1LVyqUrTtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bO8ccwkSrTqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "!huggingface-cli login --token CCCCCCCC\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "id": "UVsymLJRrTnE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "a8a55521-0c24-414c-ef55-177b8bf1561a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f2c47acbb3bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mentropy_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-entropy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mblt_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mblt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtok_and_patcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/blt/setup/download_prepare_hf_data.py"
      ],
      "metadata": {
        "id": "53F-KOxtxfok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python download_blt_weights.py\n",
        "!python demo.py \"A BLT has\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdLPHUznrZuL",
        "outputId": "66a365a6-7b0a-49d2-8ddc-e8e70a2b84be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "Fetching 9 files: 100% 9/9 [00:00<00:00, 2339.99it/s]\n",
            "Loading BLT model: blt-1b\n",
            "[rank0]: \u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/blt/\u001b[0m\u001b[1;33mdemo.py\u001b[0m:\u001b[94m20\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0msetup_torch_distributed(distributed_args)                       \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mcheckpoint_path = os.path.join(\u001b[33m\"\u001b[0m\u001b[33mhf-weights\u001b[0m\u001b[33m\"\u001b[0m, model_name)            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading BLT model: \u001b[0m\u001b[33m{\u001b[0mmodel_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m20 \u001b[2m│   \u001b[0mmodel, tokenizer, train_cfg = \u001b[1;4mload_consolidated_model_and_tokenizer\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[1;2;4m│   │   \u001b[0m\u001b[1;4mcheckpoint_path,\u001b[0m                                                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[1;2;4m│   \u001b[0m\u001b[1;4m)\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(model, ByteLatentTransformer)                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m─────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m──────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  checkpoint_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m distributed_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       model_name = \u001b[33m'blt-1b'\u001b[0m                                         \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           prompt = \u001b[33m'A BLT has'\u001b[0m                                      \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰─────────────────────────────────────────────────────────────────────╯\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m403\u001b[0m in                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[92mload_consolidated_model_and_tokenizer\u001b[0m                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m400 \u001b[0m\u001b[2m│   │   │   \u001b[0msetup_torch_distributed(distributed_args)                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0mtrain_args_path = os.path.join(consolidated_path, \u001b[33m\"\u001b[0m\u001b[33mparams.json\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m│   \u001b[0mfs = get_fs(train_args_path)                                       \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m403 \u001b[2m│   \u001b[0mtrain_args = TrainArgs.model_validate_json(\u001b[1;4mfs.read_text(train_args\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m train_args.train_entropy_model:                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args = train_args.entropy_model                          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m consolidated_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[39mat \u001b[0m\u001b[94m0x7897e3a77590\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  init_distributed = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   train_args_path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m721\u001b[0m in \u001b[92mread_text\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 718 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mURL of file on this filesystems\u001b[0m                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 719 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mencoding, errors, newline: same as `open`.\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 720 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 721 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.open(                                               \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 722 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath,                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 723 \u001b[0m\u001b[2m│   │   │   \u001b[0mmode=\u001b[33m\"\u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\u001b[0m,                                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 724 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoding=encoding,                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m encoding = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   errors = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  newline = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[94m0x7897e3a77590\u001b[0m\u001b[1m>\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1298\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1295 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m k \u001b[95min\u001b[0m kwargs                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1296 \u001b[0m\u001b[2m│   │   │   \u001b[0m}                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1297 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m io.TextIOWrapper(                                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1298 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.open(                                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1299 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpath,                                             \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1300 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmode,                                             \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1301 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mblock_size=block_size,                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0x7897e3a77590\u001b[0m\u001b[1m>\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   text_kwargs = \u001b[1m{\u001b[0m\u001b[33m'encoding'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'errors'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'newline'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1310\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1307 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1309 \u001b[0m\u001b[2m│   │   │   \u001b[0mac = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mautocommit\u001b[0m\u001b[33m\"\u001b[0m, \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m._intrans)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1310 \u001b[2m│   │   │   \u001b[0mf = \u001b[96mself\u001b[0m._open(                                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1311 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath,                                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1312 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmode=mode,                                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1313 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mblock_size=block_size,                                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            ac = \u001b[94mTrue\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0x7897e3a77590\u001b[0m\u001b[1m>\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m201\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_mkdir \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m mode:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.makedirs(\u001b[96mself\u001b[0m._parent(path), exist_ok=\u001b[94mTrue\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mLocalFileOpener(path, mode, fs=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, **kwargs)\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mtouch\u001b[0m(\u001b[96mself\u001b[0m, path, truncate=\u001b[94mTrue\u001b[0m, **kwargs):                    \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m block_size = \u001b[94mNone\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     kwargs = \u001b[1m{\u001b[0m\u001b[33m'autocommit'\u001b[0m: \u001b[94mTrue\u001b[0m, \u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       mode = \u001b[33m'rb'\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[94m0x7897e3a77590\u001b[0m\u001b[1m>\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m365\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.autocommit = autocommit                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m363 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.compression = get_compression(path, compression)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.blocksize = io.DEFAULT_BUFFER_SIZE                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m365 \u001b[2m│   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._open()\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  autocommit = \u001b[94mTrue\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m compression = \u001b[94mNone\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0x7897e3a77590\u001b[0m\u001b[1m>\u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      kwargs = \u001b[1m{\u001b[0m\u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        mode = \u001b[33m'rb'\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0x7897e3a79930\u001b[0m\u001b[1m>\u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m370\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.autocommit \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.mode:                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = \u001b[1;4;96mopen\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.path, mode=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.mode)\u001b[0m               \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.compression:                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcompress = compr[\u001b[96mself\u001b[0m.compression]                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = compress(\u001b[96mself\u001b[0m.f, mode=\u001b[96mself\u001b[0m.mode)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        \u001b[94m0x7897e3a79930\u001b[0m\u001b[1m>\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "[rank0]: \u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \n",
            "[rank0]: \u001b[32m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m\n",
            "[rank0]:[W508 21:21:40.197628249 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "!huggingface-cli login --token XXXXXXXXXXXXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_oGnrzFtlhe",
        "outputId": "3394670b-1309-402f-8d32-ade3531bc47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, make sure you’re logged in:\n",
        "#!huggingface-cli login\n",
        "%cd /content/blt\n",
        "# Then run:\n",
        "!python -m bytelatent.hf load-transformers \\\n",
        "    --entropy-repo facebook/blt-entropy \\\n",
        "    --blt-repo     facebook/blt-1b \\\n",
        "    hub \\\n",
        "    --prompt      \"A BLT has\"\n"
      ],
      "metadata": {
        "id": "ofoFmVBHtl31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71ec2882-6140-42a7-df51-438fa013818b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mload_transformers\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(blt_model)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(tok_and_patcher)                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m source == \u001b[33m\"\u001b[0m\u001b[33mhub\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0mentropy_model = \u001b[1;4mLMTransformer.from_pretrained(entropy_repo)\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0mblt_model = ByteLatentTransformer.from_pretrained(blt_repo)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0mtok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_r \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer = tok_and_patcher.tokenizer_args.build()             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      blt_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     blt_repo = \u001b[33m'facebook/blt-1b'\u001b[0m      \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  entropy_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m entropy_repo = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       prompt = \u001b[33m'A BLT has'\u001b[0m            \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       source = \u001b[33m'hub'\u001b[0m                  \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             arg_name = \u001b[33m'pretrained_model_name_or_path'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            arg_value = \u001b[33m'facebook/blt-entropy'\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 args = \u001b[1m(\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'bytelatent.transformer.LMTransformer'\u001b[0m\u001b[1m>\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[33m'facebook/blt-entropy'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[1m)\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m check_use_auth_token = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            has_token = \u001b[94mFalse\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            signature = \u001b[1m<\u001b[0m\u001b[1;95mSignature\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mcls: Type\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39m~T\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpretrained_model_name_or_path: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, *, force_download: bool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mresume_download: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mbool\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, proxies: \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mOptional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mDict\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, token: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, bool, \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mNoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, cache_dir: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path, NoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, local_files_only:\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mbool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, revision: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39m**model_kwargs\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -> ~T\u001b[0m\u001b[1m>\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m566\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m._hub_mixin_inject_config \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m model_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_kwargs[\u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m] = config                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0minstance = \u001b[96mcls\u001b[0m._from_pretrained(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_id=\u001b[96mstr\u001b[0m(model_id),                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0mcache_dir=cache_dir,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        config = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   config_file = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m pretrained_model_name_or_path = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰────────────────────────────────────────────────────────╯\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m789\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_from_pretrained\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0m**model_kwargs,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   \u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Load Pytorch pretrained weights and return the loaded model\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m789 \u001b[2m│   │   \u001b[0mmodel = \u001b[1;4;96mcls\u001b[0m\u001b[1;4m(**model_kwargs)\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m os.path.isdir(model_id):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m791 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading weights from local directory\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_file = os.path.join(model_id, constants.SAFETENSORS_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m─────────────────\u001b[0m\u001b[33m─╮\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     map_location = \u001b[33m'cpu'\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           strict = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────╯\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mLMTransformer.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \n",
            "\u001b[32m'args'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo     = \"facebook/blt-1b\"\n",
        "\n",
        "# 1. Load the little language model (“entropy model”)\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "\n",
        "# 2. Load the byte-latent transformer\n",
        "blt_model     = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "\n",
        "# 3. Load & patch the tokenizer\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer       = tok_and_patcher.tokenizer_args.build()\n",
        "patcher         = tok_and_patcher.patcher_args.build()\n",
        "\n",
        "# 4. Run a simple generation\n",
        "inputs = tokenizer(\"A BLT has\", return_tensors=\"pt\")\n",
        "patched = patcher.apply_batch(inputs[\"input_ids\"])\n",
        "outputs = blt_model.generate(**patched)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "9kHNrF1EyMR1",
        "outputId": "1a292d11-7c9d-4e7b-8a76-36b8650e0b15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b0cd59bfa4d1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. Load the little language model (“entropy model”)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 2. Load the byte-latent transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This reads your downloaded weights + params.json,\n",
        "# writes out a `train_args.json` under output_dir/blt, and the entropy one as well.\n",
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    hf-weights/blt-1b      output_dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4dwMF7Ry583",
        "outputId": "9af1101c-384f-4576-b80e-2a4221e8882c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m95\u001b[0m in \u001b[92mconvert_to_transformers\u001b[0m                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mconvert_to_transformers\u001b[0m(blt_weights_dir: \u001b[96mstr\u001b[0m, output_dir: \u001b[96mstr\u001b[0m):    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m os.path.exists(output_dir):                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   \u001b[0mos.makedirs(output_dir, exist_ok=\u001b[94mTrue\u001b[0m)                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 95 \u001b[2m│   \u001b[0mmodel, tokenizer, train_cfg = \u001b[1;4mload_consolidated_model_and_tokenize\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   \u001b[0mblt_dir = os.path.join(output_dir, \u001b[33m\"\u001b[0m\u001b[33mblt\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   \u001b[0mentropy_dir = os.path.join(output_dir, \u001b[33m\"\u001b[0m\u001b[33mentropy\u001b[0m\u001b[33m\"\u001b[0m)                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   \u001b[0mmodel.save_pretrained(blt_dir, config={\u001b[33m\"\u001b[0m\u001b[33margs\u001b[0m\u001b[33m\"\u001b[0m: train_cfg.model.mod \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m blt_weights_dir = \u001b[33m'hf-weights/blt-1b'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      output_dir = \u001b[33m'output_dir'\u001b[0m        \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m403\u001b[0m in                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mload_consolidated_model_and_tokenizer\u001b[0m                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m400 \u001b[0m\u001b[2m│   │   │   \u001b[0msetup_torch_distributed(distributed_args)                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0mtrain_args_path = os.path.join(consolidated_path, \u001b[33m\"\u001b[0m\u001b[33mparams.json\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m│   \u001b[0mfs = get_fs(train_args_path)                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m403 \u001b[2m│   \u001b[0mtrain_args = TrainArgs.model_validate_json(\u001b[1;4mfs.read_text(train_args\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m train_args.train_entropy_model:                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args = train_args.entropy_model                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m consolidated_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[39mat \u001b[0m\u001b[94m0x78710008b510\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  init_distributed = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   train_args_path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m721\u001b[0m in \u001b[92mread_text\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 718 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mURL of file on this filesystems\u001b[0m                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 719 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mencoding, errors, newline: same as `open`.\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 720 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 721 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.open(                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 722 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath,                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 723 \u001b[0m\u001b[2m│   │   │   \u001b[0mmode=\u001b[33m\"\u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\u001b[0m,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 724 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoding=encoding,                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m encoding = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   errors = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  newline = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[94m0x78710008b510\u001b[0m\u001b[1m>\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1298\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1295 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m k \u001b[95min\u001b[0m kwargs                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1296 \u001b[0m\u001b[2m│   │   │   \u001b[0m}                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1297 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m io.TextIOWrapper(                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1298 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.open(                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1299 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpath,                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1300 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmode,                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1301 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mblock_size=block_size,                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0x78710008b510\u001b[0m\u001b[1m>\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   text_kwargs = \u001b[1m{\u001b[0m\u001b[33m'encoding'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'errors'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'newline'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1310\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1307 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1309 \u001b[0m\u001b[2m│   │   │   \u001b[0mac = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mautocommit\u001b[0m\u001b[33m\"\u001b[0m, \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m._intrans)          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1310 \u001b[2m│   │   │   \u001b[0mf = \u001b[96mself\u001b[0m._open(                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1311 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1312 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmode=mode,                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1313 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mblock_size=block_size,                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            ac = \u001b[94mTrue\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0x78710008b510\u001b[0m\u001b[1m>\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m201\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_mkdir \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m mode:                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.makedirs(\u001b[96mself\u001b[0m._parent(path), exist_ok=\u001b[94mTrue\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mLocalFileOpener(path, mode, fs=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, **kwargs)\u001b[0m          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mtouch\u001b[0m(\u001b[96mself\u001b[0m, path, truncate=\u001b[94mTrue\u001b[0m, **kwargs):                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m block_size = \u001b[94mNone\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     kwargs = \u001b[1m{\u001b[0m\u001b[33m'autocommit'\u001b[0m: \u001b[94mTrue\u001b[0m, \u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       mode = \u001b[33m'rb'\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[94m0x78710008b510\u001b[0m\u001b[1m>\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m365\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.autocommit = autocommit                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m363 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.compression = get_compression(path, compression)          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.blocksize = io.DEFAULT_BUFFER_SIZE                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m365 \u001b[2m│   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._open()\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  autocommit = \u001b[94mTrue\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m compression = \u001b[94mNone\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0x78710008b510\u001b[0m\u001b[1m>\u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      kwargs = \u001b[1m{\u001b[0m\u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        mode = \u001b[33m'rb'\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0x787100091270\u001b[0m\u001b[1m>\u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m370\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.autocommit \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.mode:                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = \u001b[1;4;96mopen\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.path, mode=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.mode)\u001b[0m               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.compression:                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcompress = compr[\u001b[96mself\u001b[0m.compression]                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = compress(\u001b[96mself\u001b[0m.f, mode=\u001b[96mself\u001b[0m.mode)          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        \u001b[94m0x787100091270\u001b[0m\u001b[1m>\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \n",
            "\u001b[32m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/facebook/blt-entropy hf-weights/blt-entropy\n",
        "!git clone https://huggingface.co/facebook/blt-1b       hf-weights/blt-1b\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMyapzwFzOs1",
        "outputId": "e9a04bbb-0ff8-4c11-a1ca-c2a3d3476334"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hf-weights/blt-entropy'...\n",
            "fatal: could not read Username for 'https://huggingface.co': No such device or address\n",
            "fatal: destination path 'hf-weights/blt-1b' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "# point at your cloned folder\n",
        "entropy_dir = \"hf-weights/blt-entropy\"\n",
        "blt_dir     = \"hf-weights/blt-1b\"\n",
        "\n",
        "entropy_model = LMTransformer.from_pretrained(\n",
        "    entropy_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "blt_model     = ByteLatentTransformer.from_pretrained(\n",
        "    blt_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "tokpatch = BltTokenizerAndPatcher.from_pretrained(blt_dir, local_files_only=True)\n",
        "tokenizer = tokpatch.tokenizer_args.build()\n",
        "patcher    = tokpatch.patcher_args.build()\n",
        "\n",
        "inputs  = tokenizer(\"A BLT has\", return_tensors=\"pt\")\n",
        "patched = patcher.apply_batch(inputs[\"input_ids\"])\n",
        "outputs = blt_model.generate(**patched)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "Qwsxjuoqzn2V",
        "outputId": "a9e4995b-5f8e-440c-99af-d1908d313c9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-55559a1fc189>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mblt_dir\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;34m\"hf-weights/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m entropy_model = LMTransformer.from_pretrained(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mentropy_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    hf-weights/blt-1b   output/blt\n",
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    hf-weights/blt-entropy output/entropy\n"
      ],
      "metadata": {
        "id": "vDS5UV8Ozs89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HUfBiwtDz3-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "from bytelatent.args import ModelArgs  # Import ModelArgs\n",
        "\n",
        "# point at your cloned folder\n",
        "entropy_dir = \"hf-weights/blt-entropy\"\n",
        "blt_dir = \"hf-weights/blt-1b\"\n",
        "\n",
        "# Create ModelArgs instance\n",
        "entropy_args = ModelArgs()\n",
        "\n",
        "entropy_model = LMTransformer.from_pretrained(\n",
        "    entropy_dir,\n",
        "    local_files_only=True,\n",
        "    args=entropy_args  # Pass args to from_pretrained\n",
        ")\n",
        "blt_model = ByteLatentTransformer.from_pretrained(\n",
        "    blt_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "tokpatch = BltTokenizerAndPatcher.from_pretrained(blt_dir, local_files_only=True)\n",
        "tokenizer = tokpatch.tokenizer_args.build()\n",
        "patcher = tokpatch.patcher_args.build()\n",
        "\n",
        "inputs = tokenizer(\"A BLT has\", return_tensors=\"pt\")\n",
        "patched = patcher.apply_batch(inputs[\"input_ids\"])\n",
        "outputs = blt_model.generate(**patched)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "dH_-IW_Sz6MF",
        "outputId": "bc19e6ff-7628-4a58-af36-b2be283e1da5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bytelatent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-426cac94935c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelArgs\u001b[0m  \u001b[0;31m# Import ModelArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bytelatent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "!mkdir -p output/blt output/entropy # Create output directories\n",
        "!python -m bytelatent.hf convert-to-transformers hf-weights/blt-1b output/blt\n",
        "!python -m bytelatent.hf convert-to-transformers hf-weights/blt-entropy output/entropy"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oW4cdP4X0CUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!mv /content/blt/hf-weights/blt-1b/entropy_model/params.json /content/blt/hf-weights/blt-entropy/"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2f2UodKZ0Zl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    --params-file /content/blt/hf-weights/blt-1b/entropy_model/params.json \\  # إضافة مسار الملف\n",
        "    hf-weights/blt-1b output/blt\n",
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    --params-file /content/blt/hf-weights/blt-1b/entropy_model/params.json \\  # إضافة مسار الملف\n",
        "    hf-weights/blt-entropy output/entropy"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "NTOgIP010eQ2",
        "outputId": "059a8ff9-1b99-4430-a1af-9076bd55493c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-9-7d8b37129493>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7d8b37129493>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    hf-weights/blt-1b output/blt\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    hf-weights/blt-1b output/blt\n",
        "!python -m bytelatent.hf convert-to-transformers \\\n",
        "    hf-weights/blt-entropy output/entropy"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD8U8_Iq0kbu",
        "outputId": "dc869c52-68ce-4a96-a28e-7b0050b161b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3: Error while finding module specification for 'bytelatent.hf' (ModuleNotFoundError: No module named 'bytelatent')\n",
            "/usr/bin/python3: Error while finding module specification for 'bytelatent.hf' (ModuleNotFoundError: No module named 'bytelatent')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup/download_tokenizer.py llama3 /content/blt/hf-weights/blt-1b --api_key CCCCCCCC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVe-l_Gt1Gc2",
        "outputId": "4cb7243c-447c-4388-97b3-7c49a4f9d24a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:933: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "tokenizer.model: 100% 2.18M/2.18M [00:00<00:00, 20.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo.py \"A BLT has\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW4U90bh1Ou2",
        "outputId": "c46b3d39-dbca-4308-f985-4fe72d60f809"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BLT model: blt-1b\n",
            "[rank0]: \u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/blt/\u001b[0m\u001b[1;33mdemo.py\u001b[0m:\u001b[94m20\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0msetup_torch_distributed(distributed_args)                       \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mcheckpoint_path = os.path.join(\u001b[33m\"\u001b[0m\u001b[33mhf-weights\u001b[0m\u001b[33m\"\u001b[0m, model_name)            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading BLT model: \u001b[0m\u001b[33m{\u001b[0mmodel_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m20 \u001b[2m│   \u001b[0mmodel, tokenizer, train_cfg = \u001b[1;4mload_consolidated_model_and_tokenizer\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[1;2;4m│   │   \u001b[0m\u001b[1;4mcheckpoint_path,\u001b[0m                                                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[1;2;4m│   \u001b[0m\u001b[1;4m)\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(model, ByteLatentTransformer)                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m─────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m──────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  checkpoint_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m distributed_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       model_name = \u001b[33m'blt-1b'\u001b[0m                                         \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           prompt = \u001b[33m'A BLT has'\u001b[0m                                      \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰─────────────────────────────────────────────────────────────────────╯\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m403\u001b[0m in                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[92mload_consolidated_model_and_tokenizer\u001b[0m                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m400 \u001b[0m\u001b[2m│   │   │   \u001b[0msetup_torch_distributed(distributed_args)                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0mtrain_args_path = os.path.join(consolidated_path, \u001b[33m\"\u001b[0m\u001b[33mparams.json\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m│   \u001b[0mfs = get_fs(train_args_path)                                       \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m403 \u001b[2m│   \u001b[0mtrain_args = TrainArgs.model_validate_json(\u001b[1;4mfs.read_text(train_args\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m train_args.train_entropy_model:                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args = train_args.entropy_model                          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m consolidated_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[39mat \u001b[0m\u001b[94m0x10d19ab41510\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  init_distributed = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   train_args_path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m721\u001b[0m in \u001b[92mread_text\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 718 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mURL of file on this filesystems\u001b[0m                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 719 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mencoding, errors, newline: same as `open`.\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 720 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 721 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.open(                                               \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 722 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath,                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 723 \u001b[0m\u001b[2m│   │   │   \u001b[0mmode=\u001b[33m\"\u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\u001b[0m,                                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 724 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoding=encoding,                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m encoding = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   errors = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  newline = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[94m0x10d19ab41510\u001b[0m\u001b[1m>\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1298\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1295 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m k \u001b[95min\u001b[0m kwargs                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1296 \u001b[0m\u001b[2m│   │   │   \u001b[0m}                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1297 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m io.TextIOWrapper(                                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1298 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.open(                                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1299 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpath,                                             \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1300 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmode,                                             \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1301 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mblock_size=block_size,                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0x10d19ab41510\u001b[0m\u001b[1m>\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   text_kwargs = \u001b[1m{\u001b[0m\u001b[33m'encoding'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'errors'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'newline'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1310\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1307 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1309 \u001b[0m\u001b[2m│   │   │   \u001b[0mac = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mautocommit\u001b[0m\u001b[33m\"\u001b[0m, \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m._intrans)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1310 \u001b[2m│   │   │   \u001b[0mf = \u001b[96mself\u001b[0m._open(                                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1311 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath,                                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1312 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmode=mode,                                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1313 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mblock_size=block_size,                                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            ac = \u001b[94mTrue\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0x10d19ab41510\u001b[0m\u001b[1m>\u001b[0m                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m201\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_mkdir \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m mode:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.makedirs(\u001b[96mself\u001b[0m._parent(path), exist_ok=\u001b[94mTrue\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mLocalFileOpener(path, mode, fs=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, **kwargs)\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mtouch\u001b[0m(\u001b[96mself\u001b[0m, path, truncate=\u001b[94mTrue\u001b[0m, **kwargs):                    \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m block_size = \u001b[94mNone\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     kwargs = \u001b[1m{\u001b[0m\u001b[33m'autocommit'\u001b[0m: \u001b[94mTrue\u001b[0m, \u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       mode = \u001b[33m'rb'\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[94m0x10d19ab41510\u001b[0m\u001b[1m>\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m365\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.autocommit = autocommit                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m363 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.compression = get_compression(path, compression)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.blocksize = io.DEFAULT_BUFFER_SIZE                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m365 \u001b[2m│   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._open()\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  autocommit = \u001b[94mTrue\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m compression = \u001b[94mNone\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0x10d19ab41510\u001b[0m\u001b[1m>\u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      kwargs = \u001b[1m{\u001b[0m\u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        mode = \u001b[33m'rb'\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0x10d1d5e3d900\u001b[0m\u001b[1m>\u001b[0m                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m370\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.autocommit \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.mode:                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = \u001b[1;4;96mopen\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.path, mode=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.mode)\u001b[0m               \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.compression:                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcompress = compr[\u001b[96mself\u001b[0m.compression]                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = compress(\u001b[96mself\u001b[0m.f, mode=\u001b[96mself\u001b[0m.mode)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        \u001b[94m0x10d1d5e3d900\u001b[0m\u001b[1m>\u001b[0m                                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "[rank0]: \u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \n",
            "[rank0]: \u001b[32m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m\n",
            "[rank0]:[W508 21:38:56.438464016 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python -m bytelatent.hf load-transformers \\\n",
        "    --entropy-repo facebook/blt-entropy \\\n",
        "    --blt-repo     facebook/blt-1b \\\n",
        "    hub \\\n",
        "    --prompt      \"My test prompt\"\n"
      ],
      "metadata": {
        "id": "MwqDjmdx1TPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python -m bytelatent.hf load-transformers \\\n",
        "    --entropy-repo facebook/blt-entropy \\\n",
        "    --blt-repo     facebook/blt-1b \\\n",
        "    hub \\\n",
        "    --prompt      \"My test prompt\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syTVbS2z2dMu",
        "outputId": "49f0adb4-16ff-422c-f193-cf167ec025e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mload_transformers\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(blt_model)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(tok_and_patcher)                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m source == \u001b[33m\"\u001b[0m\u001b[33mhub\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0mentropy_model = \u001b[1;4mLMTransformer.from_pretrained(entropy_repo)\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0mblt_model = ByteLatentTransformer.from_pretrained(blt_repo)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0mtok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_r \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer = tok_and_patcher.tokenizer_args.build()             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      blt_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     blt_repo = \u001b[33m'facebook/blt-1b'\u001b[0m      \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  entropy_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m entropy_repo = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       prompt = \u001b[33m'My test prompt'\u001b[0m       \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       source = \u001b[33m'hub'\u001b[0m                  \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             arg_name = \u001b[33m'pretrained_model_name_or_path'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            arg_value = \u001b[33m'facebook/blt-entropy'\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 args = \u001b[1m(\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'bytelatent.transformer.LMTransformer'\u001b[0m\u001b[1m>\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[33m'facebook/blt-entropy'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[1m)\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m check_use_auth_token = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            has_token = \u001b[94mFalse\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            signature = \u001b[1m<\u001b[0m\u001b[1;95mSignature\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mcls: Type\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39m~T\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpretrained_model_name_or_path: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, *, force_download: bool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mresume_download: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mbool\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, proxies: \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mOptional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mDict\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, token: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, bool, \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mNoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, cache_dir: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path, NoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, local_files_only:\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mbool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, revision: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39m**model_kwargs\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -> ~T\u001b[0m\u001b[1m>\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m566\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m._hub_mixin_inject_config \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m model_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_kwargs[\u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m] = config                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0minstance = \u001b[96mcls\u001b[0m._from_pretrained(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_id=\u001b[96mstr\u001b[0m(model_id),                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0mcache_dir=cache_dir,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        config = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   config_file = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m pretrained_model_name_or_path = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰────────────────────────────────────────────────────────╯\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m789\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_from_pretrained\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0m**model_kwargs,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   \u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Load Pytorch pretrained weights and return the loaded model\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m789 \u001b[2m│   │   \u001b[0mmodel = \u001b[1;4;96mcls\u001b[0m\u001b[1;4m(**model_kwargs)\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m os.path.isdir(model_id):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m791 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading weights from local directory\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_file = os.path.join(model_id, constants.SAFETENSORS_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m─────────────────\u001b[0m\u001b[33m─╮\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     map_location = \u001b[33m'cpu'\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           strict = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────╯\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mLMTransformer.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \n",
            "\u001b[32m'args'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo     = \"facebook/blt-1b\"\n",
        "\n",
        "# تحميل نموذج اللغة الصغير\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "\n",
        "# تحميل نموذج BLT\n",
        "blt_model     = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "\n",
        "# تحميل ومعالجة الـ tokenizer\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer       = tok_and_patcher.tokenizer_args.build()\n",
        "patcher         = tok_and_patcher.patcher_args.build()\n",
        "\n",
        "# توليد نص\n",
        "inputs  = tokenizer(\"required positional argument\", return_tensors=\"pt\")\n",
        "patched = patcher.apply_batch(inputs[\"input_ids\"])\n",
        "outputs = blt_model.generate(**patched)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "fKLfnysU2hgu",
        "outputId": "59a7861e-d40a-45f8-d406-ddf344b749f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1f885f0c8142>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# تحميل نموذج اللغة الصغير\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# تحميل نموذج BLT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# إنشاء مجلّد جديد للـ entropy داخل hf-weights\n",
        "!mkdir -p /content/blt/hf-weights/blt-entropy\n",
        "\n",
        "# نقل نسخة من train_args.json إليه\n",
        "!cp /content/blt/hf-weights/blt-1b/train_args.json /content/blt/hf-weights/blt-entropy/\n",
        "# ثم تأكد من أن أوزان نموذج entropy (pytorch_model.bin) موجودة هناك أيضًا\n"
      ],
      "metadata": {
        "id": "YitcNgk23XWH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_dir = \"/content/blt/hf-weights/blt-entropy\"\n",
        "blt_dir     = \"/content/blt/hf-weights/blt-1b\"\n",
        "\n",
        "# تحميل نموذج الـ entropy مع تمرير TrainArgs من JSON\n",
        "entropy_model = LMTransformer.from_pretrained(\n",
        "    entropy_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "# تحميل نموذج BLT byte-latent transformer\n",
        "blt_model = ByteLatentTransformer.from_pretrained(\n",
        "    blt_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "# تحميل ومعالجة الـ tokenizer\n",
        "tokpatch = BltTokenizerAndPatcher.from_pretrained(\n",
        "    blt_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "tokenizer = tokpatch.tokenizer_args.build()\n",
        "patcher    = tokpatch.patcher_args.build()\n",
        "\n",
        "# توليد نص تجريبي\n",
        "inputs  = tokenizer(\"هذا اختبار\", return_tensors=\"pt\")\n",
        "patched = patcher.apply_batch(inputs[\"input_ids\"])\n",
        "outputs = blt_model.generate(**patched)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "C4RihcCo3beW",
        "outputId": "a538af8b-179c-4731-92b5-782e3eb99078"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "config.json not found in /content/blt/hf-weights/blt-entropy\n",
            "WARNING:huggingface_hub.hub_mixin:config.json not found in /content/blt/hf-weights/blt-entropy\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1990b2751497>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# تحميل نموذج الـ entropy مع تمرير TrainArgs من JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m entropy_model = LMTransformer.from_pretrained(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mentropy_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/blt/hf-weights/blt-1b/params.json \\\n",
        "   /content/blt/hf-weights/blt-1b/train_args.json\n",
        "!mv /content/blt/hf-weights/blt-1b/entropy_model/params.json \\\n",
        "   /content/blt/hf-weights/blt-entropy/train_args.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF6w8HCP3jKu",
        "outputId": "3954b2fa-8557-4185-c966-b46142ae7508"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/blt/hf-weights/blt-1b/params.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/blt/hf-weights/blt-1b/config.json /content/blt/hf-weights/blt-1b/entropy_model"
      ],
      "metadata": {
        "id": "qt7jSJm84Ene"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp"
      ],
      "metadata": {
        "id": "ChiTiLLr4NQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Sj74LZBp4zpP",
        "outputId": "e11b5cac-0239-4604-e408-cc89dbd8362f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-074b9d338a11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mentropy_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-entropy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mblt_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mblt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtok_and_patcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0;31m#model = cls(**model_kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_prepare_hf_data.py\n",
        "\n",
        "\n",
        "\n",
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "import fsspec\n",
        "import requests\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "\n",
        "def run_command(command):\n",
        "    print(f\"Running: {command}\")\n",
        "    subprocess.run(command, shell=True, check=True)\n",
        "\n",
        "\n",
        "def download_dataset(repo_id, local_dir, allow_patterns):\n",
        "    print(f\"Downloading dataset from {repo_id}...\")\n",
        "    max_retries = 5\n",
        "    retry_delay = 10  # seconds\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            snapshot_download(\n",
        "                repo_id,\n",
        "                repo_type=\"dataset\",\n",
        "                local_dir=local_dir,\n",
        "                allow_patterns=allow_patterns,\n",
        "                resume_download=True,\n",
        "                max_workers=16,  # Don't hesitate to increase this number to lower the download time\n",
        "            )\n",
        "            break\n",
        "        except requests.exceptions.ReadTimeout:\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"Timeout occurred. Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "            else:\n",
        "                raise\n",
        "    print(f\"Dataset downloaded to {local_dir}\")\n",
        "\n",
        "\n",
        "def parquet_to_jsonl(\n",
        "    dataset, work_dir, src_dir, tgt_dir, ntasks=64, s3_profile: str | None = None\n",
        "):\n",
        "    from datatrove.executor import LocalPipelineExecutor\n",
        "    from datatrove.pipeline.readers import ParquetReader\n",
        "    from datatrove.pipeline.writers import JsonlWriter\n",
        "\n",
        "    if tgt_dir.startswith(\"s3//\"):\n",
        "        if s3_profile is None:\n",
        "            out_spec = tgt_dir\n",
        "        else:\n",
        "            out_spec = (tgt_dir, fsspec.filesystem(\"s3\", profile=s3_profile))\n",
        "    else:\n",
        "        out_spec = tgt_dir\n",
        "\n",
        "    pipeline_exec = LocalPipelineExecutor(\n",
        "        pipeline=[\n",
        "            ParquetReader(\n",
        "                src_dir,\n",
        "                file_progress=True,\n",
        "                doc_progress=True,\n",
        "                glob_pattern=\"**/*.parquet\",\n",
        "            ),\n",
        "            JsonlWriter(\n",
        "                out_spec,\n",
        "                output_filename=dataset + \".chunk.${rank}.jsonl\",\n",
        "                compression=None,\n",
        "            ),\n",
        "        ],\n",
        "        tasks=ntasks,\n",
        "        logging_dir=os.path.join(work_dir, \"datatrove\"),\n",
        "    )\n",
        "    pipeline_exec.run()\n",
        "\n",
        "\n",
        "def setup_terashuf(work_dir):\n",
        "    terashuf_dir = os.path.join(work_dir, \"terashuf\")\n",
        "    terashuf_executable = os.path.join(terashuf_dir, \"terashuf\")\n",
        "\n",
        "    if os.path.exists(terashuf_executable):\n",
        "        print(\"terashuf executable already exists. Skipping setup.\")\n",
        "        return terashuf_dir\n",
        "\n",
        "    print(\"Setting up terashuf...\")\n",
        "    run_command(f\"git clone https://github.com/alexandres/terashuf {terashuf_dir}\")\n",
        "    run_command(f\"make -C {terashuf_dir}\")\n",
        "    return terashuf_dir\n",
        "\n",
        "\n",
        "def main(dataset, memory, data_dir, seed=42, nchunks=32, s3_profile: str | None = None):\n",
        "    # Configuration\n",
        "    repo_id = {\n",
        "        \"fineweb_edu\": \"HuggingFaceFW/fineweb-edu\",\n",
        "        \"fineweb_edu_10bt\": \"HuggingFaceFW/fineweb-edu\",\n",
        "        \"dclm_baseline_1.0\": \"mlfoundations/dclm-baseline-1.0\",\n",
        "        \"dclm_baseline_1.0_10prct\": \"mlfoundations/dclm-baseline-1.0\",\n",
        "    }[dataset]\n",
        "    src_dir = f\"{data_dir}/{dataset}\"\n",
        "    out_dir = f\"{src_dir}_shuffled\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    work_dir = src_dir  # Directory of this Python file\n",
        "    prefix = f\"{dataset}.chunk.\"\n",
        "    orig_extension = {\n",
        "        \"fineweb_edu\": \".jsonl\",\n",
        "        \"fineweb_edu_10bt\": \".jsonl\",\n",
        "        \"dclm_baseline_1.0\": \".jsonl.zst\",\n",
        "        \"dclm_baseline_1.0_10prct\": \".jsonl.zst\",\n",
        "    }[dataset]\n",
        "    cat_command = {\n",
        "        \"fineweb_edu\": \"cat\",\n",
        "        \"fineweb_edu_10bt\": \"cat\",\n",
        "        \"dclm_baseline_1.0\": \"zstdcat\",\n",
        "        \"dclm_baseline_1.0_10prct\": \"zstdcat\",\n",
        "    }[dataset]\n",
        "    allow_patterns = {\n",
        "        \"fineweb_edu\": None,\n",
        "        \"fineweb_edu_10bt\": \"sample/10BT/*\",\n",
        "        \"dclm_baseline_1.0\": \"*.jsonl.zst\",\n",
        "        \"dclm_baseline_1.0_10prct\": \"global-shard_01_of_10/*.jsonl.zst\",\n",
        "    }[dataset]\n",
        "    suffix = \".jsonl\"\n",
        "    k_validation = 10000  # Number of lines to take from each chunk for validation\n",
        "\n",
        "    # Setup terashuf\n",
        "    terashuf_dir = setup_terashuf(work_dir)\n",
        "\n",
        "    # Download dataset\n",
        "    download_dataset(repo_id, src_dir, allow_patterns)\n",
        "\n",
        "    if \"fineweb\" in dataset:\n",
        "        parquet_to_jsonl(dataset, work_dir, src_dir, src_dir)\n",
        "\n",
        "    # Set up environment variables\n",
        "    os.environ[\"MEMORY\"] = f\"{memory}\"\n",
        "    os.environ[\"SEED\"] = f\"{seed}\"\n",
        "\n",
        "    # Run the original shuffling and splitting command\n",
        "    terashuf_executable = os.path.join(terashuf_dir, \"terashuf\")\n",
        "    run_command(\n",
        "        f\"ulimit -n 100000 && \"\n",
        "        f\"find {src_dir} -type f -name '*{orig_extension}' -print0 | xargs -0 {cat_command} | {terashuf_executable} | \"\n",
        "        f\"split -n r/{nchunks} -d --suffix-length 2 --additional-suffix {suffix} - {out_dir}/{prefix}\"\n",
        "        \"; trap 'echo \\\"Caught signal 13, exiting with code 1\\\"; exit 1' SIGPIPE;\"\n",
        "    )\n",
        "\n",
        "    # Create validation set and remove lines from chunks\n",
        "    validation_file = f\"{out_dir}/{dataset}.val{suffix}\"\n",
        "    for i in range(nchunks):\n",
        "        chunk_file = f\"{out_dir}/{prefix}{i:02d}{suffix}\"\n",
        "        run_command(f\"head -n {k_validation} {chunk_file} >> {validation_file}\")\n",
        "        run_command(f\"sed -i '1,{k_validation}d' {chunk_file}\")\n",
        "\n",
        "    print(\"All tasks completed successfully!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"dataset\", type=str)\n",
        "    parser.add_argument(\"memory\", type=float, default=8)\n",
        "    parser.add_argument(\"--data_dir\", type=str, default=\"data\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "    parser.add_argument(\"--nchunks\", type=int, default=1)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    main(args.dataset, args.memory, args.data_dir, args.seed, args.nchunks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "T5DHhVPq5gVY",
        "outputId": "33c8aeea-c8fe-4eb9-cfa8-25b282b3c93b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'download_prepare_hf_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7892297e912a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownload_prepare_hf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'download_prepare_hf_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PretrainedConfig\n",
        "\n",
        "# أنشئ config من dict\n",
        "cfg = PretrainedConfig.from_dict({\n",
        "    \"model_type\": \"bytelatent-lm\",\n",
        "    \"dim\": 512,\n",
        "    \"n_layers\": 8,\n",
        "    \"n_heads\": 12,\n",
        "    /* ... */\n",
        "})\n",
        "# ثم احفظه\n",
        "cfg.save_pretrained(\"/content/blt/hf-weights/blt-entropy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "MJGGR-Wi5g3X",
        "outputId": "f4c4eb30-b48b-4086-c2e4-9cc98b370274"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-19-c1d4bc30b9b4>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-c1d4bc30b9b4>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    /* ... */\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PretrainedConfig\n",
        "\n",
        "# أنشئ قاموس الإعدادات بدون تعليقات C-style\n",
        "cfg_dict = {\n",
        "    \"model_type\":   \"bytelatent-lm\",\n",
        "    \"dim\":          512,\n",
        "    \"n_layers\":     8,\n",
        "    \"n_heads\":      12,\n",
        "    # يمكنك إضافة باقي المفاتيح المطلوبة هنا:\n",
        "    # \"hidden_size\": 768,\n",
        "    # \"vocab_size\":  260,\n",
        "    # …\n",
        "}\n",
        "\n",
        "# قم بإنشاء الـ config من القاموس\n",
        "cfg = PretrainedConfig.from_dict(cfg_dict)\n",
        "\n",
        "# احفظ config.json في المسار المطلوب\n",
        "cfg.save_pretrained(\"/content/blt/hf-weights/blt-entropy\")\n"
      ],
      "metadata": {
        "id": "QJeSwmee6fEX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_dir = \"/content/blt/hf-weights/blt-entropy\"\n",
        "blt_dir     = \"/content/blt/hf-weights/blt-1b\"\n",
        "\n",
        "entropy_model = LMTransformer.from_pretrained(\n",
        "    entropy_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "blt_model = ByteLatentTransformer.from_pretrained(\n",
        "    blt_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "tokpatch  = BltTokenizerAndPatcher.from_pretrained(\n",
        "    blt_dir,\n",
        "    local_files_only=True\n",
        ")\n",
        "tokenizer = tokpatch.tokenizer_args.build()\n",
        "patcher   = tokpatch.patcher_args.build()\n",
        "\n",
        "inputs  = tokenizer(\"هذا اختبار\", return_tensors=\"pt\")\n",
        "patched = patcher.apply_batch(inputs[\"input_ids\"])\n",
        "outputs = blt_model.generate(**patched)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Ai9cK2vM6fav",
        "outputId": "1d42cc12-7e7c-4282-94ef-39122a668173"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e7c638b0c9fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mblt_dir\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/blt/hf-weights/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m entropy_model = LMTransformer.from_pretrained(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mentropy_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "# المسار إلى مجلّد الـ entropy\n",
        "entropy_dir = \"/content/blt/hf-weights/blt-entropy\"\n",
        "\n",
        "#  تحميل النموذج مع الاعتماد على الملفات المحلية فقط\n",
        "entropy_model = LMTransformer.from_pretrained(\n",
        "    entropy_dir,\n",
        "    local_files_only=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "o9BmYMEz6qMe",
        "outputId": "21f74d51-1636-4081-ae6e-d8060c91bf94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-eac3408a68fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  تحميل النموذج مع الاعتماد على الملفات المحلية فقط\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m entropy_model = LMTransformer.from_pretrained(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mentropy_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMTransformerArgs(BaseTransformerArgs):\n",
        "    seed: int = 42\n",
        "    vocab_size: int = -1\n",
        "    weight_tying: bool = False\n",
        "    sliding_window: int | None = None\n",
        "\n",
        "class LMTransformer(BaseTransformer, PyTorchModelHubMixin, ...):\n",
        "    def __init__(self, *, args: LMTransformerArgs):\n",
        "        super().__init__(args)\n",
        "        ...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "XJN88YeW65mP",
        "outputId": "3c772af2-f16b-4c66-da31-72a73e55c78f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'BaseTransformerArgs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0545cbcd68cd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLMTransformerArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseTransformerArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mweight_tying\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msliding_window\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BaseTransformerArgs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# تحميل كامل إعدادات التدريب\n",
        "train_args = json.load(open(\"hf-weights/blt-entropy/train_args.json\"))\n",
        "\n",
        "# استخرج معطيات الـ entropy model\n",
        "e = train_args[\"entropy_model\"]\n",
        "\n",
        "cfg = {\n",
        "  \"args\": {\n",
        "    \"seed\":               train_args[\"seed\"],\n",
        "    \"vocab_size\":         e[\"vocab_size\"],\n",
        "    \"weight_tying\":       False,\n",
        "    \"sliding_window\":     None,\n",
        "    \"dim\":                e[\"dim\"],\n",
        "    \"n_layers\":           e[\"n_layers\"],\n",
        "    \"n_heads\":            e[\"n_heads\"],\n",
        "    \"norm_eps\":           e[\"norm_eps\"],\n",
        "    \"attn_impl\":          e[\"attn_impl\"],\n",
        "    \"attn_bias_type\":     e[\"attn_bias_type\"],\n",
        "    \"eos_id\":             e[\"eos_id\"],\n",
        "  }\n",
        "}\n",
        "\n",
        "with open(\"hf-weights/blt-entropy/config.json\", \"w\") as f:\n",
        "    json.dump(cfg, f, indent=2)\n"
      ],
      "metadata": {
        "id": "fSgSBCCe7Ma3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "\n",
        "entropy_model = LMTransformer.from_pretrained(\n",
        "    \"/content/blt/hf-weights/blt-1b/entropy_model\",\n",
        "    local_files_only=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iedsJKXZ7XBH",
        "outputId": "0209bd63-ec8e-4707-9d72-e5ccffddb183"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "82 validation errors for LMTransformerArgs\nalpha_depth\n  Extra inputs are not permitted [type=extra_forbidden, input_value='disabled', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\narchitecture\n  Extra inputs are not permitted [type=extra_forbidden, input_value='vanilla', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nattn_to_keep\n  Extra inputs are not permitted [type=extra_forbidden, input_value='all', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nconv_kernel_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_all_layers_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_all_layers_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_init_by_pooling\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_k\n  Extra inputs are not permitted [type=extra_forbidden, input_value=2, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_nheads\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_use_flex_attention\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_window_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_window_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncustom_bwd\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=2048, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_local_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1024, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_local_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1024, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_patch_emb\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_token\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_token_emb\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndownsampling_by_pooling\n  Extra inputs are not permitted [type=extra_forbidden, input_value='max', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndropout\n  Extra inputs are not permitted [type=extra_forbidden, input_value=0.0, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_enable_byte_group_hash\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_enable_byte_ngrams\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_hash_byte_group_nb_functions\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_hash_byte_group_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[3, 4, 5, 6, 7, 8], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_hash_byte_group_vocab\n  Extra inputs are not permitted [type=extra_forbidden, input_value=500002, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_lm_loss\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_ngram_table_dir\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_ngram_to_size_str\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_preds_low_entropy_toks\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_preds_random_toks\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nentropy_model_checkpoint_dir\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nentropy_model_is_ngram_model\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nfull_logging_n_layers\n  Extra inputs are not permitted [type=extra_forbidden, input_value=4, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nfuse_sequence_parallel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nglobal_local_decoder_residual_layer\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ninit_use_depth\n  Extra inputs are not permitted [type=extra_forbidden, input_value='current', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ninit_use_gaussian\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nlayer_ckpt\n  Extra inputs are not permitted [type=extra_forbidden, input_value='none', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nlocal_attention_window_len\n  Extra inputs are not permitted [type=extra_forbidden, input_value=512, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nlog_patch_lengths\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nloss_parallel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmax_encoder_seq_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=24576, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmax_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=256, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmax_patch_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmonotonicity\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_heads_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_heads_local_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_heads_local_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_kv_heads_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_layers_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=25, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_layers_local_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=9, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_layers_local_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nngram_vocab_sizes\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nnon_linearity\n  Extra inputs are not permitted [type=extra_forbidden, input_value='swiglu', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nnorm_affine\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nnorm_type\n  Extra inputs are not permitted [type=extra_forbidden, input_value='rmsnorm', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\noutput_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=-1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npad_to_max_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatch_in_forward\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatch_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=4.5, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_batch_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_device\n  Extra inputs are not permitted [type=extra_forbidden, input_value='cuda', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_mode\n  Extra inputs are not permitted [type=extra_forbidden, input_value='entropy', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_threshold\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1.335442066192627, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_threshold_add\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_thresholds_str\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npm_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npre_norm\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nrecompute_attn\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nrecompute_fc1_out\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nrecompute_fc3_out\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nsequence_parallel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nshare_encoder_decoder_emb\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ntie_local_encoder_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ntie_local_encoder_decoder_logits\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ntokenize_with_bpe_delimiter\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nuse_fsdp\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nuse_local_encoder_transformer\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nuse_rope\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ea234ba550f9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m entropy_model = LMTransformer.from_pretrained(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"/content/blt/hf-weights/blt-1b/entropy_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m                     \u001b[0mexpected_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hub_mixin_init_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mexpected_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;31m# Populate model_kwargs from config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_decode_arg\u001b[0;34m(cls, expected_type, value)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hub_mixin_coders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Otherwise => don't decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/blt/bytelatent/transformer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     74\u001b[0m         LMTransformerArgs: (\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLMTransformerArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     },\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 82 validation errors for LMTransformerArgs\nalpha_depth\n  Extra inputs are not permitted [type=extra_forbidden, input_value='disabled', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\narchitecture\n  Extra inputs are not permitted [type=extra_forbidden, input_value='vanilla', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nattn_to_keep\n  Extra inputs are not permitted [type=extra_forbidden, input_value='all', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nconv_kernel_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_all_layers_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_all_layers_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_init_by_pooling\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_k\n  Extra inputs are not permitted [type=extra_forbidden, input_value=2, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_nheads\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_use_flex_attention\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_window_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncross_attn_window_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ncustom_bwd\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=2048, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_local_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1024, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_local_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1024, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_patch_emb\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_token\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndim_token_emb\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndownsampling_by_pooling\n  Extra inputs are not permitted [type=extra_forbidden, input_value='max', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ndropout\n  Extra inputs are not permitted [type=extra_forbidden, input_value=0.0, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_enable_byte_group_hash\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_enable_byte_ngrams\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_hash_byte_group_nb_functions\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_hash_byte_group_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=[3, 4, 5, 6, 7, 8], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_hash_byte_group_vocab\n  Extra inputs are not permitted [type=extra_forbidden, input_value=500002, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_lm_loss\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_ngram_table_dir\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_ngram_to_size_str\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_preds_low_entropy_toks\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nencoder_preds_random_toks\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nentropy_model_checkpoint_dir\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nentropy_model_is_ngram_model\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nfull_logging_n_layers\n  Extra inputs are not permitted [type=extra_forbidden, input_value=4, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nfuse_sequence_parallel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nglobal_local_decoder_residual_layer\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ninit_use_depth\n  Extra inputs are not permitted [type=extra_forbidden, input_value='current', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ninit_use_gaussian\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nlayer_ckpt\n  Extra inputs are not permitted [type=extra_forbidden, input_value='none', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nlocal_attention_window_len\n  Extra inputs are not permitted [type=extra_forbidden, input_value=512, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nlog_patch_lengths\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nloss_parallel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmax_encoder_seq_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=24576, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmax_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=256, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmax_patch_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nmonotonicity\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_heads_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_heads_local_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_heads_local_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=16, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_kv_heads_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_layers_global\n  Extra inputs are not permitted [type=extra_forbidden, input_value=25, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_layers_local_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=9, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nn_layers_local_encoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nngram_vocab_sizes\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nnon_linearity\n  Extra inputs are not permitted [type=extra_forbidden, input_value='swiglu', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nnorm_affine\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nnorm_type\n  Extra inputs are not permitted [type=extra_forbidden, input_value='rmsnorm', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\noutput_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=-1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npad_to_max_length\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatch_in_forward\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatch_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=4.5, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_batch_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_device\n  Extra inputs are not permitted [type=extra_forbidden, input_value='cuda', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_mode\n  Extra inputs are not permitted [type=extra_forbidden, input_value='entropy', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_threshold\n  Extra inputs are not permitted [type=extra_forbidden, input_value=1.335442066192627, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_threshold_add\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npatching_thresholds_str\n  Extra inputs are not permitted [type=extra_forbidden, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npm_size\n  Extra inputs are not permitted [type=extra_forbidden, input_value=0, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\npre_norm\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nrecompute_attn\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nrecompute_fc1_out\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nrecompute_fc3_out\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nsequence_parallel\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nshare_encoder_decoder_emb\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ntie_local_encoder_decoder\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ntie_local_encoder_decoder_logits\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\ntokenize_with_bpe_delimiter\n  Extra inputs are not permitted [type=extra_forbidden, input_value=False, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nuse_fsdp\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nuse_local_encoder_transformer\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nuse_rope\n  Extra inputs are not permitted [type=extra_forbidden, input_value=True, input_type=bool]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "import torch\n",
        "import transformers\n",
        "blt_model = ByteLatentTransformer.from_pretrained(\n",
        "    \"/content/blt/hf-weights/blt-1b\",\n",
        "    local_files_only=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb3upt-N7XR3",
        "outputId": "e187bee5-aeca-4cd6-c74c-35548fba3ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"My test prompt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8a_qPSM7mWo",
        "outputId": "07670ea0-a4b2-4a05-87ef-0b11b736f762"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mload_transformers\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(blt_model)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(tok_and_patcher)                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m source == \u001b[33m\"\u001b[0m\u001b[33mhub\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0mentropy_model = \u001b[1;4mLMTransformer.from_pretrained(entropy_repo)\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0mblt_model = ByteLatentTransformer.from_pretrained(blt_repo)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0mtok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_r \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer = tok_and_patcher.tokenizer_args.build()             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      blt_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     blt_repo = \u001b[33m'facebook/blt-1b'\u001b[0m      \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  entropy_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m entropy_repo = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       prompt = \u001b[33m'My test prompt'\u001b[0m       \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       source = \u001b[33m'hub'\u001b[0m                  \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             arg_name = \u001b[33m'pretrained_model_name_or_path'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            arg_value = \u001b[33m'facebook/blt-entropy'\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 args = \u001b[1m(\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'bytelatent.transformer.LMTransformer'\u001b[0m\u001b[1m>\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[33m'facebook/blt-entropy'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[1m)\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m check_use_auth_token = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            has_token = \u001b[94mFalse\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            signature = \u001b[1m<\u001b[0m\u001b[1;95mSignature\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mcls: Type\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39m~T\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpretrained_model_name_or_path: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, *, force_download: bool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mresume_download: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mbool\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, proxies: \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mOptional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mDict\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, token: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, bool, \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mNoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, cache_dir: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path, NoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, local_files_only:\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mbool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, revision: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39m**model_kwargs\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -> ~T\u001b[0m\u001b[1m>\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m566\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m._hub_mixin_inject_config \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m model_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_kwargs[\u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m] = config                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0minstance = \u001b[96mcls\u001b[0m._from_pretrained(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_id=\u001b[96mstr\u001b[0m(model_id),                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0mcache_dir=cache_dir,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        config = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   config_file = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m pretrained_model_name_or_path = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰────────────────────────────────────────────────────────╯\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m789\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_from_pretrained\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0m**model_kwargs,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   \u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Load Pytorch pretrained weights and return the loaded model\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m789 \u001b[2m│   │   \u001b[0mmodel = \u001b[1;4;96mcls\u001b[0m\u001b[1;4m(**model_kwargs)\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m os.path.isdir(model_id):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m791 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading weights from local directory\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_file = os.path.join(model_id, constants.SAFETENSORS_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m─────────────────\u001b[0m\u001b[33m─╮\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     map_location = \u001b[33m'cpu'\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           strict = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────╯\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mLMTransformer.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \n",
            "\u001b[32m'args'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "C8UoZnlR8Fj_",
        "outputId": "4457bf27-6c09-4652-8d19-8afd3c48a64c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-074b9d338a11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mentropy_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-entropy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mblt_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mblt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtok_and_patcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "source": [
        "#!pip install transformers  # Install the \"transformers\" package\n",
        "%cd /content/blt\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "import torch\n",
        "#import transformer # No need to import \"transformer\" if you meant \"transformers\"\n",
        "from transformers import AutoModelForCausalLM # Import AutoModelForCausalLM for loading causal language models\n",
        "\n",
        "blt_model = ByteLatentTransformer.from_pretrained(\n",
        "    \"/content/blt/hf-weights/blt-1b\",\n",
        "    local_files_only=True,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "S9_46z3Q9Lbw",
        "outputId": "83a25c6d-c2db-4ddf-dd7d-c805f444de68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ByteLatentTransformer.__init__() got an unexpected keyword argument 'device_map'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c1dd20d4b18d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m \u001b[0;31m# Import AutoModelForCausalLM for loading causal language models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m blt_model = ByteLatentTransformer.from_pretrained(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"/content/blt/hf-weights/blt-1b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ByteLatentTransformer.__init__() got an unexpected keyword argument 'device_map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pvhI-Oh_Vep",
        "outputId": "b1e213d4-8a3a-4698-ef3b-2b4f814ab381"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers@ git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148 (from -r /content/1.txt (line 279))\n",
            "  Using cached xformers-0.0.29+de742ec.d20250508-cp311-cp311-linux_x86_64.whl\n",
            "Collecting absl-py==2.1.0 (from -r /content/1.txt (line 1))\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting accelerate==1.0.1 (from -r /content/1.txt (line 2))\n",
            "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: adlfs==2024.12.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 3)) (2024.12.0)\n",
            "Collecting aiobotocore==2.16.1 (from -r /content/1.txt (line 4))\n",
            "  Downloading aiobotocore-2.16.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting aiohappyeyeballs==2.4.3 (from -r /content/1.txt (line 5))\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiohttp==3.10.10 (from -r /content/1.txt (line 6))\n",
            "  Downloading aiohttp-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: aioitertools==0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 7)) (0.12.0)\n",
            "Collecting aiosignal==1.3.1 (from -r /content/1.txt (line 8))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: altair==5.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 11)) (4.9.3)\n",
            "Collecting anyio==4.8.0 (from -r /content/1.txt (line 12))\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 13)) (23.1.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 14)) (21.2.0)\n",
            "Collecting arrow==1.3.0 (from -r /content/1.txt (line 15))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting asttokens==3.0.0 (from -r /content/1.txt (line 16))\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting async-lru==2.0.4 (from -r /content/1.txt (line 17))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting async-timeout==4.0.3 (from -r /content/1.txt (line 18))\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting attrs==24.2.0 (from -r /content/1.txt (line 19))\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core==1.32.0 (from -r /content/1.txt (line 20))\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: azure-datalake-store==0.0.53 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 21)) (0.0.53)\n",
            "Collecting azure-identity==1.19.0 (from -r /content/1.txt (line 22))\n",
            "  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob==12.24.0 (from -r /content/1.txt (line 23))\n",
            "  Downloading azure_storage_blob-12.24.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: babel==2.17.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 24)) (2.17.0)\n",
            "Collecting bcrypt==4.2.1 (from -r /content/1.txt (line 25))\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting beautifulsoup4==4.13.3 (from -r /content/1.txt (line 26))\n",
            "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting black==24.8.0 (from -r /content/1.txt (line 27))\n",
            "  Downloading black-24.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bleach==6.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 28)) (6.2.0)\n",
            "Requirement already satisfied: blobfile==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 29)) (3.0.0)\n",
            "Collecting bokeh==3.6.2 (from -r /content/1.txt (line 30))\n",
            "  Downloading bokeh-3.6.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting botocore==1.35.88 (from -r /content/1.txt (line 31))\n",
            "  Downloading botocore-1.35.88-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting cachetools==5.5.0 (from -r /content/1.txt (line 32))\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting certifi==2024.8.30 (from -r /content/1.txt (line 33))\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: cffi==1.17.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 34)) (1.17.1)\n",
            "Requirement already satisfied: chardet==5.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 35)) (5.2.0)\n",
            "Collecting charset-normalizer==3.4.0 (from -r /content/1.txt (line 36))\n",
            "  Downloading charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Collecting circuitbreaker==2.0.0 (from -r /content/1.txt (line 37))\n",
            "  Downloading circuitbreaker-2.0.0-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting click==8.1.7 (from -r /content/1.txt (line 38))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cloudpickle==3.1.0 (from -r /content/1.txt (line 39))\n",
            "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 40)) (0.4.6)\n",
            "Collecting comm==0.2.2 (from -r /content/1.txt (line 41))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy==1.3.1 (from -r /content/1.txt (line 42))\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cryptography==44.0.0 (from -r /content/1.txt (line 43))\n",
            "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dask==2024.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 44)) (2024.12.1)\n",
            "Collecting DataProperty==1.0.1 (from -r /content/1.txt (line 45))\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets==3.1.0 (from -r /content/1.txt (line 46))\n",
            "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting datatrove==0.4.0 (from -r /content/1.txt (line 47))\n",
            "  Downloading datatrove-0.4.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting debugpy==1.8.9 (from -r /content/1.txt (line 48))\n",
            "  Downloading debugpy-1.8.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting decorator==5.1.1 (from -r /content/1.txt (line 49))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 50)) (0.7.1)\n",
            "Requirement already satisfied: dill==0.3.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 51)) (0.3.8)\n",
            "Requirement already satisfied: distributed==2024.12.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 52)) (2024.12.1)\n",
            "Requirement already satisfied: docker-pycreds==0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 53)) (0.4.0)\n",
            "Requirement already satisfied: dropbox==12.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 54)) (12.0.2)\n",
            "Requirement already satisfied: dropboxdrivefs==1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 55)) (1.4.1)\n",
            "Requirement already satisfied: evaluate==0.4.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 56)) (0.4.3)\n",
            "Collecting exceptiongroup==1.2.2 (from -r /content/1.txt (line 57))\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting executing==2.1.0 (from -r /content/1.txt (line 58))\n",
            "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: fastjsonschema==2.21.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 59)) (2.21.1)\n",
            "Collecting filelock==3.16.1 (from -r /content/1.txt (line 60))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fqdn==1.5.1 (from -r /content/1.txt (line 61))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting frozenlist==1.5.0 (from -r /content/1.txt (line 62))\n",
            "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fsspec==2024.9.0 (from -r /content/1.txt (line 63))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fusepy==3.0.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 64)) (3.0.1)\n",
            "Collecting gcsfs==2024.9.0.post1 (from -r /content/1.txt (line 65))\n",
            "  Downloading gcsfs-2024.9.0.post1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting gitdb==4.0.11 (from -r /content/1.txt (line 66))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting GitPython==3.1.43 (from -r /content/1.txt (line 67))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting google-api-core==2.24.0 (from -r /content/1.txt (line 68))\n",
            "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-auth==2.37.0 (from -r /content/1.txt (line 69))\n",
            "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting google-auth-oauthlib==1.2.1 (from -r /content/1.txt (line 70))\n",
            "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-cloud-core==2.4.1 (from -r /content/1.txt (line 71))\n",
            "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-cloud-storage==2.19.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 72)) (2.19.0)\n",
            "Collecting google-crc32c==1.6.0 (from -r /content/1.txt (line 73))\n",
            "  Downloading google_crc32c-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: google-resumable-media==2.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 74)) (2.7.2)\n",
            "Collecting googleapis-common-protos==1.66.0 (from -r /content/1.txt (line 75))\n",
            "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting h11==0.14.0 (from -r /content/1.txt (line 76))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httpcore==1.0.7 (from -r /content/1.txt (line 77))\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 78)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub==0.30.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 79)) (0.30.2)\n",
            "Collecting humanize==4.11.0 (from -r /content/1.txt (line 80))\n",
            "  Downloading humanize-4.11.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 81)) (3.10)\n",
            "Collecting importlib_metadata==8.5.0 (from -r /content/1.txt (line 82))\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting iniconfig==2.0.0 (from -r /content/1.txt (line 83))\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ipykernel==6.29.5 (from -r /content/1.txt (line 84))\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipython==8.30.0 (from -r /content/1.txt (line 85))\n",
            "  Downloading ipython-8.30.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: isodate==0.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 86)) (0.7.2)\n",
            "Collecting isoduration==20.11.0 (from -r /content/1.txt (line 87))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting isort==6.0.0 (from -r /content/1.txt (line 88))\n",
            "  Downloading isort-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting jedi==0.19.2 (from -r /content/1.txt (line 89))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r /content/1.txt (line 90))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jmespath==1.0.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 91)) (1.0.1)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 92)) (1.4.2)\n",
            "Collecting json5==0.10.0 (from -r /content/1.txt (line 93))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonlines==4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 94)) (4.0.0)\n",
            "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 95)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema==4.23.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 96)) (4.23.0)\n",
            "Collecting jsonschema-specifications==2024.10.1 (from -r /content/1.txt (line 97))\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting jupyter-events==0.12.0 (from -r /content/1.txt (line 98))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-lsp==2.2.5 (from -r /content/1.txt (line 99))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter_client==8.6.3 (from -r /content/1.txt (line 100))\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 101)) (5.7.2)\n",
            "Collecting jupyter_server==2.15.0 (from -r /content/1.txt (line 102))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyter_server_terminals==0.5.3 (from -r /content/1.txt (line 103))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jupyterlab==4.3.5 (from -r /content/1.txt (line 104))\n",
            "  Downloading jupyterlab-4.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 105)) (0.3.0)\n",
            "Collecting jupyterlab_server==2.27.3 (from -r /content/1.txt (line 106))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting libarchive-c==5.1 (from -r /content/1.txt (line 107))\n",
            "  Downloading libarchive_c-5.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: linkify-it-py==2.0.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 108)) (2.0.3)\n",
            "Collecting lm_eval==0.4.5 (from -r /content/1.txt (line 109))\n",
            "  Downloading lm_eval-0.4.5-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: locket==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 110)) (1.0.0)\n",
            "Requirement already satisfied: loguru==0.7.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 111)) (0.7.3)\n",
            "Collecting lxml==5.3.0 (from -r /content/1.txt (line 112))\n",
            "  Downloading lxml-5.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting Markdown==3.7 (from -r /content/1.txt (line 113))\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 114)) (3.0.0)\n",
            "Collecting MarkupSafe==2.1.5 (from -r /content/1.txt (line 115))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 116)) (0.1.7)\n",
            "Collecting mbstrdecoder==1.1.3 (from -r /content/1.txt (line 117))\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: mdit-py-plugins==0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 118)) (0.4.2)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 119)) (0.1.2)\n",
            "Collecting mistune==3.1.1 (from -r /content/1.txt (line 120))\n",
            "  Downloading mistune-3.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting more-itertools==10.5.0 (from -r /content/1.txt (line 121))\n",
            "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 122)) (1.3.0)\n",
            "Collecting msal==1.31.1 (from -r /content/1.txt (line 123))\n",
            "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions==1.2.0 (from -r /content/1.txt (line 124))\n",
            "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: msgpack==1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 125)) (1.1.0)\n",
            "Collecting msgspec==0.18.6 (from -r /content/1.txt (line 126))\n",
            "  Downloading msgspec-0.18.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting multidict==6.1.0 (from -r /content/1.txt (line 127))\n",
            "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 128)) (0.70.16)\n",
            "Collecting mypy-extensions==1.0.0 (from -r /content/1.txt (line 129))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting narwhals==1.17.0 (from -r /content/1.txt (line 130))\n",
            "  Downloading narwhals-1.17.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: nbclient==0.10.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 131)) (0.10.2)\n",
            "Requirement already satisfied: nbconvert==7.16.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 132)) (7.16.6)\n",
            "Requirement already satisfied: nbformat==5.10.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 133)) (5.10.4)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 134)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 135)) (3.4.2)\n",
            "Collecting ninja==1.11.1.1 (from -r /content/1.txt (line 136))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 137)) (3.9.1)\n",
            "Requirement already satisfied: notebook_shim==0.2.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 138)) (0.2.4)\n",
            "Collecting numexpr==2.10.1 (from -r /content/1.txt (line 139))\n",
            "  Downloading numexpr-2.10.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting numpy==2.1.2 (from -r /content/1.txt (line 140))\n",
            "  Downloading numpy-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 141)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 142)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 143)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 144)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 145)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 146)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 147)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 148)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 149)) (12.1.0.106)\n",
            "Collecting nvidia-ml-py==12.560.30 (from -r /content/1.txt (line 150))\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 151)) (2.21.5)\n",
            "Collecting nvidia-nvjitlink-cu12==12.1.105 (from -r /content/1.txt (line 152))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 153)) (12.1.105)\n",
            "Requirement already satisfied: oauthlib==3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 154)) (3.2.2)\n",
            "Collecting objprint==0.2.3 (from -r /content/1.txt (line 155))\n",
            "  Downloading objprint-0.2.3-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting oci==2.141.1 (from -r /content/1.txt (line 156))\n",
            "  Downloading oci-2.141.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting ocifs==1.3.1 (from -r /content/1.txt (line 157))\n",
            "  Downloading ocifs-1.3.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: omegaconf==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 158)) (2.3.0)\n",
            "Collecting orjson==3.10.14 (from -r /content/1.txt (line 159))\n",
            "  Downloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides==7.7.0 (from -r /content/1.txt (line 160))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting packaging==24.1 (from -r /content/1.txt (line 161))\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas==2.2.3 (from -r /content/1.txt (line 162))\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 163)) (1.5.1)\n",
            "Collecting panel==1.5.5 (from -r /content/1.txt (line 164))\n",
            "  Downloading panel-1.5.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: param==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 165)) (2.2.0)\n",
            "Collecting paramiko==3.5.0 (from -r /content/1.txt (line 166))\n",
            "  Downloading paramiko-3.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 167)) (0.8.4)\n",
            "Requirement already satisfied: partd==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 168)) (1.4.2)\n",
            "Collecting pathspec==0.12.1 (from -r /content/1.txt (line 169))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pathvalidate==3.2.1 (from -r /content/1.txt (line 170))\n",
            "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting peft==0.13.2 (from -r /content/1.txt (line 171))\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 172)) (4.9.0)\n",
            "Collecting pillow==11.1.0 (from -r /content/1.txt (line 173))\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting platformdirs==4.3.6 (from -r /content/1.txt (line 174))\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pluggy==1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 175)) (1.5.0)\n",
            "Requirement already satisfied: ply==3.11 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 176)) (3.11)\n",
            "Collecting portalocker==2.10.1 (from -r /content/1.txt (line 177))\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: prometheus_client==0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 178)) (0.21.1)\n",
            "Collecting prompt_toolkit==3.0.48 (from -r /content/1.txt (line 179))\n",
            "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting propcache==0.2.0 (from -r /content/1.txt (line 180))\n",
            "  Downloading propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting proto-plus==1.25.0 (from -r /content/1.txt (line 181))\n",
            "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf==5.28.3 (from -r /content/1.txt (line 182))\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting psutil==6.1.0 (from -r /content/1.txt (line 183))\n",
            "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 184)) (0.7.0)\n",
            "Collecting pudb==2024.1.3 (from -r /content/1.txt (line 185))\n",
            "  Downloading pudb-2024.1.3-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting pure_eval==0.2.3 (from -r /content/1.txt (line 186))\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pyarrow==18.0.0 (from -r /content/1.txt (line 187))\n",
            "  Downloading pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyasn1==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 188)) (0.6.1)\n",
            "Collecting pyasn1_modules==0.4.1 (from -r /content/1.txt (line 189))\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pybind11==2.13.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 190)) (2.13.6)\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 191)) (2.22)\n",
            "Collecting pycryptodomex==3.21.0 (from -r /content/1.txt (line 192))\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pydantic==2.10.3 (from -r /content/1.txt (line 193))\n",
            "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic_core==2.27.1 (from -r /content/1.txt (line 194))\n",
            "  Downloading pydantic_core-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pygit2==1.16.0 (from -r /content/1.txt (line 195))\n",
            "  Downloading pygit2-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting Pygments==2.18.0 (from -r /content/1.txt (line 196))\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: PyJWT==2.10.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 197)) (2.10.1)\n",
            "Requirement already satisfied: PyNaCl==1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 198)) (1.5.0)\n",
            "Requirement already satisfied: pynvml==12.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 199)) (12.0.0)\n",
            "Collecting pyOpenSSL==24.3.0 (from -r /content/1.txt (line 200))\n",
            "  Downloading pyOpenSSL-24.3.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pyspnego==0.11.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 201)) (0.11.2)\n",
            "Collecting pytablewriter==1.2.0 (from -r /content/1.txt (line 202))\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting pytest==8.3.3 (from -r /content/1.txt (line 203))\n",
            "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 204)) (2.9.0.post0)\n",
            "Collecting python-json-logger==3.2.1 (from -r /content/1.txt (line 205))\n",
            "  Downloading python_json_logger-3.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: pytorch-triton==3.1.0+cf34004b8a in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 206)) (3.1.0+cf34004b8a)\n",
            "Collecting pytz==2024.2 (from -r /content/1.txt (line 207))\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pyviz_comms==3.0.3 (from -r /content/1.txt (line 208))\n",
            "  Downloading pyviz_comms-3.0.3-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 209)) (6.0.2)\n",
            "Collecting pyzmq==26.2.0 (from -r /content/1.txt (line 210))\n",
            "  Downloading pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting referencing==0.35.1 (from -r /content/1.txt (line 211))\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting regex==2024.9.11 (from -r /content/1.txt (line 212))\n",
            "  Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 213)) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib==2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 214)) (2.0.0)\n",
            "Collecting rfc3339-validator==0.1.4 (from -r /content/1.txt (line 215))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator==0.1.1 (from -r /content/1.txt (line 216))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 217)) (13.9.4)\n",
            "Requirement already satisfied: rouge_score==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 218)) (0.1.2)\n",
            "Collecting rpds-py==0.22.3 (from -r /content/1.txt (line 219))\n",
            "  Downloading rpds_py-0.22.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting rsa==4.9 (from -r /content/1.txt (line 220))\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting s3fs==2024.9.0 (from -r /content/1.txt (line 221))\n",
            "  Downloading s3fs-2024.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting sacrebleu==2.4.3 (from -r /content/1.txt (line 222))\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors==0.4.5 (from -r /content/1.txt (line 223))\n",
            "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting scikit-learn==1.5.2 (from -r /content/1.txt (line 224))\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting scipy==1.14.1 (from -r /content/1.txt (line 225))\n",
            "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Send2Trash==1.8.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 226)) (1.8.3)\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 227)) (0.2.0)\n",
            "Collecting sentry-sdk==2.17.0 (from -r /content/1.txt (line 228))\n",
            "  Downloading sentry_sdk-2.17.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting setproctitle==1.3.3 (from -r /content/1.txt (line 229))\n",
            "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 230)) (1.5.4)\n",
            "Collecting six==1.16.0 (from -r /content/1.txt (line 231))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: smbprotocol==1.15.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 232)) (1.15.0)\n",
            "Collecting smmap==5.0.1 (from -r /content/1.txt (line 233))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 234)) (1.3.1)\n",
            "Requirement already satisfied: sortedcontainers==2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 235)) (2.4.0)\n",
            "Collecting soupsieve==2.6 (from -r /content/1.txt (line 236))\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: sqlitedict==2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 237)) (2.1.0)\n",
            "Collecting stack-data==0.6.3 (from -r /content/1.txt (line 238))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: stone==3.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 239)) (3.3.1)\n",
            "Requirement already satisfied: submitit==1.5.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 240)) (1.5.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 241)) (1.13.1)\n",
            "Collecting tabledata==1.3.3 (from -r /content/1.txt (line 242))\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 243)) (0.9.0)\n",
            "Collecting tblib==3.0.0 (from -r /content/1.txt (line 244))\n",
            "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tcolorpy==0.1.6 (from -r /content/1.txt (line 245))\n",
            "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: terminado==0.18.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 246)) (0.18.1)\n",
            "Collecting threadpoolctl==3.5.0 (from -r /content/1.txt (line 247))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tiktoken==0.8.0 (from -r /content/1.txt (line 248))\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tinycss2==1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/1.txt (line 249)) (1.4.0)\n",
            "Collecting tokenizers==0.20.1 (from -r /content/1.txt (line 250))\n",
            "  Downloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tomli==2.0.2 (from -r /content/1.txt (line 251))\n",
            "  Downloading tomli-2.0.2-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting toolz==1.0.0 (from -r /content/1.txt (line 252))\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.6.0.dev20241031+cu121 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.6.0.dev20241031+cu121\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"My test prompt\""
      ],
      "metadata": {
        "id": "W7I_gJTP_Xso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python /content/blt/demo.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrkRGYx5_tB5",
        "outputId": "af21f7bc-2ad5-4627-8920-fe60dc4959ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "\u001b[33mUsage: \u001b[0mdemo.py [OPTIONS] PROMPT\n",
            "\u001b[2mTry \u001b[0m\u001b[2;34m'demo.py \u001b[0m\u001b[1;2;34m-\u001b[0m\u001b[1;2;34m-help\u001b[0m\u001b[2;34m'\u001b[0m\u001b[2m for help.\u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m Error \u001b[0m\u001b[31m─────────────────────────────────────────────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m Missing argument 'PROMPT'.                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/demo.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQWPie_v_vzw",
        "outputId": "71716ce0-3f32-486c-952f-ac8b65983916"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m                                                                                \u001b[0m\n",
            "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mdemo.py [OPTIONS] PROMPT\u001b[0m\u001b[1m                                               \u001b[0m\u001b[1m \u001b[0m\n",
            "\u001b[1m                                                                                \u001b[0m\n",
            "\u001b[2m╭─\u001b[0m\u001b[2m Arguments \u001b[0m\u001b[2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[31m*\u001b[0m    prompt      \u001b[1;33mTEXT\u001b[0m  \u001b[2m[default: None]\u001b[0m \u001b[2;31m[required]\u001b[0m                            \u001b[2m│\u001b[0m\n",
            "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-model\u001b[0m\u001b[1;36m-name\u001b[0m        \u001b[1;33mTEXT\u001b[0m  \u001b[2m[default: blt-1b]\u001b[0m                                  \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m              \u001b[1;33m    \u001b[0m  Show this message and exit.                        \u001b[2m│\u001b[0m\n",
            "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/demo.py --model-name blt-1b prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkImE3fn_3uo",
        "outputId": "8017c0e2-04e0-4a85-a186-c45a7322d451"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BLT model: blt-1b\n",
            "[rank0]: \u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/blt/\u001b[0m\u001b[1;33mdemo.py\u001b[0m:\u001b[94m20\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0msetup_torch_distributed(distributed_args)                       \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mcheckpoint_path = os.path.join(\u001b[33m\"\u001b[0m\u001b[33mhf-weights\u001b[0m\u001b[33m\"\u001b[0m, model_name)            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading BLT model: \u001b[0m\u001b[33m{\u001b[0mmodel_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m20 \u001b[2m│   \u001b[0mmodel, tokenizer, train_cfg = \u001b[1;4mload_consolidated_model_and_tokenizer\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[1;2;4m│   │   \u001b[0m\u001b[1;4mcheckpoint_path,\u001b[0m                                                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[1;2;4m│   \u001b[0m\u001b[1;4m)\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(model, ByteLatentTransformer)                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m─────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m──────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  checkpoint_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m distributed_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       model_name = \u001b[33m'blt-1b'\u001b[0m                                         \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           prompt = \u001b[33m'prompt'\u001b[0m                                         \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰─────────────────────────────────────────────────────────────────────╯\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m403\u001b[0m in                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[92mload_consolidated_model_and_tokenizer\u001b[0m                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m400 \u001b[0m\u001b[2m│   │   │   \u001b[0msetup_torch_distributed(distributed_args)                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m401 \u001b[0m\u001b[2m│   \u001b[0mtrain_args_path = os.path.join(consolidated_path, \u001b[33m\"\u001b[0m\u001b[33mparams.json\u001b[0m\u001b[33m\"\u001b[0m)   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m│   \u001b[0mfs = get_fs(train_args_path)                                       \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m403 \u001b[2m│   \u001b[0mtrain_args = TrainArgs.model_validate_json(\u001b[1;4mfs.read_text(train_args\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m405 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m train_args.train_entropy_model:                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_args = train_args.entropy_model                          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m consolidated_path = \u001b[33m'hf-weights/blt-1b'\u001b[0m                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     \u001b[39mat \u001b[0m\u001b[94m0xfe6997c1d10\u001b[0m\u001b[1m>\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  init_distributed = \u001b[94mFalse\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   train_args_path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m721\u001b[0m in \u001b[92mread_text\u001b[0m      \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 718 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mURL of file on this filesystems\u001b[0m                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 719 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mencoding, errors, newline: same as `open`.\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 720 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 721 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.open(                                               \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 722 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath,                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 723 \u001b[0m\u001b[2m│   │   │   \u001b[0mmode=\u001b[33m\"\u001b[0m\u001b[33mr\u001b[0m\u001b[33m\"\u001b[0m,                                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m 724 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoding=encoding,                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m encoding = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   errors = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  newline = \u001b[94mNone\u001b[0m                                                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     path = \u001b[33m'hf-weights/blt-1b/params.json'\u001b[0m                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[94m0xfe6997c1d10\u001b[0m\u001b[1m>\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1298\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1295 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m k \u001b[95min\u001b[0m kwargs                                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1296 \u001b[0m\u001b[2m│   │   │   \u001b[0m}                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1297 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m io.TextIOWrapper(                                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1298 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.open(                                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1299 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpath,                                             \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1300 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmode,                                             \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1301 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mblock_size=block_size,                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0xfe6997c1d10\u001b[0m\u001b[1m>\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   text_kwargs = \u001b[1m{\u001b[0m\u001b[33m'encoding'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'errors'\u001b[0m: \u001b[94mNone\u001b[0m, \u001b[33m'newline'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/\u001b[0m\u001b[1;33mspec.py\u001b[0m:\u001b[94m1310\u001b[0m in \u001b[92mopen\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1307 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1309 \u001b[0m\u001b[2m│   │   │   \u001b[0mac = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mautocommit\u001b[0m\u001b[33m\"\u001b[0m, \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m._intrans)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1310 \u001b[2m│   │   │   \u001b[0mf = \u001b[96mself\u001b[0m._open(                                           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1311 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpath,                                                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1312 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmode=mode,                                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m1313 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mblock_size=block_size,                                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            ac = \u001b[94mTrue\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m    block_size = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m cache_options = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   compression = \u001b[94mNone\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            io = \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[39m \u001b[0m\u001b[33m'io'\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfrozen\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1m>\u001b[0m                                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          mode = \u001b[33m'rb'\u001b[0m                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 \u001b[94m0xfe6997c1d10\u001b[0m\u001b[1m>\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m201\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_mkdir \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m mode:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.makedirs(\u001b[96mself\u001b[0m._parent(path), exist_ok=\u001b[94mTrue\u001b[0m)           \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mLocalFileOpener(path, mode, fs=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m, **kwargs)\u001b[0m          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92mtouch\u001b[0m(\u001b[96mself\u001b[0m, path, truncate=\u001b[94mTrue\u001b[0m, **kwargs):                    \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   \u001b[0mpath = \u001b[96mself\u001b[0m._strip_protocol(path)                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m block_size = \u001b[94mNone\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     kwargs = \u001b[1m{\u001b[0m\u001b[33m'autocommit'\u001b[0m: \u001b[94mTrue\u001b[0m, \u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       mode = \u001b[33m'rb'\u001b[0m                                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[94m0xfe6997c1d10\u001b[0m\u001b[1m>\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m365\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m362 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.autocommit = autocommit                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m363 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.compression = get_compression(path, compression)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m364 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.blocksize = io.DEFAULT_BUFFER_SIZE                        \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m365 \u001b[2m│   │   \u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m._open()\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m366 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  autocommit = \u001b[94mTrue\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m compression = \u001b[94mNone\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          fs = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileSystem\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0xfe6997c1d10\u001b[0m\u001b[1m>\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      kwargs = \u001b[1m{\u001b[0m\u001b[33m'cache_options'\u001b[0m: \u001b[94mNone\u001b[0m\u001b[1m}\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        mode = \u001b[33m'rb'\u001b[0m                                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        path = \u001b[33m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               \u001b[94m0xfe6997c5990\u001b[0m\u001b[1m>\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/fsspec/implementations/\u001b[0m\u001b[1;33mlocal.py\u001b[0m:\u001b[94m370\u001b[0m  \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m in \u001b[92m_open\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m367 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m\u001b[90m \u001b[0m\u001b[92m_open\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.f \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m.f.closed:                            \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.autocommit \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.mode:                \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m370 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = \u001b[1;4;96mopen\u001b[0m\u001b[1;4m(\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.path, mode=\u001b[0m\u001b[1;4;96mself\u001b[0m\u001b[1;4m.mode)\u001b[0m               \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m371 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.compression:                                   \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m372 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcompress = compr[\u001b[96mself\u001b[0m.compression]                 \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m   \u001b[2m373 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.f = compress(\u001b[96mself\u001b[0m.f, mode=\u001b[96mself\u001b[0m.mode)          \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m self = \u001b[1m<\u001b[0m\u001b[1;95mfsspec.implementations.local.LocalFileOpener\u001b[0m\u001b[39m object at \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        \u001b[94m0xfe6997c5990\u001b[0m\u001b[1m>\u001b[0m                                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "[rank0]: \u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "[rank0]: \u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \n",
            "[rank0]: \u001b[32m'/content/blt/hf-weights/blt-1b/params.json'\u001b[0m\n",
            "[rank0]:[W508 22:26:51.021138074 ProcessGroupNCCL.cpp:1374] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"My test prompt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbFhGhYFAEOh",
        "outputId": "d8b23490-0d9c-4439-b580-2867917dfa25"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mload_transformers\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(blt_model)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(tok_and_patcher)                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m source == \u001b[33m\"\u001b[0m\u001b[33mhub\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0mentropy_model = \u001b[1;4mLMTransformer.from_pretrained(entropy_repo)\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0mblt_model = ByteLatentTransformer.from_pretrained(blt_repo)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0mtok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_r \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer = tok_and_patcher.tokenizer_args.build()             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      blt_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     blt_repo = \u001b[33m'facebook/blt-1b'\u001b[0m      \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  entropy_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m entropy_repo = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       prompt = \u001b[33m'My test prompt'\u001b[0m       \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       source = \u001b[33m'hub'\u001b[0m                  \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             arg_name = \u001b[33m'pretrained_model_name_or_path'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            arg_value = \u001b[33m'facebook/blt-entropy'\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 args = \u001b[1m(\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'bytelatent.transformer.LMTransformer'\u001b[0m\u001b[1m>\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[33m'facebook/blt-entropy'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[1m)\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m check_use_auth_token = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            has_token = \u001b[94mFalse\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            signature = \u001b[1m<\u001b[0m\u001b[1;95mSignature\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mcls: Type\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39m~T\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpretrained_model_name_or_path: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, *, force_download: bool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mresume_download: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mbool\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, proxies: \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mOptional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mDict\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, token: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, bool, \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mNoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, cache_dir: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path, NoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, local_files_only:\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mbool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, revision: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39m**model_kwargs\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -> ~T\u001b[0m\u001b[1m>\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m566\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m._hub_mixin_inject_config \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m model_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_kwargs[\u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m] = config                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0minstance = \u001b[96mcls\u001b[0m._from_pretrained(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_id=\u001b[96mstr\u001b[0m(model_id),                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0mcache_dir=cache_dir,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        config = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   config_file = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m pretrained_model_name_or_path = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰────────────────────────────────────────────────────────╯\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m789\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_from_pretrained\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0m**model_kwargs,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   \u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Load Pytorch pretrained weights and return the loaded model\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m789 \u001b[2m│   │   \u001b[0mmodel = \u001b[1;4;96mcls\u001b[0m\u001b[1;4m(**model_kwargs)\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m os.path.isdir(model_id):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m791 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading weights from local directory\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_file = os.path.join(model_id, constants.SAFETENSORS_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m─────────────────\u001b[0m\u001b[33m─╮\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     map_location = \u001b[33m'cpu'\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           strict = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────╯\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mLMTransformer.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \n",
            "\u001b[32m'args'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://gist.github.com/EntilZha/a70177a6a3d6fb3db0d04d79b9e5d48f\n",
        "\n",
        "\n",
        "/content/1.txt\n",
        "absl-py==2.1.0\n",
        "accelerate==1.0.1\n",
        "adlfs==2024.12.0\n",
        "aiobotocore==2.16.1\n",
        "aiohappyeyeballs==2.4.3\n",
        "aiohttp==3.10.10\n",
        "aioitertools==0.12.0\n",
        "aiosignal==1.3.1\n",
        "altair==5.5.0\n",
        "annotated-types==0.7.0\n",
        "antlr4-python3-runtime==4.9.3\n",
        "anyio==4.8.0\n",
        "argon2-cffi==23.1.0\n",
        "argon2-cffi-bindings==21.2.0\n",
        "arrow==1.3.0\n",
        "asttokens==3.0.0\n",
        "async-lru==2.0.4\n",
        "async-timeout==4.0.3\n",
        "attrs==24.2.0\n",
        "azure-core==1.32.0\n",
        "azure-datalake-store==0.0.53\n",
        "azure-identity==1.19.0\n",
        "azure-storage-blob==12.24.0\n",
        "babel==2.17.0\n",
        "bcrypt==4.2.1\n",
        "beautifulsoup4==4.13.3\n",
        "black==24.8.0\n",
        "bleach==6.2.0\n",
        "blobfile==3.0.0\n",
        "bokeh==3.6.2\n",
        "botocore==1.35.88\n",
        "cachetools==5.5.0\n",
        "certifi==2024.8.30\n",
        "cffi==1.17.1\n",
        "chardet==5.2.0\n",
        "charset-normalizer==3.4.0\n",
        "circuitbreaker==2.0.0\n",
        "click==8.1.7\n",
        "cloudpickle==3.1.0\n",
        "colorama==0.4.6\n",
        "comm==0.2.2\n",
        "contourpy==1.3.1\n",
        "cryptography==44.0.0\n",
        "dask==2024.12.1\n",
        "DataProperty==1.0.1\n",
        "datasets==3.1.0\n",
        "datatrove==0.4.0\n",
        "debugpy==1.8.9\n",
        "decorator==5.1.1\n",
        "defusedxml==0.7.1\n",
        "dill==0.3.8\n",
        "distributed==2024.12.1\n",
        "docker-pycreds==0.4.0\n",
        "dropbox==12.0.2\n",
        "dropboxdrivefs==1.4.1\n",
        "evaluate==0.4.3\n",
        "exceptiongroup==1.2.2\n",
        "executing==2.1.0\n",
        "fastjsonschema==2.21.1\n",
        "filelock==3.16.1\n",
        "fqdn==1.5.1\n",
        "frozenlist==1.5.0\n",
        "fsspec==2024.9.0\n",
        "fusepy==3.0.1\n",
        "gcsfs==2024.9.0.post1\n",
        "gitdb==4.0.11\n",
        "GitPython==3.1.43\n",
        "google-api-core==2.24.0\n",
        "google-auth==2.37.0\n",
        "google-auth-oauthlib==1.2.1\n",
        "google-cloud-core==2.4.1\n",
        "google-cloud-storage==2.19.0\n",
        "google-crc32c==1.6.0\n",
        "google-resumable-media==2.7.2\n",
        "googleapis-common-protos==1.66.0\n",
        "h11==0.14.0\n",
        "httpcore==1.0.7\n",
        "httpx==0.28.1\n",
        "huggingface-hub==0.30.2\n",
        "humanize==4.11.0\n",
        "idna==3.10\n",
        "importlib_metadata==8.5.0\n",
        "iniconfig==2.0.0\n",
        "ipykernel==6.29.5\n",
        "ipython==8.30.0\n",
        "isodate==0.7.2\n",
        "isoduration==20.11.0\n",
        "isort==6.0.0\n",
        "jedi==0.19.2\n",
        "Jinja2==3.1.4\n",
        "jmespath==1.0.1\n",
        "joblib==1.4.2\n",
        "json5==0.10.0\n",
        "jsonlines==4.0.0\n",
        "jsonpointer==3.0.0\n",
        "jsonschema==4.23.0\n",
        "jsonschema-specifications==2024.10.1\n",
        "jupyter-events==0.12.0\n",
        "jupyter-lsp==2.2.5\n",
        "jupyter_client==8.6.3\n",
        "jupyter_core==5.7.2\n",
        "jupyter_server==2.15.0\n",
        "jupyter_server_terminals==0.5.3\n",
        "jupyterlab==4.3.5\n",
        "jupyterlab_pygments==0.3.0\n",
        "jupyterlab_server==2.27.3\n",
        "libarchive-c==5.1\n",
        "linkify-it-py==2.0.3\n",
        "lm_eval==0.4.5\n",
        "locket==1.0.0\n",
        "loguru==0.7.3\n",
        "lxml==5.3.0\n",
        "Markdown==3.7\n",
        "markdown-it-py==3.0.0\n",
        "MarkupSafe==2.1.5\n",
        "matplotlib-inline==0.1.7\n",
        "mbstrdecoder==1.1.3\n",
        "mdit-py-plugins==0.4.2\n",
        "mdurl==0.1.2\n",
        "mistune==3.1.1\n",
        "more-itertools==10.5.0\n",
        "mpmath==1.3.0\n",
        "msal==1.31.1\n",
        "msal-extensions==1.2.0\n",
        "msgpack==1.1.0\n",
        "msgspec==0.18.6\n",
        "multidict==6.1.0\n",
        "multiprocess==0.70.16\n",
        "mypy-extensions==1.0.0\n",
        "narwhals==1.17.0\n",
        "nbclient==0.10.2\n",
        "nbconvert==7.16.6\n",
        "nbformat==5.10.4\n",
        "nest-asyncio==1.6.0\n",
        "networkx==3.4.2\n",
        "ninja==1.11.1.1\n",
        "nltk==3.9.1\n",
        "notebook_shim==0.2.4\n",
        "numexpr==2.10.1\n",
        "numpy==2.1.2\n",
        "nvidia-cublas-cu12==12.1.3.1\n",
        "nvidia-cuda-cupti-cu12==12.1.105\n",
        "nvidia-cuda-nvrtc-cu12==12.1.105\n",
        "nvidia-cuda-runtime-cu12==12.1.105\n",
        "nvidia-cudnn-cu12==9.1.0.70\n",
        "nvidia-cufft-cu12==11.0.2.54\n",
        "nvidia-curand-cu12==10.3.2.106\n",
        "nvidia-cusolver-cu12==11.4.5.107\n",
        "nvidia-cusparse-cu12==12.1.0.106\n",
        "nvidia-ml-py==12.560.30\n",
        "nvidia-nccl-cu12==2.21.5\n",
        "nvidia-nvjitlink-cu12==12.1.105\n",
        "nvidia-nvtx-cu12==12.1.105\n",
        "oauthlib==3.2.2\n",
        "objprint==0.2.3\n",
        "oci==2.141.1\n",
        "ocifs==1.3.1\n",
        "omegaconf==2.3.0\n",
        "orjson==3.10.14\n",
        "overrides==7.7.0\n",
        "packaging==24.1\n",
        "pandas==2.2.3\n",
        "pandocfilters==1.5.1\n",
        "panel==1.5.5\n",
        "param==2.2.0\n",
        "paramiko==3.5.0\n",
        "parso==0.8.4\n",
        "partd==1.4.2\n",
        "pathspec==0.12.1\n",
        "pathvalidate==3.2.1\n",
        "peft==0.13.2\n",
        "pexpect==4.9.0\n",
        "pillow==11.1.0\n",
        "platformdirs==4.3.6\n",
        "pluggy==1.5.0\n",
        "ply==3.11\n",
        "portalocker==2.10.1\n",
        "prometheus_client==0.21.1\n",
        "prompt_toolkit==3.0.48\n",
        "propcache==0.2.0\n",
        "proto-plus==1.25.0\n",
        "protobuf==5.28.3\n",
        "psutil==6.1.0\n",
        "ptyprocess==0.7.0\n",
        "pudb==2024.1.3\n",
        "pure_eval==0.2.3\n",
        "pyarrow==18.0.0\n",
        "pyasn1==0.6.1\n",
        "pyasn1_modules==0.4.1\n",
        "pybind11==2.13.6\n",
        "pycparser==2.22\n",
        "pycryptodomex==3.21.0\n",
        "pydantic==2.10.3\n",
        "pydantic_core==2.27.1\n",
        "pygit2==1.16.0\n",
        "Pygments==2.18.0\n",
        "PyJWT==2.10.1\n",
        "PyNaCl==1.5.0\n",
        "pynvml==12.0.0\n",
        "pyOpenSSL==24.3.0\n",
        "pyspnego==0.11.2\n",
        "pytablewriter==1.2.0\n",
        "pytest==8.3.3\n",
        "python-dateutil==2.9.0.post0\n",
        "python-json-logger==3.2.1\n",
        "pytorch-triton==3.1.0+cf34004b8a\n",
        "pytz==2024.2\n",
        "pyviz_comms==3.0.3\n",
        "PyYAML==6.0.2\n",
        "pyzmq==26.2.0\n",
        "referencing==0.35.1\n",
        "regex==2024.9.11\n",
        "requests==2.32.3\n",
        "requests-oauthlib==2.0.0\n",
        "rfc3339-validator==0.1.4\n",
        "rfc3986-validator==0.1.1\n",
        "rich==13.9.4\n",
        "rouge_score==0.1.2\n",
        "rpds-py==0.22.3\n",
        "rsa==4.9\n",
        "s3fs==2024.9.0\n",
        "sacrebleu==2.4.3\n",
        "safetensors==0.4.5\n",
        "scikit-learn==1.5.2\n",
        "scipy==1.14.1\n",
        "Send2Trash==1.8.3\n",
        "sentencepiece==0.2.0\n",
        "sentry-sdk==2.17.0\n",
        "setproctitle==1.3.3\n",
        "shellingham==1.5.4\n",
        "six==1.16.0\n",
        "smbprotocol==1.15.0\n",
        "smmap==5.0.1\n",
        "sniffio==1.3.1\n",
        "sortedcontainers==2.4.0\n",
        "soupsieve==2.6\n",
        "sqlitedict==2.1.0\n",
        "stack-data==0.6.3\n",
        "stone==3.3.1\n",
        "submitit==1.5.2\n",
        "sympy==1.13.1\n",
        "tabledata==1.3.3\n",
        "tabulate==0.9.0\n",
        "tblib==3.0.0\n",
        "tcolorpy==0.1.6\n",
        "terminado==0.18.1\n",
        "threadpoolctl==3.5.0\n",
        "tiktoken==0.8.0\n",
        "tinycss2==1.4.0\n",
        "tokenizers==0.20.1\n",
        "tomli==2.0.2\n",
        "toolz==1.0.0\n",
        "torch==2.6.0.dev20241031+cu121\n",
        "tornado==6.4.2\n",
        "tqdm==4.66.6\n",
        "tqdm-multiprocess==0.0.11\n",
        "traitlets==5.14.3\n",
        "transformers==4.46.1\n",
        "treetable==0.2.5\n",
        "typepy==1.3.2\n",
        "typer==0.15.1\n",
        "types-python-dateutil==2.9.0.20241206\n",
        "typing_extensions==4.12.2\n",
        "tzdata==2024.2\n",
        "uc-micro-py==1.0.3\n",
        "uri-template==1.3.0\n",
        "urllib3==2.2.3\n",
        "urwid==2.6.16\n",
        "urwid_readline==0.15.1\n",
        "viztracer==0.17.0\n",
        "vl-convert-python==1.7.0\n",
        "wandb==0.18.5\n",
        "wcwidth==0.2.13\n",
        "webcolors==24.11.1\n",
        "webencodings==0.5.1\n",
        "websocket-client==1.8.0\n",
        "word2number==1.1\n",
        "wrapt==1.17.0\n",
        "xformers @ git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148\n",
        "xxhash==3.5.0\n",
        "xyzservices==2024.9.0\n",
        "yarl==1.17.1\n",
        "zict==3.0.0\n",
        "zipp==3.21.0\n",
        "zstandard==0.23.0"
      ],
      "metadata": {
        "id": "VX_Xs7X4Av3x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bytelatent/eval.py"
      ],
      "metadata": {
        "id": "nfrfLaCTBM-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iePwOCeKBRAj",
        "outputId": "563c2fa0-290c-45bc-c966-db556027f943"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1967, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/ggml.py\", line 24, in <module>\n",
            "    from tokenizers import Tokenizer, decoders, normalizers, pre_tokenizers, processors\n",
            "ImportError: cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/eval.py\", line 11, in <module>\n",
            "    from lm_eval import simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/__init__.py\", line 4, in <module>\n",
            "    from .evaluator import evaluate, simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
            "    import lm_eval.api.metrics\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
            "    from lm_eval.api.registry import register_aggregation, register_metric\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
            "    import evaluate as hf_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\", line 23, in <module>\n",
            "    from ..configuration_utils import PretrainedConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 27, in <module>\n",
            "    from .modeling_gguf_pytorch_utils import load_gguf_checkpoint\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_gguf_pytorch_utils.py\", line 22, in <module>\n",
            "    from .integrations import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1955, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1969, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import transformers.integrations.ggml because of the following error (look up to see its traceback):\n",
            "cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt/bytelatent\n",
        "!python /content/blt/bytelatent/eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZOzLzImBSmZ",
        "outputId": "5078a668-074f-46f9-f9fd-b629c58dfa73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt/bytelatent\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1967, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/ggml.py\", line 24, in <module>\n",
            "    from tokenizers import Tokenizer, decoders, normalizers, pre_tokenizers, processors\n",
            "ImportError: cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/eval.py\", line 11, in <module>\n",
            "    from lm_eval import simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/__init__.py\", line 4, in <module>\n",
            "    from .evaluator import evaluate, simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
            "    import lm_eval.api.metrics\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
            "    from lm_eval.api.registry import register_aggregation, register_metric\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
            "    import evaluate as hf_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\", line 23, in <module>\n",
            "    from ..configuration_utils import PretrainedConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 27, in <module>\n",
            "    from .modeling_gguf_pytorch_utils import load_gguf_checkpoint\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_gguf_pytorch_utils.py\", line 22, in <module>\n",
            "    from .integrations import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1955, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1969, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import transformers.integrations.ggml because of the following error (look up to see its traceback):\n",
            "cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!python /content/blt/bytelatent/generate.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVfMsAU4B0LR",
        "outputId": "97ff12a5-c62b-4437-a7b3-dd915b4489ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/generate.py\", line 13, in <module>\n",
            "    from bytelatent.args import EvalArgs, PackedCausalTransformerGeneratorArgs, TrainArgs\n",
            "ModuleNotFoundError: No module named 'bytelatent'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "UZV3rqTVB9vp",
        "outputId": "a36b9964-b0ce-4eb1-96e1-4f91b4356ca7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-074b9d338a11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mentropy_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-entropy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mblt_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mblt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtok_and_patcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://huggingface.co/facebook/blt-entropy/tree/main"
      ],
      "metadata": {
        "id": "k-sMMtt-CKFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://docs.astral.sh/uv/"
      ],
      "metadata": {
        "id": "yaPKXF3fDteV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup/download_prepare_hf_data.py fineweb_edu 32 --data_dir ./data --seed 42 --nchunks 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c3_TSGVD8si",
        "outputId": "e0040e98-e043-4e29-da88-e1a4de52e502"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "train-00006-of-00014.parquet:   7% 168M/2.34G [00:17<03:40, 9.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   7% 157M/2.33G [00:17<03:51, 9.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   7% 157M/2.33G [00:17<04:12, 8.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:   7% 168M/2.38G [00:17<02:56, 12.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:   9% 199M/2.31G [00:17<02:51, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:   8% 178M/2.31G [00:17<02:42, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   8% 178M/2.37G [00:17<03:21, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:   8% 178M/2.29G [00:17<03:15, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:   9% 210M/2.35G [00:17<02:27, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:   7% 168M/2.29G [00:17<03:19, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:   8% 199M/2.37G [00:17<02:20, 15.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   7% 157M/2.32G [00:17<03:50, 9.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:   9% 199M/2.28G [00:17<03:18, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:   7% 168M/2.35G [00:17<03:35, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:   8% 189M/2.34G [00:17<03:07, 11.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:   8% 178M/2.38G [00:18<02:39, 13.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:   8% 178M/2.30G [00:18<02:55, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   7% 168M/2.33G [00:17<03:33, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:   9% 210M/2.31G [00:18<02:36, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:   8% 189M/2.31G [00:18<02:30, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:   9% 220M/2.35G [00:18<02:26, 14.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:   8% 178M/2.34G [00:18<03:26, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   7% 168M/2.33G [00:18<03:31, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:   8% 178M/2.29G [00:18<03:04, 11.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:   9% 210M/2.37G [00:18<02:13, 16.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   8% 189M/2.37G [00:18<03:12, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:   8% 189M/2.38G [00:18<02:13, 16.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:   8% 189M/2.29G [00:18<03:10, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:   9% 210M/2.28G [00:18<02:57, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:   8% 199M/2.34G [00:18<02:49, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:   8% 178M/2.35G [00:18<03:11, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   7% 168M/2.32G [00:19<04:35, 7.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:   8% 189M/2.30G [00:20<04:36, 7.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:   9% 210M/2.34G [00:20<04:12, 8.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:   8% 189M/2.29G [00:20<04:30, 7.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:   8% 189M/2.34G [00:20<04:51, 7.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   8% 178M/2.32G [00:20<04:16, 8.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:   9% 199M/2.31G [00:20<04:19, 8.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:   8% 189M/2.35G [00:20<04:33, 7.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   8% 199M/2.37G [00:20<04:40, 7.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   8% 178M/2.33G [00:20<04:58, 7.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  10% 220M/2.28G [00:20<04:19, 7.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:   8% 199M/2.38G [00:20<03:59, 9.10MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  10% 231M/2.35G [00:21<04:18, 8.20MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:   9% 199M/2.29G [00:21<04:37, 7.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  10% 220M/2.31G [00:21<04:37, 7.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:   9% 220M/2.37G [00:21<04:11, 8.55MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   8% 178M/2.33G [00:20<05:23, 6.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:   9% 199M/2.30G [00:21<03:36, 9.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:   8% 199M/2.35G [00:21<03:27, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:   9% 199M/2.29G [00:21<03:28, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:   9% 220M/2.34G [00:21<03:20, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:   9% 199M/2.34G [00:21<03:49, 9.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:   9% 210M/2.31G [00:21<03:27, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:   9% 210M/2.38G [00:21<03:13, 11.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   8% 189M/2.32G [00:21<03:30, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  10% 231M/2.37G [00:21<03:15, 10.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   9% 210M/2.37G [00:21<03:47, 9.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:   9% 210M/2.29G [00:21<03:37, 9.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  10% 231M/2.28G [00:21<03:33, 9.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:   9% 210M/2.35G [00:21<02:43, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   8% 189M/2.33G [00:21<04:02, 8.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  10% 241M/2.35G [00:21<03:28, 10.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  10% 231M/2.31G [00:21<03:40, 9.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   8% 189M/2.33G [00:21<04:11, 8.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:   9% 210M/2.30G [00:21<02:56, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  10% 220M/2.31G [00:21<02:42, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  10% 231M/2.34G [00:21<02:44, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:   9% 210M/2.29G [00:21<02:52, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:   9% 220M/2.38G [00:21<02:33, 14.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:   9% 210M/2.34G [00:21<03:02, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   9% 199M/2.32G [00:21<02:43, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  10% 241M/2.37G [00:21<02:32, 14.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  10% 220M/2.29G [00:21<02:57, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:   9% 220M/2.35G [00:21<02:21, 15.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   9% 199M/2.33G [00:21<03:23, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  11% 241M/2.28G [00:22<03:04, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  10% 241M/2.31G [00:22<03:07, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   9% 220M/2.37G [00:22<03:19, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  11% 252M/2.35G [00:22<03:05, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  10% 241M/2.34G [00:22<02:27, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   9% 199M/2.33G [00:21<03:36, 9.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  10% 231M/2.38G [00:22<02:27, 14.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   9% 210M/2.32G [00:22<02:33, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  10% 220M/2.29G [00:22<02:42, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  10% 220M/2.30G [00:22<02:48, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  11% 252M/2.37G [00:22<02:35, 13.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:   9% 220M/2.34G [00:22<03:00, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   9% 210M/2.33G [00:22<02:58, 11.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  10% 231M/2.31G [00:22<02:53, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  11% 252M/2.28G [00:22<02:43, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  10% 231M/2.29G [00:22<02:51, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  10% 231M/2.35G [00:22<02:24, 14.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  10% 231M/2.29G [00:22<02:14, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  10% 231M/2.37G [00:22<02:56, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  11% 252M/2.34G [00:22<02:14, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   9% 210M/2.33G [00:23<03:57, 8.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  11% 252M/2.31G [00:24<04:07, 8.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:   9% 220M/2.32G [00:24<04:17, 8.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  10% 241M/2.38G [00:24<04:17, 8.31MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  10% 241M/2.31G [00:24<04:11, 8.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:   9% 220M/2.33G [00:24<04:20, 8.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  10% 241M/2.37G [00:24<04:16, 8.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  10% 231M/2.34G [00:24<04:30, 7.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  11% 262M/2.34G [00:25<03:50, 9.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  11% 262M/2.35G [00:25<04:58, 7.00MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  10% 231M/2.30G [00:25<04:31, 7.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  11% 241M/2.29G [00:25<03:51, 8.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  10% 241M/2.35G [00:25<04:00, 8.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  11% 262M/2.37G [00:25<04:22, 8.01MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  11% 241M/2.29G [00:25<04:16, 8.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  11% 262M/2.31G [00:25<03:55, 8.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  11% 262M/2.28G [00:25<04:17, 7.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:   9% 220M/2.33G [00:24<04:19, 8.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  11% 252M/2.38G [00:25<03:19, 10.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  11% 252M/2.31G [00:25<03:17, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  10% 231M/2.32G [00:25<03:24, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  10% 241M/2.34G [00:25<03:29, 9.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  10% 231M/2.33G [00:25<03:26, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  12% 273M/2.37G [00:25<03:19, 10.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  11% 252M/2.29G [00:25<03:17, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  12% 273M/2.35G [00:25<03:48, 9.08MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  11% 252M/2.29G [00:25<02:59, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  11% 241M/2.30G [00:25<03:31, 9.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  11% 252M/2.37G [00:25<03:28, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  12% 273M/2.34G [00:25<03:04, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  12% 273M/2.31G [00:25<03:01, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  11% 252M/2.35G [00:25<03:14, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  10% 241M/2.32G [00:25<02:34, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  10% 231M/2.33G [00:25<03:18, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  11% 262M/2.38G [00:25<02:37, 13.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  11% 262M/2.37G [00:25<02:34, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  11% 262M/2.31G [00:25<02:36, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  10% 241M/2.33G [00:25<02:41, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  10% 241M/2.33G [00:25<02:36, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  11% 262M/2.29G [00:25<02:30, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  12% 273M/2.28G [00:25<03:35, 9.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  12% 283M/2.37G [00:29<05:56, 5.84MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  11% 252M/2.33G [00:28<05:00, 6.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  12% 283M/2.35G [00:29<06:14, 5.51MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  11% 252M/2.30G [00:29<06:01, 5.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  11% 273M/2.38G [00:29<05:26, 6.44MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  12% 273M/2.37G [00:29<05:28, 6.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  11% 252M/2.34G [00:29<06:21, 5.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  11% 252M/2.32G [00:29<05:32, 6.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  12% 273M/2.31G [00:29<05:24, 6.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  12% 283M/2.31G [00:29<05:47, 5.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  12% 283M/2.34G [00:29<05:56, 5.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  12% 294M/2.37G [00:29<04:27, 7.75MB/s]\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  12% 294M/2.35G [00:29<04:39, 7.36MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  11% 262M/2.29G [00:29<06:08, 5.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  11% 262M/2.30G [00:29<04:29, 7.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  11% 252M/2.33G [00:29<05:37, 6.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  13% 304M/2.37G [00:29<03:13, 10.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  11% 262M/2.35G [00:29<06:16, 5.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  12% 283M/2.28G [00:29<06:04, 5.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  12% 273M/2.33G [00:29<03:06, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  12% 283M/2.37G [00:29<04:08, 8.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  12% 273M/2.29G [00:29<05:34, 6.05MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  12% 283M/2.38G [00:32<07:19, 4.76MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  12% 294M/2.37G [00:33<06:21, 5.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  12% 273M/2.29G [00:33<07:58, 4.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  11% 262M/2.32G [00:33<07:41, 4.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  12% 283M/2.33G [00:32<05:15, 6.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  12% 283M/2.29G [00:33<07:09, 4.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  13% 315M/2.37G [00:33<05:58, 5.73MB/s]\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  12% 294M/2.38G [00:33<05:43, 6.06MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  12% 283M/2.31G [00:33<07:38, 4.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  12% 273M/2.35G [00:33<08:06, 4.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  13% 294M/2.34G [00:33<08:03, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  13% 294M/2.31G [00:33<07:54, 4.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  12% 273M/2.30G [00:33<06:57, 4.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  11% 262M/2.33G [00:33<07:44, 4.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  11% 262M/2.34G [00:33<08:27, 4.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  13% 294M/2.28G [00:33<07:50, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  13% 304M/2.35G [00:33<07:10, 4.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  12% 273M/2.32G [00:33<05:34, 6.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  13% 294M/2.29G [00:33<05:11, 6.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  13% 304M/2.37G [00:33<04:45, 7.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  12% 283M/2.29G [00:33<05:47, 5.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  13% 294M/2.33G [00:33<04:03, 8.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  14% 325M/2.37G [00:33<04:20, 7.83MB/s]\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  13% 304M/2.38G [00:33<04:10, 8.27MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  13% 294M/2.31G [00:34<06:30, 5.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  13% 304M/2.31G [00:34<04:40, 7.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  13% 304M/2.33G [00:34<04:13, 8.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  13% 315M/2.35G [00:34<06:31, 5.20MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  13% 304M/2.34G [00:34<07:12, 4.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  14% 336M/2.37G [00:35<04:30, 7.50MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  12% 283M/2.32G [00:34<05:24, 6.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  13% 315M/2.38G [00:34<04:25, 7.78MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  12% 283M/2.35G [00:35<07:22, 4.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  12% 273M/2.33G [00:34<07:16, 4.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  13% 294M/2.29G [00:35<05:48, 5.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  13% 304M/2.31G [00:35<07:25, 4.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  13% 315M/2.37G [00:35<05:10, 6.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  13% 304M/2.28G [00:35<07:21, 4.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  12% 273M/2.34G [00:35<07:54, 4.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  13% 294M/2.35G [00:35<05:27, 6.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  14% 315M/2.31G [00:35<03:56, 8.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  13% 315M/2.33G [00:35<03:29, 9.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  14% 325M/2.35G [00:35<04:59, 6.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  13% 304M/2.29G [00:35<05:30, 6.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  12% 283M/2.30G [00:35<06:59, 4.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  13% 315M/2.34G [00:38<08:25, 4.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  13% 304M/2.29G [00:39<07:50, 4.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  14% 315M/2.31G [00:39<08:56, 3.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  13% 294M/2.32G [00:39<07:57, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  15% 346M/2.37G [00:39<07:25, 4.54MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  14% 315M/2.28G [00:39<08:57, 3.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  12% 283M/2.33G [00:39<09:10, 3.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  14% 325M/2.38G [00:39<07:27, 4.58MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  14% 336M/2.35G [00:39<07:23, 4.54MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  14% 325M/2.37G [00:39<07:38, 4.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  12% 283M/2.34G [00:39<09:32, 3.59MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  13% 304M/2.35G [00:39<07:48, 4.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  14% 315M/2.29G [00:39<07:41, 4.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  14% 325M/2.33G [00:39<06:12, 5.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  14% 325M/2.31G [00:39<06:42, 4.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  13% 294M/2.30G [00:39<08:45, 3.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  14% 325M/2.34G [00:39<07:05, 4.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  14% 315M/2.29G [00:39<05:55, 5.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  15% 357M/2.37G [00:39<05:33, 6.02MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  14% 325M/2.31G [00:39<06:50, 4.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  14% 336M/2.38G [00:39<05:38, 6.04MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  13% 304M/2.32G [00:39<06:07, 5.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  14% 336M/2.33G [00:39<04:50, 6.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  13% 294M/2.33G [00:39<06:53, 4.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  13% 294M/2.34G [00:40<07:09, 4.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  13% 315M/2.35G [00:40<05:58, 5.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  14% 325M/2.28G [00:40<06:48, 4.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  15% 336M/2.31G [00:40<05:07, 6.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  15% 346M/2.35G [00:40<05:42, 5.85MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  14% 325M/2.29G [00:40<05:53, 5.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  14% 336M/2.37G [00:40<05:56, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  13% 304M/2.30G [00:40<06:33, 5.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  14% 336M/2.34G [00:40<05:19, 6.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  15% 336M/2.31G [00:40<04:59, 6.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  14% 325M/2.29G [00:40<04:29, 7.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  16% 367M/2.37G [00:40<04:12, 7.93MB/s]\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  15% 346M/2.38G [00:40<04:09, 8.13MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  15% 346M/2.33G [00:40<04:19, 7.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  14% 315M/2.32G [00:40<05:18, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  13% 304M/2.33G [00:40<05:50, 5.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  15% 357M/2.35G [00:43<07:01, 4.73MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  15% 336M/2.29G [00:43<06:02, 5.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  14% 325M/2.32G [00:43<05:53, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  15% 357M/2.33G [00:43<05:12, 6.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  14% 315M/2.30G [00:43<07:36, 4.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  14% 325M/2.35G [00:43<07:19, 4.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  15% 336M/2.29G [00:43<07:09, 4.56MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  16% 377M/2.37G [00:43<05:56, 5.58MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  15% 346M/2.37G [00:43<07:16, 4.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  15% 357M/2.38G [00:43<05:57, 5.65MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  15% 346M/2.31G [00:43<06:38, 4.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  15% 346M/2.34G [00:43<06:46, 4.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  15% 346M/2.31G [00:43<06:34, 4.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  15% 336M/2.28G [00:43<07:57, 4.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  13% 304M/2.34G [00:43<08:22, 4.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  15% 367M/2.38G [00:44<05:30, 6.08MB/s]\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  16% 388M/2.37G [00:44<05:29, 6.00MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  14% 315M/2.33G [00:44<07:39, 4.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  15% 346M/2.29G [00:44<06:21, 5.11MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  15% 346M/2.29G [00:44<05:40, 5.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  14% 325M/2.33G [00:44<05:30, 6.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  14% 325M/2.30G [00:44<06:51, 4.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  14% 336M/2.35G [00:45<06:42, 5.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  14% 336M/2.32G [00:45<05:42, 5.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  15% 357M/2.37G [00:45<06:40, 5.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  16% 367M/2.33G [00:44<05:13, 6.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  15% 357M/2.31G [00:45<06:18, 5.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  16% 367M/2.35G [00:45<06:45, 4.89MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  15% 357M/2.31G [00:45<06:46, 4.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  16% 377M/2.38G [00:46<05:27, 6.11MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  16% 357M/2.29G [00:47<06:06, 5.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  15% 346M/2.28G [00:47<08:57, 3.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  17% 398M/2.37G [00:47<06:16, 5.23MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  15% 357M/2.34G [00:47<08:36, 3.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  16% 357M/2.29G [00:47<06:52, 4.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  15% 346M/2.35G [00:47<07:02, 4.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  13% 315M/2.34G [00:47<09:39, 3.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  15% 367M/2.37G [00:47<07:01, 4.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  15% 346M/2.32G [00:47<06:20, 5.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  16% 377M/2.35G [00:47<06:53, 4.77MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  16% 377M/2.33G [00:47<05:59, 5.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  16% 388M/2.38G [00:47<04:51, 6.82MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  16% 367M/2.31G [00:47<06:21, 5.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  14% 336M/2.33G [00:47<06:22, 5.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  16% 367M/2.31G [00:47<06:41, 4.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  16% 357M/2.28G [00:47<06:38, 4.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  15% 336M/2.30G [00:47<07:16, 4.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  16% 367M/2.29G [00:47<04:41, 6.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  17% 409M/2.37G [00:47<04:38, 7.02MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  16% 367M/2.34G [00:47<06:13, 5.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  15% 357M/2.35G [00:47<05:08, 6.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  16% 367M/2.29G [00:47<05:02, 6.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  14% 325M/2.34G [00:47<06:59, 4.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  15% 357M/2.32G [00:47<04:39, 7.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  17% 388M/2.33G [00:47<04:22, 7.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  17% 388M/2.35G [00:47<05:00, 6.53MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  16% 377M/2.37G [00:47<05:08, 6.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  15% 346M/2.30G [00:47<05:19, 6.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  16% 367M/2.35G [00:48<03:51, 8.56MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  16% 377M/2.34G [00:48<04:38, 7.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  17% 398M/2.38G [00:50<06:10, 5.34MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  14% 336M/2.34G [00:50<07:41, 4.33MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  16% 377M/2.29G [00:50<06:13, 5.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  16% 377M/2.29G [00:50<06:25, 4.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  16% 377M/2.31G [00:51<07:48, 4.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  17% 388M/2.29G [00:51<05:04, 6.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  17% 388M/2.34G [00:51<06:35, 4.95MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  16% 388M/2.37G [00:51<07:15, 4.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  16% 367M/2.32G [00:51<06:51, 4.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  16% 357M/2.30G [00:51<07:12, 4.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  17% 388M/2.29G [00:51<05:02, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  16% 367M/2.28G [00:51<08:19, 3.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  17% 398M/2.35G [00:51<07:06, 4.57MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  16% 377M/2.31G [00:51<08:25, 3.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  17% 409M/2.38G [00:51<05:26, 6.03MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  15% 346M/2.33G [00:51<08:24, 3.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  16% 377M/2.35G [00:51<06:18, 5.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  15% 346M/2.34G [00:51<06:27, 5.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  18% 419M/2.37G [00:52<07:12, 4.50MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  17% 398M/2.33G [00:51<06:54, 4.66MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  17% 388M/2.31G [00:52<06:05, 5.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  16% 377M/2.32G [00:52<05:12, 6.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  17% 398M/2.37G [00:52<05:28, 5.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  17% 398M/2.29G [00:52<04:02, 7.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  17% 398M/2.34G [00:52<05:04, 6.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  16% 367M/2.30G [00:52<05:29, 5.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  17% 409M/2.35G [00:52<05:28, 5.90MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  17% 388M/2.35G [00:52<04:49, 6.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  17% 398M/2.29G [00:52<04:09, 7.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  17% 377M/2.28G [00:52<06:27, 4.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  18% 419M/2.38G [00:52<04:30, 7.23MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  17% 388M/2.31G [00:52<06:33, 4.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  15% 357M/2.33G [00:52<06:33, 5.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  18% 409M/2.33G [00:52<05:22, 5.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  15% 357M/2.34G [00:52<05:10, 6.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  17% 388M/2.32G [00:52<04:05, 7.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  17% 398M/2.31G [00:52<04:53, 6.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  18% 409M/2.29G [00:52<03:20, 9.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  18% 430M/2.37G [00:52<05:39, 5.70MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  17% 409M/2.34G [00:52<04:10, 7.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  18% 419M/2.35G [00:52<04:22, 7.35MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  17% 409M/2.37G [00:52<04:30, 7.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  16% 377M/2.30G [00:53<04:30, 7.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  17% 398M/2.35G [00:53<03:59, 8.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  18% 430M/2.38G [00:53<03:37, 8.93MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  18% 409M/2.29G [00:53<03:30, 8.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  17% 388M/2.28G [00:53<05:09, 6.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  16% 367M/2.33G [00:52<05:06, 6.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  18% 419M/2.29G [00:53<02:42, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  18% 419M/2.34G [00:53<03:12, 9.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  18% 419M/2.33G [00:52<04:17, 7.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  17% 398M/2.31G [00:53<05:17, 6.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  18% 409M/2.31G [00:53<03:56, 8.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  19% 440M/2.37G [00:53<04:31, 7.10MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  17% 398M/2.32G [00:53<03:31, 9.09MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  16% 367M/2.34G [00:53<04:19, 7.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  18% 430M/2.35G [00:53<03:31, 9.09MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  18% 419M/2.37G [00:53<03:38, 8.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  17% 409M/2.35G [00:53<03:08, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  19% 440M/2.38G [00:53<02:55, 11.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  17% 388M/2.30G [00:53<03:36, 8.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  17% 398M/2.28G [00:53<03:57, 7.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  16% 377M/2.33G [00:53<03:57, 8.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  18% 430M/2.33G [00:53<03:21, 9.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  19% 430M/2.29G [00:53<02:16, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  16% 377M/2.34G [00:53<03:15, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  19% 451M/2.37G [00:53<03:28, 9.20MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  18% 419M/2.29G [00:53<02:56, 10.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  18% 430M/2.34G [00:53<02:40, 11.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  19% 440M/2.35G [00:53<02:43, 11.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  18% 409M/2.31G [00:53<04:02, 7.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  18% 409M/2.32G [00:53<02:46, 11.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  19% 451M/2.38G [00:53<02:14, 14.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  18% 430M/2.37G [00:53<02:50, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  18% 419M/2.31G [00:53<03:08, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  18% 419M/2.35G [00:53<02:29, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  18% 409M/2.28G [00:53<02:55, 10.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  17% 398M/2.30G [00:53<02:44, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  17% 388M/2.33G [00:53<03:01, 10.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  19% 440M/2.29G [00:53<01:53, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  19% 440M/2.37G [00:54<02:14, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  19% 440M/2.33G [00:53<02:45, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  17% 398M/2.33G [00:58<06:56, 4.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  20% 451M/2.29G [00:59<05:51, 5.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  19% 430M/2.31G [00:59<07:03, 4.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  19% 430M/2.29G [00:59<06:58, 4.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  19% 440M/2.34G [00:59<06:52, 4.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  18% 430M/2.35G [00:59<06:43, 4.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  18% 419M/2.28G [00:59<06:54, 4.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  19% 461M/2.37G [00:59<07:29, 4.24MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  19% 451M/2.37G [00:59<06:20, 5.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  18% 419M/2.31G [00:59<07:50, 4.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  17% 388M/2.34G [00:59<07:32, 4.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  18% 419M/2.32G [00:59<07:00, 4.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  19% 451M/2.33G [00:59<06:38, 4.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  19% 461M/2.38G [00:59<06:45, 4.73MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  19% 451M/2.35G [00:59<07:07, 4.45MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  18% 409M/2.30G [00:59<07:02, 4.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  18% 409M/2.33G [00:59<05:09, 6.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  20% 461M/2.29G [01:00<04:53, 6.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  17% 398M/2.34G [01:00<06:00, 5.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  19% 440M/2.31G [01:00<05:47, 5.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  19% 440M/2.29G [01:00<05:43, 5.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  19% 430M/2.32G [01:00<05:37, 5.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  19% 440M/2.35G [01:00<05:33, 5.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  20% 472M/2.38G [01:00<05:24, 5.87MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  20% 461M/2.35G [01:00<05:37, 5.59MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  19% 430M/2.28G [01:00<05:39, 5.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  19% 461M/2.37G [01:00<05:18, 5.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  19% 451M/2.34G [01:00<05:47, 5.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  20% 461M/2.33G [01:00<05:33, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  20% 472M/2.37G [01:00<06:16, 5.04MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  19% 430M/2.31G [01:00<06:28, 4.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  18% 419M/2.33G [01:00<04:26, 7.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  18% 419M/2.30G [01:00<05:45, 5.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  20% 451M/2.31G [01:00<04:32, 6.82MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  20% 482M/2.38G [01:00<04:16, 7.39MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  19% 451M/2.35G [01:00<04:25, 7.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  21% 472M/2.29G [01:00<04:02, 7.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  20% 472M/2.35G [01:00<04:28, 7.00MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  19% 440M/2.32G [01:00<04:32, 6.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  19% 440M/2.28G [01:00<04:31, 6.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  17% 409M/2.34G [01:00<04:51, 6.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  20% 451M/2.29G [01:00<04:35, 6.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  20% 472M/2.37G [01:00<04:17, 7.38MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  20% 461M/2.34G [01:00<04:33, 6.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  20% 472M/2.33G [01:00<04:20, 7.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  18% 430M/2.33G [01:00<03:33, 8.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  20% 482M/2.37G [01:00<04:50, 6.48MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  19% 430M/2.30G [01:00<04:28, 6.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  19% 440M/2.31G [01:00<04:59, 6.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  20% 461M/2.31G [01:01<03:27, 8.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  21% 493M/2.38G [01:01<03:19, 9.45MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  21% 482M/2.33G [01:01<03:43, 8.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  19% 440M/2.33G [01:01<03:13, 9.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  21% 482M/2.29G [01:01<03:40, 8.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  21% 482M/2.35G [01:01<04:00, 7.75MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  20% 472M/2.34G [01:01<03:59, 7.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  20% 461M/2.35G [01:01<04:02, 7.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  20% 451M/2.31G [01:01<04:15, 7.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  21% 493M/2.37G [01:01<04:11, 7.45MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  18% 419M/2.34G [01:01<04:17, 7.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  19% 451M/2.32G [01:01<04:05, 7.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  21% 503M/2.38G [01:02<03:04, 10.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  20% 472M/2.31G [01:02<03:13, 9.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  19% 440M/2.30G [01:02<04:03, 7.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  20% 451M/2.28G [01:02<04:10, 7.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  20% 482M/2.37G [01:02<04:01, 7.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  20% 461M/2.29G [01:02<04:14, 7.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  21% 493M/2.33G [01:01<02:57, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  19% 451M/2.33G [01:01<02:36, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  21% 493M/2.29G [01:02<02:53, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  20% 472M/2.35G [01:02<03:07, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  20% 461M/2.32G [01:02<03:09, 9.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  20% 461M/2.31G [01:02<03:18, 9.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  21% 493M/2.35G [01:02<03:09, 9.82MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  18% 430M/2.34G [01:02<03:20, 9.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  21% 503M/2.37G [01:02<03:16, 9.48MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  20% 461M/2.28G [01:02<03:07, 9.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  21% 482M/2.31G [01:02<02:30, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  20% 451M/2.30G [01:02<03:04, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  22% 514M/2.38G [01:02<02:25, 12.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  21% 482M/2.34G [01:02<03:12, 9.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  21% 493M/2.37G [01:02<03:02, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  20% 461M/2.33G [01:02<02:10, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  22% 503M/2.29G [01:02<02:21, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  21% 472M/2.29G [01:02<03:26, 8.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  22% 503M/2.33G [01:02<02:30, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  22% 514M/2.37G [01:07<07:00, 4.40MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  20% 472M/2.32G [01:07<07:12, 4.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  22% 524M/2.38G [01:07<06:38, 4.64MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  19% 440M/2.34G [01:07<07:30, 4.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  21% 493M/2.31G [01:08<06:41, 4.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  22% 514M/2.29G [01:08<06:15, 4.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  21% 503M/2.35G [01:08<07:16, 4.23MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  20% 461M/2.30G [01:08<07:08, 4.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  20% 472M/2.31G [01:08<07:23, 4.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  21% 493M/2.34G [01:08<07:16, 4.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  21% 482M/2.35G [01:08<07:27, 4.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  22% 514M/2.33G [01:07<06:25, 4.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  22% 524M/2.37G [01:08<05:20, 5.75MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  21% 503M/2.37G [01:08<07:18, 4.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  21% 472M/2.28G [01:08<07:17, 4.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  20% 472M/2.33G [01:07<06:30, 4.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  21% 482M/2.29G [01:08<07:13, 4.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  23% 524M/2.29G [01:08<04:35, 6.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  21% 503M/2.34G [01:08<05:21, 5.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  23% 535M/2.38G [01:08<05:00, 6.14MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  21% 482M/2.32G [01:08<05:25, 5.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  19% 451M/2.34G [01:08<05:36, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  21% 472M/2.30G [01:08<05:18, 5.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  22% 514M/2.35G [01:08<05:25, 5.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  21% 493M/2.35G [01:08<05:27, 5.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  22% 503M/2.31G [01:08<05:03, 5.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  22% 514M/2.37G [01:08<05:22, 5.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  21% 482M/2.31G [01:08<05:31, 5.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  23% 535M/2.37G [01:08<04:00, 7.60MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  21% 482M/2.28G [01:08<05:19, 5.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  21% 493M/2.29G [01:08<05:17, 5.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  22% 524M/2.33G [01:08<04:53, 6.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  21% 482M/2.33G [01:08<04:48, 6.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  23% 535M/2.29G [01:08<03:22, 8.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  20% 461M/2.34G [01:08<04:02, 7.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  21% 482M/2.30G [01:08<04:03, 7.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  21% 493M/2.31G [01:08<04:08, 7.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  21% 493M/2.32G [01:08<04:14, 7.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  22% 524M/2.37G [01:12<07:42, 3.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  21% 503M/2.35G [01:13<07:50, 3.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  22% 514M/2.34G [01:13<07:53, 3.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  23% 535M/2.33G [01:13<07:48, 3.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  24% 545M/2.29G [01:14<06:55, 4.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  22% 493M/2.28G [01:14<08:27, 3.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  21% 493M/2.33G [01:13<08:11, 3.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  22% 503M/2.31G [01:14<07:23, 4.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  22% 503M/2.29G [01:14<08:27, 3.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  23% 535M/2.37G [01:14<06:23, 4.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  22% 514M/2.35G [01:14<06:28, 4.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  23% 545M/2.33G [01:13<05:54, 5.04MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  22% 524M/2.34G [01:14<06:27, 4.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  22% 514M/2.31G [01:14<08:31, 3.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  23% 545M/2.37G [01:14<07:51, 3.86MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  20% 472M/2.34G [01:14<07:56, 3.92MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  22% 524M/2.35G [01:14<08:54, 3.41MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  23% 545M/2.38G [01:14<08:41, 3.51MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  22% 503M/2.32G [01:14<07:39, 3.96MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  21% 493M/2.30G [01:14<07:34, 3.97MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  24% 556M/2.29G [01:14<05:05, 5.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  22% 503M/2.28G [01:14<06:13, 4.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  22% 514M/2.29G [01:14<06:14, 4.76MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  22% 514M/2.31G [01:14<05:32, 5.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  23% 545M/2.37G [01:14<04:47, 6.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  23% 524M/2.31G [01:14<06:09, 4.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  22% 503M/2.33G [01:14<06:09, 4.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  23% 535M/2.34G [01:14<04:52, 6.18MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  24% 556M/2.33G [01:14<04:28, 6.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  22% 503M/2.30G [01:14<05:33, 5.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  22% 524M/2.35G [01:14<04:56, 6.15MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  23% 556M/2.38G [01:14<06:25, 4.72MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  22% 514M/2.32G [01:14<05:41, 5.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  21% 482M/2.34G [01:14<05:56, 5.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  22% 514M/2.28G [01:14<04:36, 6.41MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  25% 566M/2.29G [01:14<03:53, 7.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  23% 535M/2.35G [01:14<06:36, 4.57MB/s]\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  23% 556M/2.37G [01:14<05:53, 5.12MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  23% 524M/2.29G [01:14<04:37, 6.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  23% 524M/2.31G [01:14<04:09, 7.16MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  22% 514M/2.33G [01:14<04:33, 6.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  23% 535M/2.31G [01:14<04:33, 6.48MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  23% 556M/2.37G [01:17<05:41, 5.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  23% 524M/2.32G [01:17<06:21, 4.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  25% 577M/2.29G [01:18<05:26, 5.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  23% 545M/2.34G [01:18<06:21, 4.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  24% 566M/2.33G [01:17<06:03, 4.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  22% 514M/2.30G [01:18<06:50, 4.34MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  21% 493M/2.34G [01:18<07:07, 4.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  24% 545M/2.31G [01:18<05:57, 4.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  24% 566M/2.37G [01:18<07:07, 4.21MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  24% 566M/2.37G [01:18<04:52, 6.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  23% 545M/2.35G [01:18<07:39, 3.93MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  23% 524M/2.33G [01:18<06:09, 4.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  23% 524M/2.28G [01:18<06:14, 4.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  23% 535M/2.31G [01:18<05:52, 5.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  24% 566M/2.38G [01:18<07:38, 3.95MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  23% 535M/2.29G [01:18<06:12, 4.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  23% 535M/2.35G [01:18<06:41, 4.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  23% 535M/2.32G [01:18<05:12, 5.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  26% 587M/2.29G [01:18<04:08, 6.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  22% 503M/2.34G [01:18<05:20, 5.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  25% 577M/2.33G [01:18<04:38, 6.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  23% 545M/2.35G [01:18<04:49, 6.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00009-of-00014.parquet:  24% 556M/2.31G [01:18<04:31, 6.45MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "train-00003-of-00014.parquet:  24% 556M/2.35G [01:18<05:36, 5.32MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00005-of-00014.parquet:  24% 556M/2.34G [01:18<04:54, 6.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00012-of-00014.parquet:  23% 524M/2.30G [01:18<05:12, 5.67MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  23% 535M/2.33G [01:18<04:36, 6.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "train-00002-of-00014.parquet:  24% 577M/2.37G [01:18<05:18, 5.61MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00008-of-00014.parquet:  24% 545M/2.31G [01:18<04:22, 6.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "train-00001-of-00014.parquet:  24% 577M/2.38G [01:18<05:36, 5.35MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00013-of-00014.parquet:  23% 535M/2.28G [01:18<04:38, 6.27MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00007-of-00014.parquet:  23% 545M/2.32G [01:18<03:52, 7.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00011-of-00014.parquet:  24% 545M/2.29G [01:18<04:37, 6.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00006-of-00014.parquet:  22% 514M/2.34G [01:18<03:52, 7.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00001-of-00014.parquet:  25% 587M/2.33G [01:18<03:22, 8.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00000-of-00014.parquet:  24% 577M/2.37G [01:18<03:48, 7.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  24% 556M/2.35G [01:18<03:30, 8.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00010-of-00014.parquet:  26% 598M/2.29G [01:18<03:07, 9.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching 2738 files:   0% 2/2738 [01:21<30:49:01, 40.55s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -LsSf https://astral.sh/uv/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeGO1gZEEsl1",
        "outputId": "1a3d90dc-ffa7-44de-c33f-5336573aeebc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading uv 0.7.3 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!uv run python demo.py \"A BLT has\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIKNDMGqEt0a",
        "outputId": "e86517f9-0536-4aa3-d1b1-026d3391241e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 75.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 72.19 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.15 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 71.95 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 71.32 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 70.93 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.60 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.42 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 70.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 75.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 72.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.15 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 72.49 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 71.56 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 70.93 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.60 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.42 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 71.32 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 76.20 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 72.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.15 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 72.63 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 71.60 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 71.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.52 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 71.32 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 76.20 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 73.32 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.16 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.41 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 72.31 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 71.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 68.52 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 71.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 76.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 73.32 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.16 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.41 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 72.46 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 72.25 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 68.66 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 71.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 76.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 74.04 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.16 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.41 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 72.97 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 72.25 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.63 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 68.72 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 71.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 77.58 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 74.04 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.13 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 72.97 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 72.68 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.13 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 68.72 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 71.75 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 77.58 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 74.77 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mpyarrow   \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 40.29 MiB/40.34 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.13 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.74 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.00 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.88 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.32 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 72.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 77.71 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 74.77 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[18A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.21 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.74 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.00 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.91 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.32 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 72.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 77.71 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 74.77 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.21 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.74 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.91 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.32 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 72.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 77.71 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 74.92 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (129/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.21 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 73.74 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.91 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 69.32 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 72.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 78.09 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 75.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.05 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.91 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 72.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 75.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.87 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.05 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 72.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.00 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 75.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 74.87 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.53 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.88 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 72.60 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.00 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 76.09 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 75.38 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.70 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 73.88 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 72.60 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.84 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.15 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.98 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 76.09 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 75.66 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.70 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 74.02 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 72.60 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.84 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.15 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.98 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 76.09 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 75.66 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 74.70 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 74.56 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 73.33 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 70.84 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.15 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 78.98 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 76.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.17 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 75.08 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 74.59 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 73.79 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.57 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.27 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 79.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 76.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 75.56 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 75.26 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 73.79 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.57 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.15 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 77.60 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.92 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.16 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 75.45 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 74.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 73.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.76 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 78.29 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 77.67 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.20 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 75.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 74.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 74.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.76 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 78.29 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 77.67 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.93 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 75.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.18 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 71.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 74.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 80.76 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 78.29 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 77.67 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.93 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 75.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.28 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.28 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 74.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 81.46 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 78.35 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 77.68 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 76.93 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 76.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.28 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.28 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 74.81 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 81.46 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 79.06 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.35 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 77.33 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 76.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.82 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.28 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 74.81 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 81.46 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 79.06 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.35 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 77.63 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 76.29 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.82 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 72.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 75.43 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 81.95 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 79.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.90 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.30 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 76.92 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.31 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.27 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 75.43 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 82.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 80.11 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.94 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.30 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 77.60 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.32 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.27 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 76.05 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 82.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 80.32 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 78.94 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.62 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 77.60 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.88 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.70 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 76.05 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 82.75 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 80.32 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.10 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.04 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 77.64 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 73.70 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 76.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 82.75 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 81.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.51 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.37 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.17 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.22 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 76.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 83.45 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 81.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.51 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.37 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.22 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 77.17 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 83.45 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 81.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.51 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.37 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.61 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 77.50 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 83.45 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 81.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.71 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.32 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.44 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.71 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 77.50 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 81.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.72 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.32 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.62 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 78.44 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 74.71 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 78.02 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 81.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.81 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.98 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.62 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 78.44 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.45 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 78.02 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 82.59 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.81 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.98 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.66 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 78.51 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.45 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 78.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 82.59 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.81 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.98 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.66 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.17 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.45 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 78.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 82.59 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.85 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.98 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.66 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.26 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.45 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 78.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 82.91 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.85 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.57 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.81 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.26 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.97 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 78.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 84.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 83.31 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.78 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 75.97 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 85.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 83.95 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 1.23 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.78 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.57 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 85.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 84.05 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.29 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.78 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.61 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 85.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 84.05 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.31 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.91 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.78 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.61 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 85.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 84.05 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.34 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 79.96 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 81.78 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.61 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 85.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 84.05 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 1.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.09 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 82.20 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 79.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.61 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 85.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 84.05 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.37 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.30 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 82.49 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 79.32 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 80.66 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 76.61 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 79.85 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 86.31 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 84.49 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.39 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.30 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 82.94 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 79.42 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 80.66 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.23 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 80.42 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 86.95 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 84.78 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.39 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 80.72 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 83.37 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 79.97 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 81.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 77.95 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 80.42 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 86.95 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 85.36 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.39 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 81.38 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 84.13 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 80.62 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 81.68 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 78.07 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 81.17 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 87.59 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 85.58 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.39 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 81.55 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 84.39 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 81.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 81.84 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 78.63 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 81.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 87.99 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 86.27 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.39 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 82.11 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 84.88 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 82.09 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 82.74 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 79.31 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 82.61 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 88.22 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 86.98 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.40 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 82.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 85.76 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 82.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 83.02 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.09 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 83.20 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 88.40 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 87.71 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.40 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 83.64 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 86.32 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 82.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 83.59 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.83 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 83.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 88.89 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 88.01 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.40 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 84.32 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 86.32 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 83.61 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 83.94 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 80.83 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 83.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 89.62 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 88.60 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.42 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 84.84 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 87.04 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 84.31 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 84.30 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 81.32 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 83.42 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 90.11 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 88.60 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.42 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 85.58 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 87.63 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 84.68 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 85.00 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 81.76 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 84.10 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 90.29 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 89.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.42 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 85.58 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.46 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 85.21 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 85.27 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 82.47 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 84.40 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 90.91 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 89.80 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.44 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 85.94 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.46 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 85.29 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 85.51 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 83.04 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 84.92 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 91.64 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 90.35 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.44 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 86.41 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 89.21 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 85.71 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 85.51 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 83.04 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 85.44 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 91.64 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 91.10 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.44 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 86.98 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 89.88 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 86.56 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 85.73 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 83.81 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 85.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 92.34 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 91.87 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.45 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 87.04 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 90.73 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 86.56 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 86.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 84.56 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 86.21 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 92.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 91.87 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.47 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 87.22 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 90.73 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 87.32 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 86.63 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 84.56 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 86.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 93.49 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 92.59 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.47 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.30 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 91.97 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 87.99 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.28 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 85.32 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 87.04 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 94.04 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 92.81 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.47 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.43 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 91.97 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 88.48 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.38 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.01 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 87.65 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 94.86 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 93.48 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.48 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.88 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.13 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 88.72 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.38 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.39 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 87.65 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 94.86 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 93.48 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.48 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.88 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.13 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 88.72 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.66 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.57 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 87.65 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 95.31 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 94.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.48 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 88.88 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.20 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 88.79 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.66 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 86.57 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 88.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 95.59 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 94.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 1.48 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 89.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.31 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 89.50 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.71 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 87.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 88.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 95.59 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 95.06 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.50 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 89.79 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.56 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 90.28 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 88.19 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 88.06 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 88.74 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 96.35 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 95.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.50 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 89.95 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 93.33 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 90.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 88.85 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 88.06 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 88.97 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 97.04 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 95.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.50 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 89.95 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 93.96 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 91.34 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 89.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 88.85 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 89.20 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 97.69 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 96.29 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.50 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 90.66 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.69 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 91.68 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 90.00 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 89.55 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 89.20 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 98.38 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 97.02 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.51 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 91.26 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.35 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 91.94 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 90.25 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 89.65 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 89.90 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 99.01 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 97.77 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.51 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 91.41 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.35 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 92.68 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 91.06 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 90.33 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 90.64 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 99.01 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 97.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.51 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.15 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.56 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 92.68 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 91.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 90.36 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 90.64 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 99.71 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.14 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.51 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 92.15 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.62 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 93.44 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 92.22 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 91.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 91.30 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 100.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.17 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.53 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 92.91 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.65 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 93.92 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 92.29 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 91.76 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 92.08 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 100.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.18 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.54 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 93.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.67 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 94.19 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 93.06 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 91.76 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 92.08 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 101.22 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.20 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.54 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 93.65 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.73 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 94.89 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 93.06 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 92.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 92.77 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 101.59 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.20 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.55 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 94.09 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.73 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 94.89 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 93.76 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 92.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 92.77 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 101.96 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.26 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 1.56 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 94.35 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 96.38 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 94.89 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 93.76 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 93.24 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 92.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 101.96 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.47 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.61 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 94.88 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 96.47 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 95.63 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 94.53 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 93.24 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 93.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 102.14 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 98.77 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.61 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 94.88 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 97.15 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 95.86 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 94.53 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 94.03 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 93.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 102.73 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 99.46 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.61 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.55 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 97.82 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 95.86 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 94.79 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 94.46 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 93.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 102.73 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 99.46 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.62 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.55 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 97.92 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 96.10 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 95.32 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 94.46 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 94.52 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 103.46 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 99.85 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.62 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 95.86 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 98.08 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 96.65 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 95.32 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 95.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 94.52 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 103.50 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 100.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.62 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 96.48 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 98.56 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 96.99 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 95.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 95.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 94.65 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 104.04 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 100.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.64 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 96.48 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 98.56 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 97.41 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 95.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 95.48 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 95.12 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 104.61 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 101.10 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 1.70 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 97.28 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 98.86 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 97.41 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 96.23 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 96.10 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 95.23 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 104.61 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 101.10 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.76 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 97.48 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.20 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 97.51 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 96.51 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 96.10 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 95.92 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 105.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 101.71 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.76 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 97.90 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.20 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 98.15 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 96.51 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 96.80 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 95.92 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 105.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 101.71 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.76 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 98.50 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.33 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 98.15 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 97.22 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 96.91 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 96.18 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 105.51 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 102.44 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 98.50 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.50 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 98.87 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 97.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 97.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 96.65 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 105.53 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 102.44 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.27 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 98.87 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 97.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 97.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 97.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 105.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 103.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.27 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 99.44 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 97.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 98.06 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 97.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 106.15 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 103.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.27 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.06 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 99.44 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 97.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 98.39 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 97.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 106.15 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 103.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 99.27 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.15 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 99.44 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 98.43 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 98.39 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 97.42 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 106.15 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 103.91 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.00 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.15 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 100.13 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 98.43 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 98.39 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 97.89 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 106.17 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 103.91 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.00 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.89 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 100.13 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 99.20 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 98.86 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 98.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 106.49 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 103.91 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 100.63 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 100.89 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 100.42 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 99.20 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 98.86 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 98.39 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.17 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 104.39 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 100.63 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 101.38 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 100.86 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 99.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 99.54 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 99.01 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.17 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 104.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 101.24 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 101.38 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 101.31 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 99.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 99.16 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 104.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 101.24 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 101.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 101.48 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 99.16 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 105.00 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.78 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 101.95 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 101.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 101.48 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 99.88 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 105.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 101.98 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 101.69 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 102.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 101.25 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.78 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 99.88 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.42 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 105.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 101.98 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 102.39 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 102.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 101.25 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 100.78 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 100.57 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.42 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 106.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 102.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 102.39 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 102.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 101.25 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 101.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 100.60 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.95 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 106.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 102.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 102.68 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 102.70 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.01 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 101.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 100.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 107.95 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 106.78 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.11 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.09 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 102.77 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.01 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 101.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 100.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 108.50 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 106.78 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.11 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.09 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 103.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.01 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 102.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 101.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 108.50 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 107.23 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.76 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 103.71 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.30 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 102.78 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 101.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 108.58 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 107.50 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.79 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 103.76 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 104.03 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.57 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 102.78 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 102.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 109.32 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 108.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.81 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 104.00 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 104.53 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 104.53 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 103.48 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 102.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 109.32 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 108.71 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.81 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 104.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 104.53 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 104.53 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 102.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 103.48 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 102.60 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 109.40 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 108.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.81 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 104.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 104.53 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 104.53 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 103.36 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 103.48 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 102.60 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 109.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 108.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 1.84 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 104.73 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 105.21 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 105.00 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 103.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 104.23 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 102.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 109.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 109.23 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.86 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 104.86 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 105.70 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 105.47 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 104.23 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 104.23 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 102.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 110.43 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 109.50 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.86 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 104.94 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 105.70 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 105.73 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 104.23 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 104.96 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 103.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 111.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 110.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.87 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 105.49 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 106.49 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 106.55 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 104.36 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 105.12 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 103.56 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 111.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 110.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.87 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 105.49 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 106.49 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 106.55 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 104.73 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 105.12 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 103.62 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 111.68 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 111.02 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.87 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 105.49 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.13 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 106.55 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 104.73 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 105.38 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 104.29 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 111.68 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 111.02 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.89 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.22 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.13 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 106.75 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 105.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 105.76 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 104.29 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.40 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 111.15 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.90 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.22 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.77 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 107.16 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 105.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 105.76 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 105.05 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.40 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 111.48 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.90 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.34 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.77 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 107.24 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 105.85 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 106.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 105.05 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.40 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 112.18 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.90 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.38 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 108.49 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 107.24 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 105.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 106.51 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 105.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.74 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 112.18 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.94 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.53 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 108.49 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 108.05 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 106.53 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 107.20 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 105.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.76 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 112.81 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.94 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.63 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 109.20 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 108.78 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 106.53 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 107.97 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 106.30 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 112.87 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.94 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.64 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 109.91 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 108.78 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 107.25 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 107.97 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 107.05 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 113.58 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.95 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.74 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 109.91 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 109.53 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 107.96 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 108.65 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 107.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.98 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.97 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.74 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 109.53 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 107.96 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 108.65 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 107.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 112.98 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.97 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 106.74 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.25 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 107.96 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 108.84 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 107.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 113.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.97 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.24 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.66 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.25 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 108.21 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 108.84 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 107.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 113.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.99 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.97 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.24 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.43 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.25 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 108.21 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 109.13 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 108.57 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 113.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.99 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 1.97 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.24 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.43 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 108.21 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 109.38 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 108.57 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 114.30 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.99 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.11 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 107.24 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.43 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.39 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 108.63 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 109.38 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 108.57 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 114.30 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 114.99 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.12 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 108.00 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.90 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.39 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 108.78 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 109.38 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 109.04 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 114.30 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.14 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 108.00 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.90 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 110.69 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 108.81 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 110.17 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 109.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 115.06 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.14 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 108.62 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.90 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.12 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 109.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 110.17 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 109.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 115.06 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.14 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 108.62 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 112.21 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 109.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 110.60 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.02 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 115.06 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 108.62 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 112.21 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 109.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 110.90 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.02 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 115.66 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.17 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 112.21 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.10 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 110.90 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.02 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 115.66 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.17 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 112.91 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.10 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 110.90 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.02 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 115.66 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.70 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.17 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 112.91 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.10 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 111.28 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 116.19 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.87 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.64 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 112.91 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.74 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 111.70 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 116.19 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 115.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.64 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 113.59 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 111.98 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.74 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 111.70 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 110.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 116.19 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 116.40 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 109.69 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 113.59 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 112.72 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.74 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 111.70 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 111.22 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 116.79 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 116.40 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.20 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 113.65 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 112.72 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 111.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.33 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 111.22 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 116.79 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 116.40 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.20 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 114.12 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.12 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 111.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.33 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 111.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 116.79 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 116.94 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.32 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 114.12 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 111.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.95 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 111.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 117.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 116.94 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.64 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 114.12 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 111.90 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.95 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 111.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 117.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 117.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 110.64 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.85 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 111.99 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.95 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 111.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 117.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 117.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.16 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.88 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.94 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 111.99 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.95 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 112.07 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 117.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 117.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.16 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.88 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.94 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 112.07 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 118.25 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 117.55 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.16 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.88 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 113.94 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 112.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 118.25 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 118.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.43 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 115.08 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 114.50 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 112.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 118.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 118.21 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.43 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 115.08 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 114.50 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 114.40 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 112.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 118.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 118.82 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.43 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 115.81 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 114.50 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 112.95 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 114.45 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 112.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 118.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 118.82 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.15 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 111.82 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 115.85 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.10 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.25 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 114.45 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 113.38 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 119.36 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 118.82 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 112.39 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 116.57 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.10 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.43 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 114.54 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 114.01 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 119.67 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 119.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 112.59 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 116.57 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.55 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.71 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 115.16 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 114.01 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 119.67 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 119.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 112.59 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 116.57 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.55 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.78 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 115.16 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 114.48 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 120.28 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 120.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 113.11 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.16 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.75 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 113.78 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 115.16 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 114.73 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 120.28 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 120.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 113.37 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.16 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.75 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 114.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 115.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 114.73 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 120.28 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 120.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 113.37 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.16 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 114.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 115.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 115.32 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 120.78 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 121.03 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 113.99 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.48 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 115.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 114.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 115.89 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 115.49 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 120.78 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 121.03 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.17 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.15 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.48 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 116.02 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.22 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 116.10 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 115.49 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 121.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 121.64 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.15 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.86 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 116.54 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.22 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 116.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 116.20 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 121.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 121.64 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.86 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 116.57 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.33 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 116.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 116.20 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 121.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 121.86 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 117.86 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 116.57 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.33 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 116.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 116.20 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 122.24 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.16 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusolver-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 118.35 MiB/118.41 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 116.57 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.34 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 117.14 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 116.78 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 122.24 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.16 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[17A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (130/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 114.89 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.04 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 117.14 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 116.78 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 122.24 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.16 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (131/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 115.59 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.04 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 115.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 117.21 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 117.04 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 122.81 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (131/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.19 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 115.96 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.48 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 116.71 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 117.86 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 117.17 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 123.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (131/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cufft-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 116.00 MiB/116.00 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.96 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 116.94 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 117.63 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 123.54 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.67 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[16A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (131/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.96 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 117.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 117.63 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 123.54 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 122.67 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (131/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.96 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 117.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 117.63 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 123.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 123.01 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 117.96 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 117.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 118.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 123.67 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 123.01 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 118.67 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 117.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.12 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 118.14 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 123.67 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 123.01 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 118.85 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.07 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.83 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 118.50 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 124.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 123.73 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 119.38 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.69 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.83 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 118.98 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 123.73 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 119.38 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.69 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.83 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 119.08 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 124.34 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 119.40 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 120.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 119.08 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 124.40 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.20 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.12 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 120.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 119.63 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 124.40 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.12 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 118.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 120.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 119.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.55 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 124.40 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.12 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 120.67 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 119.67 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.77 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 124.81 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 121.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 120.17 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 125.77 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 125.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.21 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 121.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 120.17 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 126.48 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 125.35 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.87 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 119.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 121.91 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 120.18 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 126.48 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 125.35 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.87 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 120.17 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 121.91 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 120.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 126.48 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 125.35 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 120.87 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 120.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 122.46 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 120.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 125.44 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 121.11 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 120.48 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 122.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 120.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 125.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 121.11 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 120.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 122.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 121.61 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 126.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 121.80 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 121.17 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 122.58 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 121.61 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.21 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 126.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 121.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 121.17 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 123.31 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 121.63 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.45 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 126.08 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 121.83 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 121.17 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 123.31 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.73 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 126.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 122.28 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 121.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 123.31 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 126.25 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 2.22 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 122.32 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 121.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 123.79 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 127.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 126.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 122.86 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 121.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 124.05 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.14 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 128.19 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 126.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 122.86 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 122.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 124.05 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.43 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 128.51 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 126.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 122.86 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 122.40 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 124.05 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 128.51 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 127.47 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 123.30 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 122.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 124.08 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 128.51 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 127.49 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 123.60 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 122.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.60 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 122.83 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 128.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 127.49 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 123.60 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 122.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.82 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 123.44 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 128.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 127.50 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 123.60 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 122.94 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.82 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 123.44 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 129.36 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.24 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 124.32 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 123.21 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.82 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 123.44 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 129.36 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.24 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 124.32 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 123.81 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.85 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 124.06 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 129.36 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.24 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.24 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 124.32 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 123.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.86 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 124.06 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 129.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.98 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 124.72 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 123.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.50 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 124.06 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 129.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.98 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 125.02 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 123.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.50 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 124.50 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 129.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.98 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 125.02 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.24 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.50 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 124.82 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 130.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 128.98 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 125.34 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.24 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.50 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 124.82 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 130.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 129.73 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 125.52 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.93 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 125.32 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 130.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 129.73 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 125.52 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.93 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.67 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 125.58 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 130.35 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 129.73 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 125.52 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.93 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 126.31 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 125.58 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 130.35 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 130.37 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 126.26 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 124.93 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 126.31 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 125.58 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 130.72 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 130.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.25 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 126.26 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.28 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 126.41 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 126.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 130.82 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 130.94 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.26 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 126.99 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 126.41 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 126.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 130.96 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 130.94 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.26 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 126.99 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 125.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 127.07 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 126.93 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 131.84 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 131.07 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.28 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 127.79 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 126.32 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 127.62 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 127.06 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 131.84 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 131.66 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.28 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 128.42 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 126.91 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 127.71 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 127.26 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 132.02 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 132.44 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.29 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 128.97 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 127.47 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 128.42 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 127.49 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 132.05 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 132.47 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.29 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 129.58 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 127.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 129.20 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 127.53 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 132.55 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 133.22 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.30 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 129.73 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 128.35 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 129.59 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 127.82 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 133.28 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 133.80 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.30 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 130.39 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 129.13 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 130.17 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 128.47 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 133.28 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 134.06 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.31 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 130.81 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 129.13 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 130.43 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 129.24 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 134.10 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 134.69 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.31 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 131.13 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 129.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 130.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 129.24 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 134.17 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 135.19 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.31 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 131.24 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 129.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 131.15 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 129.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 134.20 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 135.19 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.31 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 131.78 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 130.59 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 131.15 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 129.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 134.82 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 135.30 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.33 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 131.87 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 130.59 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 131.92 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 130.24 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 134.82 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 135.72 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.33 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 132.19 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 130.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 131.92 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 130.78 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 135.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 135.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.34 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 132.57 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 131.59 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 132.09 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 130.78 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 135.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 136.31 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.34 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 132.57 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 131.59 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 132.68 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 131.23 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 135.86 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 136.62 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.34 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 132.62 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 132.10 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 132.68 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 131.40 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 136.52 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 136.62 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.34 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 133.31 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 132.29 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 133.22 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 131.40 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 136.52 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 137.01 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 2.34 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 133.31 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 132.29 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 133.28 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 132.16 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 136.82 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 137.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m----------------------------\u001b[2m--\u001b[0m\u001b[0m 133.33 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.06 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 133.88 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 132.16 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 136.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 137.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 134.06 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.06 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 133.88 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 132.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 137.50 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 137.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 134.06 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.08 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 134.43 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 132.69 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 137.50 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 138.31 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 134.70 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.08 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 134.43 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 133.09 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 137.84 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 138.31 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 134.70 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.72 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 134.85 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 133.09 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 137.84 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 138.91 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 135.00 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.85 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 135.16 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 133.46 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 138.43 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 139.39 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 135.03 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.85 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 135.16 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 134.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 138.43 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 139.39 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 135.03 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 133.85 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 135.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 134.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 138.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 139.39 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 135.61 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 134.06 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 135.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 134.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 138.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 139.39 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 135.61 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 134.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 135.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 134.13 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 138.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 139.61 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 135.61 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 134.54 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 135.77 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 134.56 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 139.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 140.17 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 136.17 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 134.79 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 136.11 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 134.74 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 139.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 140.17 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 136.17 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 135.04 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 136.11 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 135.42 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 139.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 140.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 136.25 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 135.30 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 136.68 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 136.10 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 140.40 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 140.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.36 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 136.92 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 136.04 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 136.80 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 136.10 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 140.49 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 141.64 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.37 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 137.67 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 136.05 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 137.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 136.22 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 141.18 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 141.64 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.37 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 137.67 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 136.43 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 137.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 136.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 141.30 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 142.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.37 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m-----------------------------\u001b[2m-\u001b[0m\u001b[0m 137.80 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 136.75 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.02 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m------------------\u001b[2m------------\u001b[0m\u001b[0m 137.06 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 141.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 142.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.37 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.38 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 137.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.23 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 137.43 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 141.94 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 142.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.37 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.61 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.27 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.41 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 2.47 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.77 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.41 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 2.53 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.77 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.36 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.41 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 2.61 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.77 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.39 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.41 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mlm-eval   \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 2.73 MiB/3.71 MiB\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.77 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 138.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.42 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.41 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[15A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 138.77 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 139.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.93 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.48 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 139.22 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 137.98 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 139.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.11 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.93 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 143.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (132/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 139.40 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 138.03 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 139.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.92 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 142.93 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 144.09 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 139.46 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 138.64 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 140.19 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 138.92 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 143.42 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 144.15 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 140.19 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 138.64 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 140.19 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 139.64 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 143.48 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 144.15 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 140.20 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 139.02 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 140.48 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 139.64 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 144.19 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 144.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 140.90 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 139.09 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 141.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 139.97 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 144.19 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 145.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 141.66 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 139.34 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 141.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 140.63 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 144.84 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 146.03 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 142.08 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 139.63 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 141.95 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 141.36 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 145.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 146.03 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 142.59 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 139.89 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 142.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 141.85 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 146.11 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 146.32 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 143.07 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 140.42 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 142.64 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 142.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 146.54 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 146.84 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-cusparselt-cu12\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 143.11 MiB/143.11 MiB\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 140.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 143.42 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 143.15 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 146.55 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 147.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[14A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 140.49 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 143.42 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 143.32 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 146.63 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 147.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 141.01 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 144.19 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 143.89 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 146.77 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 148.23 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 141.62 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 144.89 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 144.03 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 147.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 148.86 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (133/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 141.70 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 145.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 144.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 147.41 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 148.94 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 142.23 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 145.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 144.86 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 148.12 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 148.98 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 142.61 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 146.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 144.94 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 148.12 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 149.59 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 142.95 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 146.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 144.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 148.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 150.31 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 143.74 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 146.90 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 145.24 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 148.90 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 150.36 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 144.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 147.60 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 145.56 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 149.57 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 150.53 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 144.72 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 147.68 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 146.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 150.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 150.86 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 144.90 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 148.41 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 146.31 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 150.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 150.87 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 144.90 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 148.41 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 146.76 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 150.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 151.36 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 145.62 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 148.93 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 146.77 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 151.13 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 151.37 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 145.62 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 148.93 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 147.49 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 151.13 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 152.11 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 145.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 149.60 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 147.55 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 151.96 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 152.11 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 146.63 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 150.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 147.82 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 152.13 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 152.73 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 146.63 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 150.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 148.06 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 152.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 153.28 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 147.21 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 150.34 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 148.70 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 152.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 153.33 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 147.35 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 150.55 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 148.70 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 153.58 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 153.96 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 148.08 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 150.75 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 149.35 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 153.58 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 153.96 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 148.08 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 150.75 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 149.48 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 154.29 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 154.72 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 148.08 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 151.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 150.08 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 154.29 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 154.72 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 148.39 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 151.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 150.23 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 154.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 155.46 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 148.66 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 152.05 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 150.77 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 154.85 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 155.49 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 149.29 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 152.05 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.14 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 155.59 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 155.58 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 149.55 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 152.54 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.48 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 156.31 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 156.22 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.13 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 156.66 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 156.96 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.66 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.52 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.68 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.18 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.62 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.69 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.63 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.71 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.64 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.72 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.65 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.73 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.07 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.66 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.74 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.54 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.66 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.80 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.59 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.66 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.82 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.59 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.60 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.66 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.82 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.62 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.66 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.87 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.64 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.80 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.88 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.65 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.84 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.90 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 153.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.67 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.86 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.91 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.87 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.92 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.88 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.93 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 157.83 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.94 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.15 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.94 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.22 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.96 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.23 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.90 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.72 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.26 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.93 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠧\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 150.97 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.87 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.37 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.93 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 151.03 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 154.25 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 151.87 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.43 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 151.03 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 156.01 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 152.34 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.43 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 151.03 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 156.01 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 152.98 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.43 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 157.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠇\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 151.05 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 156.01 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 153.33 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.44 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 158.45 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 151.56 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 156.59 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 153.85 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 158.96 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 158.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 152.32 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 157.19 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 154.21 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 159.58 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 159.15 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 152.88 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 157.79 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 154.82 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 160.10 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 159.89 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 153.29 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 158.46 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 155.57 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 160.67 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 160.57 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 153.53 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 159.26 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 155.57 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 161.26 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 160.58 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 154.07 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 159.26 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 156.22 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 161.33 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 160.70 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 154.78 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 159.91 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 156.25 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 162.06 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 160.70 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A   \u001b[36m\u001b[1mUpdating\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 154.78 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 160.53 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 156.90 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 162.75 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 160.79 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[13A    \u001b[32m\u001b[1mUpdated\u001b[0m\u001b[39m https://github.com/facebookresearch/xformers.git (\u001b[2mde742ec3d64bd83b1184cc\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 155.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 160.66 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 156.90 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 162.75 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 161.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[11A      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m word2number\u001b[2m==1.1\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m sqlitedict\u001b[2m==2.1.0\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m rouge-score\u001b[2m==0.1.2\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m antlr4-python3-runtime\u001b[2m==4.9.3\u001b[0m\n",
            "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m luigi\u001b[2m==3.6.0\u001b[0m\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 155.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 160.66 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 156.96 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 162.75 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 161.42 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 155.46 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 161.19 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 157.43 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 163.50 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 162.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 156.69 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 161.92 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 158.10 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 164.51 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 162.68 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 157.76 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 162.93 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 158.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 165.16 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 163.44 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 158.23 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 163.59 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 159.37 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 166.01 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 164.64 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 159.12 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 164.28 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 159.71 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 166.56 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 164.97 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 160.04 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 164.91 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 160.40 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 167.63 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 165.65 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 160.11 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 165.74 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 160.79 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 167.98 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 166.12 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 160.68 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.14 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 161.42 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 168.24 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 166.83 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 162.00 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 168.79 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 167.30 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠦\u001b[0m \u001b[2mPreparing packages...\u001b[0m (134/141)\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 162.00 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 168.79 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 167.30 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[8A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 162.00 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 168.79 MiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 167.30 MiB/633.96 MiB\n",
            "\u001b[2K\u001b[7A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 162.00 MiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 168.79 MiB/391.57 MiB\n",
            "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 168.79 MiB/391.57 MiB\n",
            "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2K\u001b[4A\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 161.15 MiB/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2K\u001b[2A\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m---------------------------\u001b[2m---\u001b[0m\u001b[0m 166.44 MiB/186.88 MiB\n",
            "\u001b[2K  \u001b[31m×\u001b[0m Failed to build `xformers @\n",
            "  \u001b[31m│\u001b[0m git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148`\n",
            "\u001b[31m  ├─▶ \u001b[0mThe build backend returned an error\n",
            "\u001b[31m  ╰─▶ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n",
            "\u001b[31m      \u001b[0mstatus: 1)\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n",
            "\u001b[31m      \u001b[0mTraceback (most recent call last):\n",
            "\u001b[31m      \u001b[0m  File \"<string>\", line 8, in <module>\n",
            "\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'setuptools'\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n",
            "\u001b[31m      \u001b[0menvironment.\n",
            "\u001b[36m  help: \u001b[0m`\u001b[36mxformers\u001b[39m` was included because `\u001b[36mblt\u001b[39m` (\u001b[36mv0.1.0\u001b[39m) depends on `\u001b[36mxformers\u001b[39m`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv run python demo.py \"A BLT has\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQlyRTMDFC_z",
        "outputId": "0a366677-3afa-4a93-9ff7-4b6c57dd2ce7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m⠋\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)                                                   \r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)                                                   \r\u001b[2K   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)                                                   \u001b[2A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[2A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/228.52 MiB                \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.00 KiB/228.52 MiB               \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 24.00 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 40.00 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 48.00 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 56.00 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 62.46 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 70.46 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 78.46 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 86.46 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 94.46 KiB/228.52 MiB              \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 102.46 KiB/228.52 MiB             \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 110.46 KiB/228.52 MiB             \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 118.46 KiB/228.52 MiB             \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 126.46 KiB/228.52 MiB             \u001b[3A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2K\u001b[3A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 8.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 172.11 KiB/228.52 MiB\n",
            "\u001b[2K\u001b[5A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/7)\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 108.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 184.60 KiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 80.54 KiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 112.00 KiB/633.96 MiB\n",
            "\u001b[2K\u001b[7A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-nccl-cu12\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/179.91 MiB\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 184.60 KiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 200.54 KiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 176.00 KiB/633.96 MiB\n",
            "\u001b[2K\u001b[7A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 184.60 KiB/228.52 MiB\n",
            "\u001b[2mnvidia-cublas-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 200.54 KiB/391.57 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 176.00 KiB/633.96 MiB\n",
            "\u001b[2K\u001b[6A   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m xformers\u001b[2m @ git+https://github.com/facebookresearch/xformers.git@de742ec3\n",
            "\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 184.60 KiB/228.52 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 176.00 KiB/633.96 MiB\n",
            "\u001b[2K\u001b[5A\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 184.60 KiB/228.52 MiB\n",
            "\u001b[2mnvidia-cudnn-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 176.00 KiB/633.96 MiB\n",
            "\u001b[2K\u001b[3A\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.00 KiB/186.88 MiB\n",
            "\u001b[2mpytorch-triton\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 184.60 KiB/228.52 MiB\n",
            "\u001b[2K\u001b[2A\u001b[2mnvidia-cusparse-cu12\u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 316.00 KiB/186.88 MiB\n",
            "\u001b[2K  \u001b[31m×\u001b[0m Failed to build `xformers @\n",
            "  \u001b[31m│\u001b[0m git+https://github.com/facebookresearch/xformers.git@de742ec3d64bd83b1184cc043e541f15d270c148`\n",
            "\u001b[31m  ├─▶ \u001b[0mThe build backend returned an error\n",
            "\u001b[31m  ╰─▶ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n",
            "\u001b[31m      \u001b[0mstatus: 1)\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n",
            "\u001b[31m      \u001b[0mTraceback (most recent call last):\n",
            "\u001b[31m      \u001b[0m  File \"<string>\", line 8, in <module>\n",
            "\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'setuptools'\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n",
            "\u001b[31m      \u001b[0menvironment.\n",
            "\u001b[36m  help: \u001b[0m`\u001b[36mxformers\u001b[39m` was included because `\u001b[36mblt\u001b[39m` (\u001b[36mv0.1.0\u001b[39m) depends on `\u001b[36mxformers\u001b[39m`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"My test prompt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI4U_cmxG7HL",
        "outputId": "017bcad8-7f40-4b8d-949e-5c248cea900f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 538/538 [00:00<00:00, 3.00MB/s]\n",
            "model.safetensors: 100% 199M/199M [00:03<00:00, 63.0MB/s]\n",
            "config.json: 100% 3.28k/3.28k [00:00<00:00, 24.3MB/s]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo)\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3DGHGCzHB_C",
        "outputId": "c96663f3-a5e0-4cfa-e9cc-7b7d3d7c6419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo, use_cash=\"True\")\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "loTDQ3piIYML",
        "outputId": "911e7d39-cb44-4e2f-a852-56950d721f79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ByteLatentTransformer.__init__() got an unexpected keyword argument 'use_cash'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e04800bc5dd9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mblt_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mblt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtok_and_patcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok_and_patcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ByteLatentTransformer.__init__() got an unexpected keyword argument 'use_cash'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "import json\n",
        "import os\n",
        "from dataclasses import Field, asdict, dataclass, is_dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, ClassVar, Dict, List, Optional, Protocol, Tuple, Type, TypeVar, Union\n",
        "\n",
        "import packaging.version\n",
        "\n",
        "from . import constants\n",
        "from .errors import EntryNotFoundError, HfHubHTTPError\n",
        "from .file_download import hf_hub_download\n",
        "from .hf_api import HfApi\n",
        "from .repocard import ModelCard, ModelCardData\n",
        "from .utils import (\n",
        "    SoftTemporaryDirectory,\n",
        "    is_jsonable,\n",
        "    is_safetensors_available,\n",
        "    is_simple_optional_type,\n",
        "    is_torch_available,\n",
        "    logging,\n",
        "    unwrap_simple_optional_type,\n",
        "    validate_hf_hub_args,\n",
        ")\n",
        "\n",
        "\n",
        "if is_torch_available():\n",
        "    import torch  # type: ignore\n",
        "\n",
        "if is_safetensors_available():\n",
        "    import safetensors\n",
        "    from safetensors.torch import load_model as load_model_as_safetensor\n",
        "    from safetensors.torch import save_model as save_model_as_safetensor\n",
        "\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "\n",
        "# Type alias for dataclass instances, copied from https://github.com/python/typeshed/blob/9f28171658b9ca6c32a7cb93fbb99fc92b17858b/stdlib/_typeshed/__init__.pyi#L349\n",
        "class DataclassInstance(Protocol):\n",
        "    __dataclass_fields__: ClassVar[Dict[str, Field]]\n",
        "\n",
        "\n",
        "# Generic variable that is either ModelHubMixin or a subclass thereof\n",
        "T = TypeVar(\"T\", bound=\"ModelHubMixin\")\n",
        "# Generic variable to represent an args type\n",
        "ARGS_T = TypeVar(\"ARGS_T\")\n",
        "ENCODER_T = Callable[[ARGS_T], Any]\n",
        "DECODER_T = Callable[[Any], ARGS_T]\n",
        "CODER_T = Tuple[ENCODER_T, DECODER_T]\n",
        "\n",
        "\n",
        "DEFAULT_MODEL_CARD = \"\"\"\n",
        "---\n",
        "# For reference on model card metadata, see the spec: https://github.com/huggingface/hub-docs/blob/main/modelcard.md?plain=1\n",
        "# Doc / guide: https://huggingface.co/docs/hub/model-cards\n",
        "{{ card_data }}\n",
        "---\n",
        "\n",
        "This model has been pushed to the Hub using the [PytorchModelHubMixin](https://huggingface.co/docs/huggingface_hub/package_reference/mixins#huggingface_hub.PyTorchModelHubMixin) integration:\n",
        "- Code: {{ repo_url | default(\"[More Information Needed]\", true) }}\n",
        "- Paper: {{ paper_url | default(\"[More Information Needed]\", true) }}\n",
        "- Docs: {{ docs_url | default(\"[More Information Needed]\", true) }}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MixinInfo:\n",
        "    model_card_template: str\n",
        "    model_card_data: ModelCardData\n",
        "    docs_url: Optional[str] = None\n",
        "    paper_url: Optional[str] = None\n",
        "    repo_url: Optional[str] = None\n",
        "\n",
        "\n",
        "class ModelHubMixin:\n",
        "    \"\"\"\n",
        "    A generic mixin to integrate ANY machine learning framework with the Hub.\n",
        "\n",
        "    To integrate your framework, your model class must inherit from this class. Custom logic for saving/loading models\n",
        "    have to be overwritten in  [`_from_pretrained`] and [`_save_pretrained`]. [`PyTorchModelHubMixin`] is a good example\n",
        "    of mixin integration with the Hub. Check out our [integration guide](../guides/integrations) for more instructions.\n",
        "\n",
        "    When inheriting from [`ModelHubMixin`], you can define class-level attributes. These attributes are not passed to\n",
        "    `__init__` but to the class definition itself. This is useful to define metadata about the library integrating\n",
        "    [`ModelHubMixin`].\n",
        "\n",
        "    For more details on how to integrate the mixin with your library, checkout the [integration guide](../guides/integrations).\n",
        "\n",
        "    Args:\n",
        "        repo_url (`str`, *optional*):\n",
        "            URL of the library repository. Used to generate model card.\n",
        "        paper_url (`str`, *optional*):\n",
        "            URL of the library paper. Used to generate model card.\n",
        "        docs_url (`str`, *optional*):\n",
        "            URL of the library documentation. Used to generate model card.\n",
        "        model_card_template (`str`, *optional*):\n",
        "            Template of the model card. Used to generate model card. Defaults to a generic template.\n",
        "        language (`str` or `List[str]`, *optional*):\n",
        "            Language supported by the library. Used to generate model card.\n",
        "        library_name (`str`, *optional*):\n",
        "            Name of the library integrating ModelHubMixin. Used to generate model card.\n",
        "        license (`str`, *optional*):\n",
        "            License of the library integrating ModelHubMixin. Used to generate model card.\n",
        "            E.g: \"apache-2.0\"\n",
        "        license_name (`str`, *optional*):\n",
        "            Name of the library integrating ModelHubMixin. Used to generate model card.\n",
        "            Only used if `license` is set to `other`.\n",
        "            E.g: \"coqui-public-model-license\".\n",
        "        license_link (`str`, *optional*):\n",
        "            URL to the license of the library integrating ModelHubMixin. Used to generate model card.\n",
        "            Only used if `license` is set to `other` and `license_name` is set.\n",
        "            E.g: \"https://coqui.ai/cpml\".\n",
        "        pipeline_tag (`str`, *optional*):\n",
        "            Tag of the pipeline. Used to generate model card. E.g. \"text-classification\".\n",
        "        tags (`List[str]`, *optional*):\n",
        "            Tags to be added to the model card. Used to generate model card. E.g. [\"computer-vision\"]\n",
        "        coders (`Dict[Type, Tuple[Callable, Callable]]`, *optional*):\n",
        "            Dictionary of custom types and their encoders/decoders. Used to encode/decode arguments that are not\n",
        "            jsonable by default. E.g dataclasses, argparse.Namespace, OmegaConf, etc.\n",
        "\n",
        "    Example:\n",
        "\n",
        "    ```python\n",
        "    >>> from huggingface_hub import ModelHubMixin\n",
        "\n",
        "    # Inherit from ModelHubMixin\n",
        "    >>> class MyCustomModel(\n",
        "    ...         ModelHubMixin,\n",
        "    ...         library_name=\"my-library\",\n",
        "    ...         tags=[\"computer-vision\"],\n",
        "    ...         repo_url=\"https://github.com/huggingface/my-cool-library\",\n",
        "    ...         paper_url=\"https://arxiv.org/abs/2304.12244\",\n",
        "    ...         docs_url=\"https://huggingface.co/docs/my-cool-library\",\n",
        "    ...         # ^ optional metadata to generate model card\n",
        "    ...     ):\n",
        "    ...     def __init__(self, size: int = 512, device: str = \"cpu\"):\n",
        "    ...         # define how to initialize your model\n",
        "    ...         super().__init__()\n",
        "    ...         ...\n",
        "    ...\n",
        "    ...     def _save_pretrained(self, save_directory: Path) -> None:\n",
        "    ...         # define how to serialize your model\n",
        "    ...         ...\n",
        "    ...\n",
        "    ...     @classmethod\n",
        "    ...     def from_pretrained(\n",
        "    ...         cls: Type[T],\n",
        "    ...         pretrained_model_name_or_path: Union[str, Path],\n",
        "    ...         *,\n",
        "    ...         force_download: bool = False,\n",
        "    ...         resume_download: Optional[bool] = None,\n",
        "    ...         proxies: Optional[Dict] = None,\n",
        "    ...         token: Optional[Union[str, bool]] = None,\n",
        "    ...         cache_dir: Optional[Union[str, Path]] = None,\n",
        "    ...         local_files_only: bool = False,\n",
        "    ...         revision: Optional[str] = None,\n",
        "    ...         **model_kwargs,\n",
        "    ...     ) -> T:\n",
        "    ...         # define how to deserialize your model\n",
        "    ...         ...\n",
        "\n",
        "    >>> model = MyCustomModel(size=256, device=\"gpu\")\n",
        "\n",
        "    # Save model weights to local directory\n",
        "    >>> model.save_pretrained(\"my-awesome-model\")\n",
        "\n",
        "    # Push model weights to the Hub\n",
        "    >>> model.push_to_hub(\"my-awesome-model\")\n",
        "\n",
        "    # Download and initialize weights from the Hub\n",
        "    >>> reloaded_model = MyCustomModel.from_pretrained(\"username/my-awesome-model\")\n",
        "    >>> reloaded_model.size\n",
        "    256\n",
        "\n",
        "    # Model card has been correctly populated\n",
        "    >>> from huggingface_hub import ModelCard\n",
        "    >>> card = ModelCard.load(\"username/my-awesome-model\")\n",
        "    >>> card.data.tags\n",
        "    [\"x-custom-tag\", \"pytorch_model_hub_mixin\", \"model_hub_mixin\"]\n",
        "    >>> card.data.library_name\n",
        "    \"my-library\"\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    _hub_mixin_config: Optional[Union[dict, DataclassInstance]] = None\n",
        "    # ^ optional config attribute automatically set in `from_pretrained`\n",
        "    _hub_mixin_info: MixinInfo\n",
        "    # ^ information about the library integrating ModelHubMixin (used to generate model card)\n",
        "    _hub_mixin_inject_config: bool  # whether `_from_pretrained` expects `config` or not\n",
        "    _hub_mixin_init_parameters: Dict[str, inspect.Parameter]  # __init__ parameters\n",
        "    _hub_mixin_jsonable_default_values: Dict[str, Any]  # default values for __init__ parameters\n",
        "    _hub_mixin_jsonable_custom_types: Tuple[Type, ...]  # custom types that can be encoded/decoded\n",
        "    _hub_mixin_coders: Dict[Type, CODER_T]  # encoders/decoders for custom types\n",
        "    # ^ internal values to handle config\n",
        "\n",
        "    def __init_subclass__(\n",
        "        cls,\n",
        "        *,\n",
        "        # Generic info for model card\n",
        "        repo_url: Optional[str] = None,\n",
        "        paper_url: Optional[str] = None,\n",
        "        docs_url: Optional[str] = None,\n",
        "        # Model card template\n",
        "        model_card_template: str = DEFAULT_MODEL_CARD,\n",
        "        # Model card metadata\n",
        "        language: Optional[List[str]] = None,\n",
        "        library_name: Optional[str] = None,\n",
        "        license: Optional[str] = None,\n",
        "        license_name: Optional[str] = None,\n",
        "        license_link: Optional[str] = None,\n",
        "        pipeline_tag: Optional[str] = None,\n",
        "        tags: Optional[List[str]] = None,\n",
        "        # How to encode/decode arguments with custom type into a JSON config?\n",
        "        coders: Optional[\n",
        "            Dict[Type, CODER_T]\n",
        "            # Key is a type.\n",
        "            # Value is a tuple (encoder, decoder).\n",
        "            # Example: {MyCustomType: (lambda x: x.value, lambda data: MyCustomType(data))}\n",
        "        ] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Inspect __init__ signature only once when subclassing + handle modelcard.\"\"\"\n",
        "        super().__init_subclass__()\n",
        "\n",
        "        # Will be reused when creating modelcard\n",
        "        tags = tags or []\n",
        "        tags.append(\"model_hub_mixin\")\n",
        "\n",
        "        # Initialize MixinInfo if not existent\n",
        "        info = MixinInfo(model_card_template=model_card_template, model_card_data=ModelCardData())\n",
        "\n",
        "        # If parent class has a MixinInfo, inherit from it as a copy\n",
        "        if hasattr(cls, \"_hub_mixin_info\"):\n",
        "            # Inherit model card template from parent class if not explicitly set\n",
        "            if model_card_template == DEFAULT_MODEL_CARD:\n",
        "                info.model_card_template = cls._hub_mixin_info.model_card_template\n",
        "\n",
        "            # Inherit from parent model card data\n",
        "            info.model_card_data = ModelCardData(**cls._hub_mixin_info.model_card_data.to_dict())\n",
        "\n",
        "            # Inherit other info\n",
        "            info.docs_url = cls._hub_mixin_info.docs_url\n",
        "            info.paper_url = cls._hub_mixin_info.paper_url\n",
        "            info.repo_url = cls._hub_mixin_info.repo_url\n",
        "        cls._hub_mixin_info = info\n",
        "\n",
        "        # Update MixinInfo with metadata\n",
        "        if model_card_template is not None and model_card_template != DEFAULT_MODEL_CARD:\n",
        "            info.model_card_template = model_card_template\n",
        "        if repo_url is not None:\n",
        "            info.repo_url = repo_url\n",
        "        if paper_url is not None:\n",
        "            info.paper_url = paper_url\n",
        "        if docs_url is not None:\n",
        "            info.docs_url = docs_url\n",
        "        if language is not None:\n",
        "            info.model_card_data.language = language\n",
        "        if library_name is not None:\n",
        "            info.model_card_data.library_name = library_name\n",
        "        if license is not None:\n",
        "            info.model_card_data.license = license\n",
        "        if license_name is not None:\n",
        "            info.model_card_data.license_name = license_name\n",
        "        if license_link is not None:\n",
        "            info.model_card_data.license_link = license_link\n",
        "        if pipeline_tag is not None:\n",
        "            info.model_card_data.pipeline_tag = pipeline_tag\n",
        "        if tags is not None:\n",
        "            if info.model_card_data.tags is not None:\n",
        "                info.model_card_data.tags.extend(tags)\n",
        "            else:\n",
        "                info.model_card_data.tags = tags\n",
        "\n",
        "        info.model_card_data.tags = sorted(set(info.model_card_data.tags))\n",
        "\n",
        "        # Handle encoders/decoders for args\n",
        "        cls._hub_mixin_coders = coders or {}\n",
        "        cls._hub_mixin_jsonable_custom_types = tuple(cls._hub_mixin_coders.keys())\n",
        "\n",
        "        # Inspect __init__ signature to handle config\n",
        "        cls._hub_mixin_init_parameters = dict(inspect.signature(cls.__init__).parameters)\n",
        "        cls._hub_mixin_jsonable_default_values = {\n",
        "            param.name: cls._encode_arg(param.default)\n",
        "            for param in cls._hub_mixin_init_parameters.values()\n",
        "            if param.default is not inspect.Parameter.empty and cls._is_jsonable(param.default)\n",
        "        }\n",
        "        cls._hub_mixin_inject_config = \"config\" in inspect.signature(cls._from_pretrained).parameters\n",
        "\n",
        "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
        "        \"\"\"Create a new instance of the class and handle config.\n",
        "\n",
        "        3 cases:\n",
        "        - If `self._hub_mixin_config` is already set, do nothing.\n",
        "        - If `config` is passed as a dataclass, set it as `self._hub_mixin_config`.\n",
        "        - Otherwise, build `self._hub_mixin_config` from default values and passed values.\n",
        "        \"\"\"\n",
        "        instance = super().__new__(cls)\n",
        "\n",
        "        # If `config` is already set, return early\n",
        "        if instance._hub_mixin_config is not None:\n",
        "            return instance\n",
        "\n",
        "        # Infer passed values\n",
        "        passed_values = {\n",
        "            **{\n",
        "                key: value\n",
        "                for key, value in zip(\n",
        "                    # [1:] to skip `self` parameter\n",
        "                    list(cls._hub_mixin_init_parameters)[1:],\n",
        "                    args,\n",
        "                )\n",
        "            },\n",
        "            **kwargs,\n",
        "        }\n",
        "\n",
        "        # If config passed as dataclass => set it and return early\n",
        "        if is_dataclass(passed_values.get(\"config\")):\n",
        "            instance._hub_mixin_config = passed_values[\"config\"]\n",
        "            return instance\n",
        "\n",
        "        # Otherwise, build config from default + passed values\n",
        "        init_config = {\n",
        "            # default values\n",
        "            **cls._hub_mixin_jsonable_default_values,\n",
        "            # passed values\n",
        "            **{\n",
        "                key: cls._encode_arg(value)  # Encode custom types as jsonable value\n",
        "                for key, value in passed_values.items()\n",
        "                if instance._is_jsonable(value)  # Only if jsonable or we have a custom encoder\n",
        "            },\n",
        "        }\n",
        "        passed_config = init_config.pop(\"config\", {})\n",
        "\n",
        "        # Populate `init_config` with provided config\n",
        "        if isinstance(passed_config, dict):\n",
        "            init_config.update(passed_config)\n",
        "\n",
        "        # Set `config` attribute and return\n",
        "        if init_config != {}:\n",
        "            instance._hub_mixin_config = init_config\n",
        "        return instance\n",
        "\n",
        "    @classmethod\n",
        "    def _is_jsonable(cls, value: Any) -> bool:\n",
        "        \"\"\"Check if a value is JSON serializable.\"\"\"\n",
        "        if is_dataclass(value):\n",
        "            return True\n",
        "        if isinstance(value, cls._hub_mixin_jsonable_custom_types):\n",
        "            return True\n",
        "        return is_jsonable(value)\n",
        "\n",
        "    @classmethod\n",
        "    def _encode_arg(cls, arg: Any) -> Any:\n",
        "        \"\"\"Encode an argument into a JSON serializable format.\"\"\"\n",
        "        if is_dataclass(arg):\n",
        "            return asdict(arg)\n",
        "        for type_, (encoder, _) in cls._hub_mixin_coders.items():\n",
        "            if isinstance(arg, type_):\n",
        "                if arg is None:\n",
        "                    return None\n",
        "                return encoder(arg)\n",
        "        return arg\n",
        "\n",
        "    @classmethod\n",
        "    def _decode_arg(cls, expected_type: Type[ARGS_T], value: Any) -> Optional[ARGS_T]:\n",
        "        \"\"\"Decode a JSON serializable value into an argument.\"\"\"\n",
        "        if is_simple_optional_type(expected_type):\n",
        "            if value is None:\n",
        "                return None\n",
        "            expected_type = unwrap_simple_optional_type(expected_type)\n",
        "        # Dataclass => handle it\n",
        "        if is_dataclass(expected_type):\n",
        "            return _load_dataclass(expected_type, value)  # type: ignore[return-value]\n",
        "        # Otherwise => check custom decoders\n",
        "        for type_, (_, decoder) in cls._hub_mixin_coders.items():\n",
        "            if inspect.isclass(expected_type) and issubclass(expected_type, type_):\n",
        "                return decoder(value)\n",
        "        # Otherwise => don't decode\n",
        "        return value\n",
        "\n",
        "    def save_pretrained(\n",
        "        self,\n",
        "        save_directory: Union[str, Path],\n",
        "        *,\n",
        "        config: Optional[Union[dict, DataclassInstance]] = None,\n",
        "        repo_id: Optional[str] = None,\n",
        "        push_to_hub: bool = False,\n",
        "        model_card_kwargs: Optional[Dict[str, Any]] = None,\n",
        "        **push_to_hub_kwargs,\n",
        "    ) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Save weights in local directory.\n",
        "\n",
        "        Args:\n",
        "            save_directory (`str` or `Path`):\n",
        "                Path to directory in which the model weights and configuration will be saved.\n",
        "            config (`dict` or `DataclassInstance`, *optional*):\n",
        "                Model configuration specified as a key/value dictionary or a dataclass instance.\n",
        "            push_to_hub (`bool`, *optional*, defaults to `False`):\n",
        "                Whether or not to push your model to the Huggingface Hub after saving it.\n",
        "            repo_id (`str`, *optional*):\n",
        "                ID of your repository on the Hub. Used only if `push_to_hub=True`. Will default to the folder name if\n",
        "                not provided.\n",
        "            model_card_kwargs (`Dict[str, Any]`, *optional*):\n",
        "                Additional arguments passed to the model card template to customize the model card.\n",
        "            push_to_hub_kwargs:\n",
        "                Additional key word arguments passed along to the [`~ModelHubMixin.push_to_hub`] method.\n",
        "        Returns:\n",
        "            `str` or `None`: url of the commit on the Hub if `push_to_hub=True`, `None` otherwise.\n",
        "        \"\"\"\n",
        "        save_directory = Path(save_directory)\n",
        "        save_directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Remove config.json if already exists. After `_save_pretrained` we don't want to overwrite config.json\n",
        "        # as it might have been saved by the custom `_save_pretrained` already. However we do want to overwrite\n",
        "        # an existing config.json if it was not saved by `_save_pretrained`.\n",
        "        config_path = save_directory / constants.CONFIG_NAME\n",
        "        config_path.unlink(missing_ok=True)\n",
        "\n",
        "        # save model weights/files (framework-specific)\n",
        "        self._save_pretrained(save_directory)\n",
        "\n",
        "        # save config (if provided and if not serialized yet in `_save_pretrained`)\n",
        "        if config is None:\n",
        "            config = self._hub_mixin_config\n",
        "        if config is not None:\n",
        "            if is_dataclass(config):\n",
        "                config = asdict(config)  # type: ignore[arg-type]\n",
        "            if not config_path.exists():\n",
        "                config_str = json.dumps(config, sort_keys=True, indent=2)\n",
        "                config_path.write_text(config_str)\n",
        "\n",
        "        # save model card\n",
        "        model_card_path = save_directory / \"README.md\"\n",
        "        model_card_kwargs = model_card_kwargs if model_card_kwargs is not None else {}\n",
        "        if not model_card_path.exists():  # do not overwrite if already exists\n",
        "            self.generate_model_card(**model_card_kwargs).save(save_directory / \"README.md\")\n",
        "\n",
        "        # push to the Hub if required\n",
        "        if push_to_hub:\n",
        "            kwargs = push_to_hub_kwargs.copy()  # soft-copy to avoid mutating input\n",
        "            if config is not None:  # kwarg for `push_to_hub`\n",
        "                kwargs[\"config\"] = config\n",
        "            if repo_id is None:\n",
        "                repo_id = save_directory.name  # Defaults to `save_directory` name\n",
        "            return self.push_to_hub(repo_id=repo_id, model_card_kwargs=model_card_kwargs, **kwargs)\n",
        "        return None\n",
        "\n",
        "    def _save_pretrained(self, save_directory: Path) -> None:\n",
        "        \"\"\"\n",
        "        Overwrite this method in subclass to define how to save your model.\n",
        "        Check out our [integration guide](../guides/integrations) for instructions.\n",
        "\n",
        "        Args:\n",
        "            save_directory (`str` or `Path`):\n",
        "                Path to directory in which the model weights and configuration will be saved.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @classmethod\n",
        "    @validate_hf_hub_args\n",
        "    def from_pretrained(\n",
        "        cls: Type[T],\n",
        "        pretrained_model_name_or_path: Union[str, Path],\n",
        "        *,\n",
        "        force_download: bool = False,\n",
        "        resume_download: Optional[bool] = None,\n",
        "        proxies: Optional[Dict] = None,\n",
        "        token: Optional[Union[str, bool]] = None,\n",
        "        cache_dir: Optional[Union[str, Path]] = None,\n",
        "        local_files_only: bool = False,\n",
        "        revision: Optional[str] = None,\n",
        "        **model_kwargs,\n",
        "    ) -> T:\n",
        "        \"\"\"\n",
        "        Download a model from the Huggingface Hub and instantiate it.\n",
        "\n",
        "        Args:\n",
        "            pretrained_model_name_or_path (`str`, `Path`):\n",
        "                - Either the `model_id` (string) of a model hosted on the Hub, e.g. `bigscience/bloom`.\n",
        "                - Or a path to a `directory` containing model weights saved using\n",
        "                    [`~transformers.PreTrainedModel.save_pretrained`], e.g., `../path/to/my_model_directory/`.\n",
        "            revision (`str`, *optional*):\n",
        "                Revision of the model on the Hub. Can be a branch name, a git tag or any commit id.\n",
        "                Defaults to the latest commit on `main` branch.\n",
        "            force_download (`bool`, *optional*, defaults to `False`):\n",
        "                Whether to force (re-)downloading the model weights and configuration files from the Hub, overriding\n",
        "                the existing cache.\n",
        "            proxies (`Dict[str, str]`, *optional*):\n",
        "                A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\n",
        "                'http://hostname': 'foo.bar:4012'}`. The proxies are used on every request.\n",
        "            token (`str` or `bool`, *optional*):\n",
        "                The token to use as HTTP bearer authorization for remote files. By default, it will use the token\n",
        "                cached when running `huggingface-cli login`.\n",
        "            cache_dir (`str`, `Path`, *optional*):\n",
        "                Path to the folder where cached files are stored.\n",
        "            local_files_only (`bool`, *optional*, defaults to `False`):\n",
        "                If `True`, avoid downloading the file and return the path to the local cached file if it exists.\n",
        "            model_kwargs (`Dict`, *optional*):\n",
        "                Additional kwargs to pass to the model during initialization.\n",
        "        \"\"\"\n",
        "        model_id = str(pretrained_model_name_or_path)\n",
        "        config_file: Optional[str] = None\n",
        "        if os.path.isdir(model_id):\n",
        "            if constants.CONFIG_NAME in os.listdir(model_id):\n",
        "                config_file = os.path.join(model_id, constants.CONFIG_NAME)\n",
        "            else:\n",
        "                logger.warning(f\"{constants.CONFIG_NAME} not found in {Path(model_id).resolve()}\")\n",
        "        else:\n",
        "            try:\n",
        "                config_file = hf_hub_download(\n",
        "                    repo_id=model_id,\n",
        "                    filename=constants.CONFIG_NAME,\n",
        "                    revision=revision,\n",
        "                    cache_dir=cache_dir,\n",
        "                    force_download=force_download,\n",
        "                    proxies=proxies,\n",
        "                    resume_download=resume_download,\n",
        "                    token=token,\n",
        "                    local_files_only=local_files_only,\n",
        "                )\n",
        "            except HfHubHTTPError as e:\n",
        "                logger.info(f\"{constants.CONFIG_NAME} not found on the HuggingFace Hub: {str(e)}\")\n",
        "\n",
        "        # Read config\n",
        "        config = None\n",
        "        if config_file is not None:\n",
        "            with open(config_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                config = json.load(f)\n",
        "\n",
        "            # Decode custom types in config\n",
        "            for key, value in config.items():\n",
        "                if key in cls._hub_mixin_init_parameters:\n",
        "                    expected_type = cls._hub_mixin_init_parameters[key].annotation\n",
        "                    if expected_type is not inspect.Parameter.empty:\n",
        "                        config[key] = cls._decode_arg(expected_type, value)\n",
        "\n",
        "            # Populate model_kwargs from config\n",
        "            for param in cls._hub_mixin_init_parameters.values():\n",
        "                if param.name not in model_kwargs and param.name in config:\n",
        "                    model_kwargs[param.name] = config[param.name]\n",
        "\n",
        "            # Check if `config` argument was passed at init\n",
        "            if \"config\" in cls._hub_mixin_init_parameters and \"config\" not in model_kwargs:\n",
        "                # Decode `config` argument if it was passed\n",
        "                config_annotation = cls._hub_mixin_init_parameters[\"config\"].annotation\n",
        "                config = cls._decode_arg(config_annotation, config)\n",
        "\n",
        "                # Forward config to model initialization\n",
        "                model_kwargs[\"config\"] = config\n",
        "\n",
        "            # Inject config if `**kwargs` are expected\n",
        "            if is_dataclass(cls):\n",
        "                for key in cls.__dataclass_fields__:\n",
        "                    if key not in model_kwargs and key in config:\n",
        "                        model_kwargs[key] = config[key]\n",
        "            elif any(param.kind == inspect.Parameter.VAR_KEYWORD for param in cls._hub_mixin_init_parameters.values()):\n",
        "                for key, value in config.items():\n",
        "                    if key not in model_kwargs:\n",
        "                        model_kwargs[key] = value\n",
        "\n",
        "            # Finally, also inject if `_from_pretrained` expects it\n",
        "            if cls._hub_mixin_inject_config and \"config\" not in model_kwargs:\n",
        "                model_kwargs[\"config\"] = config\n",
        "\n",
        "        instance = cls._from_pretrained(\n",
        "            model_id=str(model_id),\n",
        "            revision=revision,\n",
        "            cache_dir=cache_dir,\n",
        "            force_download=force_download,\n",
        "            proxies=proxies,\n",
        "            resume_download=resume_download,\n",
        "            local_files_only=local_files_only,\n",
        "            token=token,\n",
        "            **model_kwargs,\n",
        "        )\n",
        "\n",
        "        # Implicitly set the config as instance attribute if not already set by the class\n",
        "        # This way `config` will be available when calling `save_pretrained` or `push_to_hub`.\n",
        "        if config is not None and (getattr(instance, \"_hub_mixin_config\", None) in (None, {})):\n",
        "            instance._hub_mixin_config = config\n",
        "\n",
        "        return instance\n",
        "\n",
        "    @classmethod\n",
        "    def _from_pretrained(\n",
        "        cls: Type[T],\n",
        "        *,\n",
        "        model_id: str,\n",
        "        revision: Optional[str],\n",
        "        cache_dir: Optional[Union[str, Path]],\n",
        "        force_download: bool,\n",
        "        proxies: Optional[Dict],\n",
        "        resume_download: Optional[bool],\n",
        "        local_files_only: bool,\n",
        "        token: Optional[Union[str, bool]],\n",
        "        **model_kwargs,\n",
        "    ) -> T:\n",
        "        \"\"\"Overwrite this method in subclass to define how to load your model from pretrained.\n",
        "\n",
        "        Use [`hf_hub_download`] or [`snapshot_download`] to download files from the Hub before loading them. Most\n",
        "        args taken as input can be directly passed to those 2 methods. If needed, you can add more arguments to this\n",
        "        method using \"model_kwargs\". For example [`PyTorchModelHubMixin._from_pretrained`] takes as input a `map_location`\n",
        "        parameter to set on which device the model should be loaded.\n",
        "\n",
        "        Check out our [integration guide](../guides/integrations) for more instructions.\n",
        "\n",
        "        Args:\n",
        "            model_id (`str`):\n",
        "                ID of the model to load from the Huggingface Hub (e.g. `bigscience/bloom`).\n",
        "            revision (`str`, *optional*):\n",
        "                Revision of the model on the Hub. Can be a branch name, a git tag or any commit id. Defaults to the\n",
        "                latest commit on `main` branch.\n",
        "            force_download (`bool`, *optional*, defaults to `False`):\n",
        "                Whether to force (re-)downloading the model weights and configuration files from the Hub, overriding\n",
        "                the existing cache.\n",
        "            proxies (`Dict[str, str]`, *optional*):\n",
        "                A dictionary of proxy servers to use by protocol or endpoint (e.g., `{'http': 'foo.bar:3128',\n",
        "                'http://hostname': 'foo.bar:4012'}`).\n",
        "            token (`str` or `bool`, *optional*):\n",
        "                The token to use as HTTP bearer authorization for remote files. By default, it will use the token\n",
        "                cached when running `huggingface-cli login`.\n",
        "            cache_dir (`str`, `Path`, *optional*):\n",
        "                Path to the folder where cached files are stored.\n",
        "            local_files_only (`bool`, *optional*, defaults to `False`):\n",
        "                If `True`, avoid downloading the file and return the path to the local cached file if it exists.\n",
        "            model_kwargs:\n",
        "                Additional keyword arguments passed along to the [`~ModelHubMixin._from_pretrained`] method.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @validate_hf_hub_args\n",
        "    def push_to_hub(\n",
        "        self,\n",
        "        repo_id: str,\n",
        "        *,\n",
        "        config: Optional[Union[dict, DataclassInstance]] = None,\n",
        "        commit_message: str = \"Push model using huggingface_hub.\",\n",
        "        private: Optional[bool] = None,\n",
        "        token: Optional[str] = None,\n",
        "        branch: Optional[str] = None,\n",
        "        create_pr: Optional[bool] = None,\n",
        "        allow_patterns: Optional[Union[List[str], str]] = None,\n",
        "        ignore_patterns: Optional[Union[List[str], str]] = None,\n",
        "        delete_patterns: Optional[Union[List[str], str]] = None,\n",
        "        model_card_kwargs: Optional[Dict[str, Any]] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Upload model checkpoint to the Hub.\n",
        "\n",
        "        Use `allow_patterns` and `ignore_patterns` to precisely filter which files should be pushed to the hub. Use\n",
        "        `delete_patterns` to delete existing remote files in the same commit. See [`upload_folder`] reference for more\n",
        "        details.\n",
        "\n",
        "        Args:\n",
        "            repo_id (`str`):\n",
        "                ID of the repository to push to (example: `\"username/my-model\"`).\n",
        "            config (`dict` or `DataclassInstance`, *optional*):\n",
        "                Model configuration specified as a key/value dictionary or a dataclass instance.\n",
        "            commit_message (`str`, *optional*):\n",
        "                Message to commit while pushing.\n",
        "            private (`bool`, *optional*):\n",
        "                Whether the repository created should be private.\n",
        "                If `None` (default), the repo will be public unless the organization's default is private.\n",
        "            token (`str`, *optional*):\n",
        "                The token to use as HTTP bearer authorization for remote files. By default, it will use the token\n",
        "                cached when running `huggingface-cli login`.\n",
        "            branch (`str`, *optional*):\n",
        "                The git branch on which to push the model. This defaults to `\"main\"`.\n",
        "            create_pr (`boolean`, *optional*):\n",
        "                Whether or not to create a Pull Request from `branch` with that commit. Defaults to `False`.\n",
        "            allow_patterns (`List[str]` or `str`, *optional*):\n",
        "                If provided, only files matching at least one pattern are pushed.\n",
        "            ignore_patterns (`List[str]` or `str`, *optional*):\n",
        "                If provided, files matching any of the patterns are not pushed.\n",
        "            delete_patterns (`List[str]` or `str`, *optional*):\n",
        "                If provided, remote files matching any of the patterns will be deleted from the repo.\n",
        "            model_card_kwargs (`Dict[str, Any]`, *optional*):\n",
        "                Additional arguments passed to the model card template to customize the model card.\n",
        "\n",
        "        Returns:\n",
        "            The url of the commit of your model in the given repository.\n",
        "        \"\"\"\n",
        "        api = HfApi(token=token)\n",
        "        repo_id = api.create_repo(repo_id=repo_id, private=private, exist_ok=True).repo_id\n",
        "\n",
        "        # Push the files to the repo in a single commit\n",
        "        with SoftTemporaryDirectory() as tmp:\n",
        "            saved_path = Path(tmp) / repo_id\n",
        "            self.save_pretrained(saved_path, config=config, model_card_kwargs=model_card_kwargs)\n",
        "            return api.upload_folder(\n",
        "                repo_id=repo_id,\n",
        "                repo_type=\"model\",\n",
        "                folder_path=saved_path,\n",
        "                commit_message=commit_message,\n",
        "                revision=branch,\n",
        "                create_pr=create_pr,\n",
        "                allow_patterns=allow_patterns,\n",
        "                ignore_patterns=ignore_patterns,\n",
        "                delete_patterns=delete_patterns,\n",
        "            )\n",
        "\n",
        "    def generate_model_card(self, *args, **kwargs) -> ModelCard:\n",
        "        card = ModelCard.from_template(\n",
        "            card_data=self._hub_mixin_info.model_card_data,\n",
        "            template_str=self._hub_mixin_info.model_card_template,\n",
        "            repo_url=self._hub_mixin_info.repo_url,\n",
        "            paper_url=self._hub_mixin_info.paper_url,\n",
        "            docs_url=self._hub_mixin_info.docs_url,\n",
        "            **kwargs,\n",
        "        )\n",
        "        return card\n",
        "\n",
        "\n",
        "class PyTorchModelHubMixin(ModelHubMixin):\n",
        "    \"\"\"\n",
        "    Implementation of [`ModelHubMixin`] to provide model Hub upload/download capabilities to PyTorch models. The model\n",
        "    is set in evaluation mode by default using `model.eval()` (dropout modules are deactivated). To train the model,\n",
        "    you should first set it back in training mode with `model.train()`.\n",
        "\n",
        "    See [`ModelHubMixin`] for more details on how to use the mixin.\n",
        "\n",
        "    Example:\n",
        "\n",
        "    ```python\n",
        "    >>> import torch\n",
        "    >>> import torch.nn as nn\n",
        "    >>> from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "    >>> class MyModel(\n",
        "    ...         nn.Module,\n",
        "    ...         PyTorchModelHubMixin,\n",
        "    ...         library_name=\"keras-nlp\",\n",
        "    ...         repo_url=\"https://github.com/keras-team/keras-nlp\",\n",
        "    ...         paper_url=\"https://arxiv.org/abs/2304.12244\",\n",
        "    ...         docs_url=\"https://keras.io/keras_nlp/\",\n",
        "    ...         # ^ optional metadata to generate model card\n",
        "    ...     ):\n",
        "    ...     def __init__(self, hidden_size: int = 512, vocab_size: int = 30000, output_size: int = 4):\n",
        "    ...         super().__init__()\n",
        "    ...         self.param = nn.Parameter(torch.rand(hidden_size, vocab_size))\n",
        "    ...         self.linear = nn.Linear(output_size, vocab_size)\n",
        "\n",
        "    ...     def forward(self, x):\n",
        "    ...         return self.linear(x + self.param)\n",
        "    >>> model = MyModel(hidden_size=256)\n",
        "\n",
        "    # Save model weights to local directory\n",
        "    >>> model.save_pretrained(\"my-awesome-model\")\n",
        "\n",
        "    # Push model weights to the Hub\n",
        "    >>> model.push_to_hub(\"my-awesome-model\")\n",
        "\n",
        "    # Download and initialize weights from the Hub\n",
        "    >>> model = MyModel.from_pretrained(\"username/my-awesome-model\")\n",
        "    >>> model.hidden_size\n",
        "    256\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init_subclass__(cls, *args, tags: Optional[List[str]] = None, **kwargs) -> None:\n",
        "        tags = tags or []\n",
        "        tags.append(\"pytorch_model_hub_mixin\")\n",
        "        kwargs[\"tags\"] = tags\n",
        "        return super().__init_subclass__(*args, **kwargs)\n",
        "\n",
        "    def _save_pretrained(self, save_directory: Path) -> None:\n",
        "        \"\"\"Save weights from a Pytorch model to a local directory.\"\"\"\n",
        "        model_to_save = self.module if hasattr(self, \"module\") else self  # type: ignore\n",
        "        save_model_as_safetensor(model_to_save, str(save_directory / constants.SAFETENSORS_SINGLE_FILE))\n",
        "\n",
        "    @classmethod\n",
        "    def _from_pretrained(\n",
        "        cls,\n",
        "        *,\n",
        "        model_id: str,\n",
        "        revision: Optional[str],\n",
        "        cache_dir: Optional[Union[str, Path]],\n",
        "        force_download: bool,\n",
        "        proxies: Optional[Dict],\n",
        "        resume_download: Optional[bool],\n",
        "        local_files_only: bool,\n",
        "        token: Union[str, bool, None],\n",
        "        map_location: str = \"cpu\",\n",
        "        strict: bool = False,\n",
        "        **model_kwargs,\n",
        "    ):\n",
        "        \"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\n",
        "        model = cls(**model_kwargs)\n",
        "        if os.path.isdir(model_id):\n",
        "            print(\"Loading weights from local directory\")\n",
        "            model_file = os.path.join(model_id, constants.SAFETENSORS_SINGLE_FILE)\n",
        "            return cls._load_as_safetensor(model, model_file, map_location, strict)\n",
        "        else:\n",
        "            try:\n",
        "                model_file = hf_hub_download(\n",
        "                    repo_id=model_id,\n",
        "                    filename=constants.SAFETENSORS_SINGLE_FILE,\n",
        "                    revision=revision,\n",
        "                    cache_dir=cache_dir,\n",
        "                    force_download=force_download,\n",
        "                    proxies=proxies,\n",
        "                    resume_download=resume_download,\n",
        "                    token=token,\n",
        "                    local_files_only=local_files_only,\n",
        "                )\n",
        "                return cls._load_as_safetensor(model, model_file, map_location, strict)\n",
        "            except EntryNotFoundError:\n",
        "                model_file = hf_hub_download(\n",
        "                    repo_id=model_id,\n",
        "                    filename=constants.PYTORCH_WEIGHTS_NAME,\n",
        "                    revision=revision,\n",
        "                    cache_dir=cache_dir,\n",
        "                    force_download=force_download,\n",
        "                    proxies=proxies,\n",
        "                    resume_download=resume_download,\n",
        "                    token=token,\n",
        "                    local_files_only=local_files_only,\n",
        "                )\n",
        "                return cls._load_as_pickle(model, model_file, map_location, strict)\n",
        "\n",
        "    @classmethod\n",
        "    def _load_as_pickle(cls, model: T, model_file: str, map_location: str, strict: bool) -> T:\n",
        "        state_dict = torch.load(model_file, map_location=torch.device(map_location), weights_only=True)\n",
        "        model.load_state_dict(state_dict, strict=strict)  # type: ignore\n",
        "        model.eval()  # type: ignore\n",
        "        return model\n",
        "\n",
        "    @classmethod\n",
        "    def _load_as_safetensor(cls, model: T, model_file: str, map_location: str, strict: bool) -> T:\n",
        "        if packaging.version.parse(safetensors.__version__) < packaging.version.parse(\"0.4.3\"):  # type: ignore [attr-defined]\n",
        "            load_model_as_safetensor(model, model_file, strict=strict)  # type: ignore [arg-type]\n",
        "            if map_location != \"cpu\":\n",
        "                logger.warning(\n",
        "                    \"Loading model weights on other devices than 'cpu' is not supported natively in your version of safetensors.\"\n",
        "                    \" This means that the model is loaded on 'cpu' first and then copied to the device.\"\n",
        "                    \" This leads to a slower loading time.\"\n",
        "                    \" Please update safetensors to version 0.4.3 or above for improved performance.\"\n",
        "                )\n",
        "                model.to(map_location)  # type: ignore [attr-defined]\n",
        "        else:\n",
        "            safetensors.torch.load_model(model, model_file, strict=strict, device=map_location)  # type: ignore [arg-type]\n",
        "        return model\n",
        "\n",
        "\n",
        "def _load_dataclass(datacls: Type[DataclassInstance], data: dict) -> DataclassInstance:\n",
        "    \"\"\"Load a dataclass instance from a dictionary.\n",
        "\n",
        "    Fields not expected by the dataclass are ignored.\n",
        "    \"\"\"\n",
        "    return datacls(**{k: v for k, v in data.items() if k in datacls.__dataclass_fields__})\n"
      ],
      "metadata": {
        "id": "g7JQYXk5IrPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "     *,\n",
        "        model_id: str,\n",
        "        revision: Optional[str],\n",
        "        cache_dir: Optional[Union[str, Path]],\n",
        "        force_download: bool,\n",
        "        proxies: Optional[Dict],\n",
        "        resume_download: Optional[bool],\n",
        "        local_files_only: bool,\n",
        "        token: Union[str, bool, None],\n",
        "        map_location: str = \"cpu\",\n",
        "        strict: bool = False,\n",
        "        **model_kwargs,"
      ],
      "metadata": {
        "id": "k7Bf-RISJbUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bytelatent.hf load-transformers --entropy-repo facebook/blt-entropy --blt-repo facebook/blt-1b hub --prompt \"My test prompt\""
      ],
      "metadata": {
        "id": "iGrCrGZ1LSls",
        "outputId": "20936941-4195-4a13-ded2-991a21164428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mhf.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mload_transformers\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(blt_model)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(tok_and_patcher)                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m source == \u001b[33m\"\u001b[0m\u001b[33mhub\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   \u001b[0mentropy_model = \u001b[1;4mLMTransformer.from_pretrained(entropy_repo)\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   \u001b[0mblt_model = ByteLatentTransformer.from_pretrained(blt_repo)    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0mtok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_r \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer = tok_and_patcher.tokenizer_args.build()             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────\u001b[0m\u001b[33m─╮\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      blt_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     blt_repo = \u001b[33m'facebook/blt-1b'\u001b[0m      \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  entropy_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m entropy_repo = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       prompt = \u001b[33m'My test prompt'\u001b[0m       \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       source = \u001b[33m'hub'\u001b[0m                  \u001b[33m│\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────╯\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m114\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m114 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[1;4mfn(*args, **kwargs)\u001b[0m                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             arg_name = \u001b[33m'pretrained_model_name_or_path'\u001b[0m                   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            arg_value = \u001b[33m'facebook/blt-entropy'\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 args = \u001b[1m(\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m                                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[33m'bytelatent.transformer.LMTransformer'\u001b[0m\u001b[1m>\u001b[0m,          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[2m│   \u001b[0m\u001b[33m'facebook/blt-entropy'\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[1m)\u001b[0m                                                 \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m check_use_auth_token = \u001b[94mTrue\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            has_token = \u001b[94mFalse\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            signature = \u001b[1m<\u001b[0m\u001b[1;95mSignature\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mcls: Type\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39m~T\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m                       \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpretrained_model_name_or_path: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, *, force_download: bool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mresume_download: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mbool\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, proxies: \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mOptional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mDict\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, token: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, bool, \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mNoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, cache_dir: Union\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr, \u001b[0m          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mpathlib.Path, NoneType\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, local_files_only:\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39mbool = \u001b[0m\u001b[94mFalse\u001b[0m\u001b[39m, revision: Optional\u001b[0m\u001b[1;39m[\u001b[0m\u001b[39mstr\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m = \u001b[0m\u001b[94mNone\u001b[0m\u001b[39m, \u001b[0m    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        \u001b[39m**model_kwargs\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -> ~T\u001b[0m\u001b[1m>\u001b[0m                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m566\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m._hub_mixin_inject_config \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m model_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel_kwargs[\u001b[33m\"\u001b[0m\u001b[33mconfig\u001b[0m\u001b[33m\"\u001b[0m] = config                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0minstance = \u001b[96mcls\u001b[0m._from_pretrained(                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_id=\u001b[96mstr\u001b[0m(model_id),                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0mrevision=revision,                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0mcache_dir=cache_dir,                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                     cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                        config = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                   config_file = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                  model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m pretrained_model_name_or_path = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                      revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰────────────────────────────────────────────────────────╯\u001b[0m                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mhub_mixin.py\u001b[0m:\u001b[94m789\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_from_pretrained\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0m**model_kwargs,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   \u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Load Pytorch pretrained weights and return the loaded model\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m789 \u001b[2m│   │   \u001b[0mmodel = \u001b[1;4;96mcls\u001b[0m\u001b[1;4m(**model_kwargs)\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m os.path.isdir(model_id):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m791 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading weights from local directory\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m792 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_file = os.path.join(model_id, constants.SAFETENSORS_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m─────────────────\u001b[0m\u001b[33m─╮\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        cache_dir = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   force_download = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_files_only = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     map_location = \u001b[33m'cpu'\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         model_id = \u001b[33m'facebook/blt-entropy'\u001b[0m \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     model_kwargs = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                     \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          proxies = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  resume_download = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         revision = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           strict = \u001b[94mFalse\u001b[0m                  \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            token = \u001b[94mNone\u001b[0m                   \u001b[33m│\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────╯\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mLMTransformer.__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m missing \u001b[1;36m1\u001b[0m required positional argument: \n",
            "\u001b[32m'args'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "from bytelatent.transformer import LMTransformer\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.hf import BltTokenizerAndPatcher\n",
        "\n",
        "entropy_repo = \"facebook/blt-entropy\"\n",
        "blt_repo = \"facebook/blt-1b\"\n",
        "entropy_model = LMTransformer.from_pretrained(entropy_repo)\n",
        "blt_model = ByteLatentTransformer.from_pretrained(blt_repo, cache_dir=\"/content/1\", map_location=\"cuda\")\n",
        "tok_and_patcher = BltTokenizerAndPatcher.from_pretrained(blt_repo)\n",
        "tokenizer = tok_and_patcher.tokenizer_args.build()\n",
        "patcher = tok_and_patcher.patcher_args.build()"
      ],
      "metadata": {
        "id": "jVKcKX7qJDgj",
        "outputId": "8929b559-e7be-4635-eb5a-caef7b786150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/blt'\n",
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LMTransformer.__init__() missing 1 required positional argument: 'args'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-644107e83819>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mentropy_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-entropy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mblt_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mentropy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mblt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteLatentTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtok_and_patcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBltTokenizerAndPatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblt_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         instance = cls._from_pretrained(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ):\n\u001b[1;32m    788\u001b[0m         \u001b[0;34m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from local directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LMTransformer.__init__() missing 1 required positional argument: 'args'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/blt"
      ],
      "metadata": {
        "id": "9Vg78dVZKD6D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "VfQHiPcCKh17",
        "outputId": "86497f4a-ed9e-4379-afef-230a251ff946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 57, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/commands/user.py\", line 153, in run\n",
            "    login(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_login.py\", line 130, in login\n",
            "    interpreter_login(new_session=new_session)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py\", line 31, in inner_f\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_login.py\", line 290, in interpreter_login\n",
            "    _login(token=token, add_to_git_credential=add_to_git_credential)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_login.py\", line 412, in _login\n",
            "    _set_active_token(token_name=token_name, add_to_git_credential=add_to_git_credential)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_login.py\", line 459, in _set_active_token\n",
            "    if _is_git_credential_helper_configured():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_login.py\", line 480, in _is_git_credential_helper_configured\n",
            "    helpers = list_credential_helpers()\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_git_credential.py\", line 50, in list_credential_helpers\n",
            "    output = run_subprocess(\"git config --list\", folder=folder).stdout\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_subprocess.py\", line 92, in run_subprocess\n",
            "    cwd=folder or os.getcwd(),\n",
            "                  ^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hP8YWK4gLxec"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}